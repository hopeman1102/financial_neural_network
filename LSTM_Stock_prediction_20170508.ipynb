{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock value prediction from Open, High, Low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt2\n",
    "import pandas as pd\n",
    "from pandas import datetime\n",
    "import math, time\n",
    "import itertools\n",
    "from sklearn import preprocessing\n",
    "import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import load_model\n",
    "import keras\n",
    "import pandas_datareader.data as web\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stock_name = '^GSPC'\n",
    "seq_len = 22\n",
    "d = 0.2\n",
    "shape = [4, seq_len, 1] # feature, window, output\n",
    "neurons = [128, 128, 32, 1]\n",
    "epochs = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1. Download data and normalize it\n",
    "Data since 1950 to today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stock_data(stock_name, normalize=True):\n",
    "    start = datetime.datetime(1950, 1, 1)\n",
    "    end = datetime.date.today()\n",
    "    df = web.DataReader(stock_name, \"yahoo\", start, end)\n",
    "    df.drop(['Volume', 'Close'], 1, inplace=True)\n",
    "    \n",
    "    if normalize:        \n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        df['Open'] = min_max_scaler.fit_transform(df.Open.values.reshape(-1,1))\n",
    "        df['High'] = min_max_scaler.fit_transform(df.High.values.reshape(-1,1))\n",
    "        df['Low'] = min_max_scaler.fit_transform(df.Low.values.reshape(-1,1))\n",
    "        df['Adj Close'] = min_max_scaler.fit_transform(df['Adj Close'].values.reshape(-1,1))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = get_stock_data(stock_name, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Plot out the Normalized Adjusted close price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_stock(stock_name):\n",
    "    df = get_stock_data(stock_name, normalize=True)\n",
    "    print(df.head())\n",
    "    plt.plot(df['Adj Close'], color='red', label='Adj Close')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Open      High       Low  Adj Close\n",
      "Date                                               \n",
      "1950-01-03  0.000000  0.000000  0.000000   0.000000\n",
      "1950-01-04  0.000080  0.000080  0.000080   0.000080\n",
      "1950-01-05  0.000114  0.000113  0.000114   0.000113\n",
      "1950-01-06  0.000135  0.000134  0.000135   0.000134\n",
      "1950-01-09  0.000177  0.000176  0.000177   0.000176\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nStD/B2IfnwgDTWMQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16b42e19f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_stock(stock_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Set last day Adjusted Close as y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(stock, seq_len):\n",
    "    amount_of_features = len(stock.columns)\n",
    "    data = stock.as_matrix() \n",
    "    sequence_length = seq_len + 1 # index starting from 0\n",
    "    result = []\n",
    "    \n",
    "    for index in range(len(data) - sequence_length): # maxmimum date = lastest date - sequence length\n",
    "        result.append(data[index: index + sequence_length]) # index : index + 22days\n",
    "    \n",
    "    result = np.array(result)\n",
    "    row = round(0.9 * result.shape[0]) # 90% split\n",
    "    \n",
    "    train = result[:int(row), :] # 90% date\n",
    "    X_train = train[:, :-1] # all data until day m\n",
    "    y_train = train[:, -1][:,-1] # day m + 1 adjusted close price\n",
    "    \n",
    "    X_test = result[int(row):, :-1]\n",
    "    y_test = result[int(row):, -1][:,-1] \n",
    "\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], amount_of_features))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], amount_of_features))  \n",
    "\n",
    "    return [X_train, y_train, X_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_data(df, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15230, 22, 4)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0], X_train.shape[1], X_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15230"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 4. Buidling neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model2(layers, neurons, d):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(neurons[0], input_shape=(layers[1], layers[0]), return_sequences=True))\n",
    "    model.add(Dropout(d))\n",
    "        \n",
    "    model.add(LSTM(neurons[1], input_shape=(layers[1], layers[0]), return_sequences=False))\n",
    "    model.add(Dropout(d))\n",
    "        \n",
    "    model.add(Dense(neurons[2],kernel_initializer=\"uniform\",activation='relu'))        \n",
    "    model.add(Dense(neurons[3],kernel_initializer=\"uniform\",activation='linear'))\n",
    "    # model = load_model('my_LSTM_stock_model1000.h5')\n",
    "    # adam = keras.optimizers.Adam(decay=0.2)\n",
    "    model.compile(loss='mse',optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Model Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model2(shape, neurons, d)\n",
    "# layers = [4, 22, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13702 samples, validate on 1523 samples\n",
      "Epoch 1/300\n",
      "13702/13702 [==============================] - 3s - loss: 0.0136 - acc: 0.0000e+00 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4231e-04 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.1697e-04 - acc: 0.0000e+00 - val_loss: 5.5174e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5014e-04 - acc: 0.0000e+00 - val_loss: 3.5958e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4812e-04 - acc: 0.0000e+00 - val_loss: 2.5470e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4567e-04 - acc: 0.0000e+00 - val_loss: 4.2694e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3548e-04 - acc: 0.0000e+00 - val_loss: 2.8099e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3038e-04 - acc: 0.0000e+00 - val_loss: 2.4284e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2627e-04 - acc: 0.0000e+00 - val_loss: 2.6150e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3148e-04 - acc: 0.0000e+00 - val_loss: 3.3284e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2079e-04 - acc: 0.0000e+00 - val_loss: 3.7575e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2943e-04 - acc: 0.0000e+00 - val_loss: 4.0294e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2078e-04 - acc: 0.0000e+00 - val_loss: 2.3423e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2792e-04 - acc: 0.0000e+00 - val_loss: 2.2350e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3823e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3013e-04 - acc: 0.0000e+00 - val_loss: 3.6247e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1625e-04 - acc: 0.0000e+00 - val_loss: 2.1267e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1240e-04 - acc: 0.0000e+00 - val_loss: 2.5752e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1321e-04 - acc: 0.0000e+00 - val_loss: 2.2389e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2018e-04 - acc: 0.0000e+00 - val_loss: 2.1248e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0613e-04 - acc: 0.0000e+00 - val_loss: 2.5593e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1032e-04 - acc: 0.0000e+00 - val_loss: 2.5799e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0151e-04 - acc: 0.0000e+00 - val_loss: 2.4435e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0319e-04 - acc: 0.0000e+00 - val_loss: 3.2280e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0529e-04 - acc: 0.0000e+00 - val_loss: 1.9097e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0036e-04 - acc: 0.0000e+00 - val_loss: 2.0103e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.1473e-05 - acc: 0.0000e+00 - val_loss: 1.8688e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.1436e-05 - acc: 0.0000e+00 - val_loss: 2.0994e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0312e-04 - acc: 0.0000e+00 - val_loss: 4.4214e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1334e-04 - acc: 0.0000e+00 - val_loss: 4.0303e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0579e-04 - acc: 0.0000e+00 - val_loss: 2.2158e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.4682e-05 - acc: 0.0000e+00 - val_loss: 2.2017e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3749e-05 - acc: 0.0000e+00 - val_loss: 1.7316e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.9007e-05 - acc: 0.0000e+00 - val_loss: 2.1759e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0617e-04 - acc: 0.0000e+00 - val_loss: 1.9034e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.7312e-05 - acc: 0.0000e+00 - val_loss: 1.7740e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.8467e-05 - acc: 0.0000e+00 - val_loss: 1.6767e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0282e-04 - acc: 0.0000e+00 - val_loss: 1.8205e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.2291e-05 - acc: 0.0000e+00 - val_loss: 1.6347e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.7696e-05 - acc: 0.0000e+00 - val_loss: 2.4535e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.7529e-05 - acc: 0.0000e+00 - val_loss: 3.5880e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.8367e-05 - acc: 0.0000e+00 - val_loss: 1.6008e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.0507e-05 - acc: 0.0000e+00 - val_loss: 4.5279e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0758e-04 - acc: 0.0000e+00 - val_loss: 1.9586e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.8539e-05 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1800e-04 - acc: 0.0000e+00 - val_loss: 2.8431e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.6308e-05 - acc: 0.0000e+00 - val_loss: 1.5417e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.2313e-05 - acc: 0.0000e+00 - val_loss: 1.6940e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.9724e-05 - acc: 0.0000e+00 - val_loss: 1.5344e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.7289e-05 - acc: 0.0000e+00 - val_loss: 1.6466e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.8772e-05 - acc: 0.0000e+00 - val_loss: 3.0318e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1421e-05 - acc: 0.0000e+00 - val_loss: 1.6044e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.8679e-05 - acc: 0.0000e+00 - val_loss: 2.0240e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.4224e-05 - acc: 0.0000e+00 - val_loss: 3.2615e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.4903e-05 - acc: 0.0000e+00 - val_loss: 1.7075e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.6489e-05 - acc: 0.0000e+00 - val_loss: 1.4582e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0077e-05 - acc: 0.0000e+00 - val_loss: 3.1613e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.8053e-05 - acc: 0.0000e+00 - val_loss: 3.4419e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.8210e-05 - acc: 0.0000e+00 - val_loss: 5.2666e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.6186e-05 - acc: 0.0000e+00 - val_loss: 2.1302e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.2406e-05 - acc: 0.0000e+00 - val_loss: 1.4408e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.0734e-05 - acc: 0.0000e+00 - val_loss: 4.9681e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0382e-04 - acc: 0.0000e+00 - val_loss: 1.6843e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1860e-05 - acc: 0.0000e+00 - val_loss: 2.0429e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0988e-04 - acc: 0.0000e+00 - val_loss: 1.8020e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3862e-05 - acc: 0.0000e+00 - val_loss: 1.4094e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.6342e-05 - acc: 0.0000e+00 - val_loss: 1.4935e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8990e-05 - acc: 0.0000e+00 - val_loss: 2.3572e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.4188e-05 - acc: 0.0000e+00 - val_loss: 1.2930e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.6033e-05 - acc: 0.0000e+00 - val_loss: 1.6442e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.5468e-05 - acc: 0.0000e+00 - val_loss: 1.3738e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9638e-05 - acc: 0.0000e+00 - val_loss: 2.6380e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0942e-05 - acc: 0.0000e+00 - val_loss: 1.2320e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.7397e-05 - acc: 0.0000e+00 - val_loss: 1.5353e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.7808e-05 - acc: 0.0000e+00 - val_loss: 1.2403e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.9859e-05 - acc: 0.0000e+00 - val_loss: 2.1464e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.5954e-05 - acc: 0.0000e+00 - val_loss: 1.1893e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.5209e-05 - acc: 0.0000e+00 - val_loss: 1.2981e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0138e-05 - acc: 0.0000e+00 - val_loss: 2.1066e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.3775e-05 - acc: 0.0000e+00 - val_loss: 1.2090e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.8492e-05 - acc: 0.0000e+00 - val_loss: 1.1822e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.9491e-05 - acc: 0.0000e+00 - val_loss: 1.1615e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.7741e-05 - acc: 0.0000e+00 - val_loss: 2.0806e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1918e-05 - acc: 0.0000e+00 - val_loss: 1.5998e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.9729e-05 - acc: 0.0000e+00 - val_loss: 1.5287e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.9717e-05 - acc: 0.0000e+00 - val_loss: 1.1764e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2737e-05 - acc: 0.0000e+00 - val_loss: 1.3288e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6860e-05 - acc: 0.0000e+00 - val_loss: 1.1201e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.8767e-05 - acc: 0.0000e+00 - val_loss: 1.1617e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2235e-05 - acc: 0.0000e+00 - val_loss: 1.1435e-04 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6933e-05 - acc: 0.0000e+00 - val_loss: 1.2584e-04 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1833e-05 - acc: 0.0000e+00 - val_loss: 3.1270e-04 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4695e-05 - acc: 0.0000e+00 - val_loss: 1.3418e-04 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4124e-05 - acc: 0.0000e+00 - val_loss: 1.2973e-04 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0884e-05 - acc: 0.0000e+00 - val_loss: 1.5953e-04 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2088e-05 - acc: 0.0000e+00 - val_loss: 1.2368e-04 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.9616e-05 - acc: 0.0000e+00 - val_loss: 1.1938e-04 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6233e-05 - acc: 0.0000e+00 - val_loss: 1.2408e-04 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.8278e-05 - acc: 0.0000e+00 - val_loss: 4.8762e-04 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.2181e-05 - acc: 0.0000e+00 - val_loss: 3.3142e-04 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.7174e-05 - acc: 0.0000e+00 - val_loss: 2.2562e-04 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6073e-05 - acc: 0.0000e+00 - val_loss: 1.5244e-04 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2030e-05 - acc: 0.0000e+00 - val_loss: 1.1316e-04 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.8848e-05 - acc: 0.0000e+00 - val_loss: 1.2944e-04 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7078e-05 - acc: 0.0000e+00 - val_loss: 1.1417e-04 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4310e-05 - acc: 0.0000e+00 - val_loss: 1.0311e-04 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2442e-05 - acc: 0.0000e+00 - val_loss: 1.0694e-04 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3377e-05 - acc: 0.0000e+00 - val_loss: 1.2424e-04 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.5391e-05 - acc: 0.0000e+00 - val_loss: 1.8296e-04 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9807e-05 - acc: 0.0000e+00 - val_loss: 1.0195e-04 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6943e-05 - acc: 0.0000e+00 - val_loss: 1.6428e-04 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.1387e-05 - acc: 0.0000e+00 - val_loss: 1.4498e-04 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13702/13702 [==============================] - 1s - loss: 6.5203e-05 - acc: 0.0000e+00 - val_loss: 1.0664e-04 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.1330e-05 - acc: 0.0000e+00 - val_loss: 1.7641e-04 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6250e-05 - acc: 0.0000e+00 - val_loss: 9.6615e-05 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8570e-05 - acc: 0.0000e+00 - val_loss: 9.5838e-05 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9823e-05 - acc: 0.0000e+00 - val_loss: 2.5840e-04 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8547e-05 - acc: 0.0000e+00 - val_loss: 2.4948e-04 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2506e-05 - acc: 0.0000e+00 - val_loss: 1.0067e-04 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.4411e-05 - acc: 0.0000e+00 - val_loss: 9.5970e-05 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.8986e-05 - acc: 0.0000e+00 - val_loss: 3.8501e-04 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.3153e-05 - acc: 0.0000e+00 - val_loss: 2.5981e-04 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2028e-05 - acc: 0.0000e+00 - val_loss: 1.0213e-04 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.7727e-05 - acc: 0.0000e+00 - val_loss: 1.6715e-04 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.7700e-05 - acc: 0.0000e+00 - val_loss: 1.2576e-04 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.5369e-05 - acc: 0.0000e+00 - val_loss: 4.6132e-04 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4957e-05 - acc: 0.0000e+00 - val_loss: 1.1058e-04 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2483e-05 - acc: 0.0000e+00 - val_loss: 2.2914e-04 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9983e-05 - acc: 0.0000e+00 - val_loss: 1.5058e-04 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.6555e-05 - acc: 0.0000e+00 - val_loss: 9.9583e-05 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.1909e-05 - acc: 0.0000e+00 - val_loss: 9.2783e-05 - val_acc: 0.0000e+00\n",
      "Epoch 132/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3968e-05 - acc: 0.0000e+00 - val_loss: 9.6689e-05 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.4631e-05 - acc: 0.0000e+00 - val_loss: 9.0343e-05 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.4776e-05 - acc: 0.0000e+00 - val_loss: 1.1422e-04 - val_acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.2688e-05 - acc: 0.0000e+00 - val_loss: 1.1141e-04 - val_acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.2706e-05 - acc: 0.0000e+00 - val_loss: 1.5521e-04 - val_acc: 0.0000e+00\n",
      "Epoch 137/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3643e-05 - acc: 0.0000e+00 - val_loss: 1.4625e-04 - val_acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.0614e-05 - acc: 0.0000e+00 - val_loss: 1.0184e-04 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.5055e-05 - acc: 0.0000e+00 - val_loss: 1.2241e-04 - val_acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.4345e-05 - acc: 0.0000e+00 - val_loss: 2.9843e-04 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.7482e-05 - acc: 0.0000e+00 - val_loss: 1.1565e-04 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9342e-05 - acc: 0.0000e+00 - val_loss: 8.9464e-05 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.2264e-05 - acc: 0.0000e+00 - val_loss: 9.0687e-05 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.1596e-05 - acc: 0.0000e+00 - val_loss: 9.9249e-05 - val_acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3632e-05 - acc: 0.0000e+00 - val_loss: 1.1767e-04 - val_acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6853e-05 - acc: 0.0000e+00 - val_loss: 1.0377e-04 - val_acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6059e-05 - acc: 0.0000e+00 - val_loss: 2.0265e-04 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.7667e-05 - acc: 0.0000e+00 - val_loss: 8.7850e-05 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5806e-05 - acc: 0.0000e+00 - val_loss: 9.8047e-05 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3237e-05 - acc: 0.0000e+00 - val_loss: 8.4626e-05 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.0972e-05 - acc: 0.0000e+00 - val_loss: 1.3301e-04 - val_acc: 0.0000e+00\n",
      "Epoch 152/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9619e-05 - acc: 0.0000e+00 - val_loss: 8.4451e-05 - val_acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.2437e-05 - acc: 0.0000e+00 - val_loss: 8.6439e-05 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5542e-05 - acc: 0.0000e+00 - val_loss: 1.3592e-04 - val_acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6599e-05 - acc: 0.0000e+00 - val_loss: 8.2375e-05 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5722e-05 - acc: 0.0000e+00 - val_loss: 1.8487e-04 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3961e-05 - acc: 0.0000e+00 - val_loss: 1.6353e-04 - val_acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.2850e-05 - acc: 0.0000e+00 - val_loss: 1.2183e-04 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9487e-05 - acc: 0.0000e+00 - val_loss: 9.7799e-05 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.4364e-05 - acc: 0.0000e+00 - val_loss: 8.5659e-05 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.7654e-05 - acc: 0.0000e+00 - val_loss: 8.4089e-05 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.0095e-05 - acc: 0.0000e+00 - val_loss: 8.4502e-05 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5181e-05 - acc: 0.0000e+00 - val_loss: 9.1799e-05 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5113e-05 - acc: 0.0000e+00 - val_loss: 1.5188e-04 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.1348e-05 - acc: 0.0000e+00 - val_loss: 8.3552e-05 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.2472e-05 - acc: 0.0000e+00 - val_loss: 9.8098e-05 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.4689e-05 - acc: 0.0000e+00 - val_loss: 8.5124e-05 - val_acc: 0.0000e+00\n",
      "Epoch 168/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1603e-05 - acc: 0.0000e+00 - val_loss: 1.1888e-04 - val_acc: 0.0000e+00\n",
      "Epoch 169/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5885e-05 - acc: 0.0000e+00 - val_loss: 1.1122e-04 - val_acc: 0.0000e+00\n",
      "Epoch 170/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2998e-05 - acc: 0.0000e+00 - val_loss: 1.1813e-04 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5739e-05 - acc: 0.0000e+00 - val_loss: 1.0320e-04 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.2852e-05 - acc: 0.0000e+00 - val_loss: 1.0873e-04 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6280e-05 - acc: 0.0000e+00 - val_loss: 1.4227e-04 - val_acc: 0.0000e+00\n",
      "Epoch 174/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5634e-05 - acc: 0.0000e+00 - val_loss: 9.7320e-05 - val_acc: 0.0000e+00\n",
      "Epoch 175/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.4526e-05 - acc: 0.0000e+00 - val_loss: 7.9367e-05 - val_acc: 0.0000e+00\n",
      "Epoch 176/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6041e-05 - acc: 0.0000e+00 - val_loss: 8.1803e-05 - val_acc: 0.0000e+00\n",
      "Epoch 177/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2158e-05 - acc: 0.0000e+00 - val_loss: 8.4961e-05 - val_acc: 0.0000e+00\n",
      "Epoch 178/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2303e-05 - acc: 0.0000e+00 - val_loss: 1.0316e-04 - val_acc: 0.0000e+00\n",
      "Epoch 179/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2412e-05 - acc: 0.0000e+00 - val_loss: 1.1308e-04 - val_acc: 0.0000e+00\n",
      "Epoch 180/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6504e-05 - acc: 0.0000e+00 - val_loss: 8.6745e-05 - val_acc: 0.0000e+00\n",
      "Epoch 181/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1254e-05 - acc: 0.0000e+00 - val_loss: 1.0308e-04 - val_acc: 0.0000e+00\n",
      "Epoch 182/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.3418e-05 - acc: 0.0000e+00 - val_loss: 7.6763e-05 - val_acc: 0.0000e+00\n",
      "Epoch 183/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0831e-05 - acc: 0.0000e+00 - val_loss: 8.3050e-05 - val_acc: 0.0000e+00\n",
      "Epoch 184/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0936e-05 - acc: 0.0000e+00 - val_loss: 7.4379e-05 - val_acc: 0.0000e+00\n",
      "Epoch 185/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1992e-05 - acc: 0.0000e+00 - val_loss: 9.2082e-05 - val_acc: 0.0000e+00\n",
      "Epoch 186/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2290e-05 - acc: 0.0000e+00 - val_loss: 9.5961e-05 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1381e-05 - acc: 0.0000e+00 - val_loss: 8.0076e-05 - val_acc: 0.0000e+00\n",
      "Epoch 188/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0250e-05 - acc: 0.0000e+00 - val_loss: 9.7413e-05 - val_acc: 0.0000e+00\n",
      "Epoch 189/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.9415e-05 - acc: 0.0000e+00 - val_loss: 1.3773e-04 - val_acc: 0.0000e+00\n",
      "Epoch 190/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2073e-05 - acc: 0.0000e+00 - val_loss: 7.1906e-05 - val_acc: 0.0000e+00\n",
      "Epoch 191/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.9095e-05 - acc: 0.0000e+00 - val_loss: 7.3268e-05 - val_acc: 0.0000e+00\n",
      "Epoch 192/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0623e-05 - acc: 0.0000e+00 - val_loss: 1.0545e-04 - val_acc: 0.0000e+00\n",
      "Epoch 193/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7892e-05 - acc: 0.0000e+00 - val_loss: 9.4336e-05 - val_acc: 0.0000e+00\n",
      "Epoch 194/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8073e-05 - acc: 0.0000e+00 - val_loss: 7.7375e-05 - val_acc: 0.0000e+00\n",
      "Epoch 195/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1746e-05 - acc: 0.0000e+00 - val_loss: 1.0786e-04 - val_acc: 0.0000e+00\n",
      "Epoch 196/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0168e-05 - acc: 0.0000e+00 - val_loss: 7.2695e-05 - val_acc: 0.0000e+00\n",
      "Epoch 197/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8570e-05 - acc: 0.0000e+00 - val_loss: 9.4546e-05 - val_acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5626e-05 - acc: 0.0000e+00 - val_loss: 8.0507e-05 - val_acc: 0.0000e+00\n",
      "Epoch 199/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0697e-05 - acc: 0.0000e+00 - val_loss: 1.1141e-04 - val_acc: 0.0000e+00\n",
      "Epoch 200/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.4101e-05 - acc: 0.0000e+00 - val_loss: 1.2819e-04 - val_acc: 0.0000e+00\n",
      "Epoch 201/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2212e-05 - acc: 0.0000e+00 - val_loss: 1.0009e-04 - val_acc: 0.0000e+00\n",
      "Epoch 202/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.9947e-05 - acc: 0.0000e+00 - val_loss: 7.2967e-05 - val_acc: 0.0000e+00\n",
      "Epoch 203/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8800e-05 - acc: 0.0000e+00 - val_loss: 9.2206e-05 - val_acc: 0.0000e+00\n",
      "Epoch 204/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7707e-05 - acc: 0.0000e+00 - val_loss: 9.6419e-05 - val_acc: 0.0000e+00\n",
      "Epoch 205/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2321e-05 - acc: 0.0000e+00 - val_loss: 6.7651e-05 - val_acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2364e-05 - acc: 0.0000e+00 - val_loss: 7.0146e-05 - val_acc: 0.0000e+00\n",
      "Epoch 207/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.3407e-05 - acc: 0.0000e+00 - val_loss: 3.3000e-04 - val_acc: 0.0000e+00\n",
      "Epoch 208/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.7697e-05 - acc: 0.0000e+00 - val_loss: 7.4783e-05 - val_acc: 0.0000e+00\n",
      "Epoch 209/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8236e-05 - acc: 0.0000e+00 - val_loss: 1.2292e-04 - val_acc: 0.0000e+00\n",
      "Epoch 210/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6508e-05 - acc: 0.0000e+00 - val_loss: 1.5742e-04 - val_acc: 0.0000e+00\n",
      "Epoch 211/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6660e-05 - acc: 0.0000e+00 - val_loss: 6.8149e-05 - val_acc: 0.0000e+00\n",
      "Epoch 212/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7912e-05 - acc: 0.0000e+00 - val_loss: 7.2622e-05 - val_acc: 0.0000e+00\n",
      "Epoch 213/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5733e-05 - acc: 0.0000e+00 - val_loss: 7.2830e-05 - val_acc: 0.0000e+00\n",
      "Epoch 214/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7270e-05 - acc: 0.0000e+00 - val_loss: 7.7760e-05 - val_acc: 0.0000e+00\n",
      "Epoch 215/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4835e-05 - acc: 0.0000e+00 - val_loss: 1.0652e-04 - val_acc: 0.0000e+00\n",
      "Epoch 216/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4262e-05 - acc: 0.0000e+00 - val_loss: 8.4212e-05 - val_acc: 0.0000e+00\n",
      "Epoch 217/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5485e-05 - acc: 0.0000e+00 - val_loss: 7.9833e-05 - val_acc: 0.0000e+00\n",
      "Epoch 218/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6357e-05 - acc: 0.0000e+00 - val_loss: 7.1568e-05 - val_acc: 0.0000e+00\n",
      "Epoch 219/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7945e-05 - acc: 0.0000e+00 - val_loss: 7.6382e-05 - val_acc: 0.0000e+00\n",
      "Epoch 220/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7550e-05 - acc: 0.0000e+00 - val_loss: 6.8440e-05 - val_acc: 0.0000e+00\n",
      "Epoch 221/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0504e-05 - acc: 0.0000e+00 - val_loss: 8.2601e-05 - val_acc: 0.0000e+00\n",
      "Epoch 222/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6138e-05 - acc: 0.0000e+00 - val_loss: 6.5305e-05 - val_acc: 0.0000e+00\n",
      "Epoch 223/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3241e-05 - acc: 0.0000e+00 - val_loss: 1.1792e-04 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9344e-05 - acc: 0.0000e+00 - val_loss: 1.9553e-04 - val_acc: 0.0000e+00\n",
      "Epoch 225/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13702/13702 [==============================] - 1s - loss: 3.8500e-05 - acc: 0.0000e+00 - val_loss: 9.2846e-05 - val_acc: 0.0000e+00\n",
      "Epoch 226/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7036e-05 - acc: 0.0000e+00 - val_loss: 1.2782e-04 - val_acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2135e-05 - acc: 0.0000e+00 - val_loss: 6.7895e-05 - val_acc: 0.0000e+00\n",
      "Epoch 228/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4487e-05 - acc: 0.0000e+00 - val_loss: 8.3031e-05 - val_acc: 0.0000e+00\n",
      "Epoch 229/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3446e-05 - acc: 0.0000e+00 - val_loss: 6.5587e-05 - val_acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3349e-05 - acc: 0.0000e+00 - val_loss: 8.3603e-05 - val_acc: 0.0000e+00\n",
      "Epoch 231/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3717e-05 - acc: 0.0000e+00 - val_loss: 8.8869e-05 - val_acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3632e-05 - acc: 0.0000e+00 - val_loss: 1.3433e-04 - val_acc: 0.0000e+00\n",
      "Epoch 233/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0558e-05 - acc: 0.0000e+00 - val_loss: 7.1371e-05 - val_acc: 0.0000e+00\n",
      "Epoch 234/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5056e-05 - acc: 0.0000e+00 - val_loss: 1.2267e-04 - val_acc: 0.0000e+00\n",
      "Epoch 235/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3424e-05 - acc: 0.0000e+00 - val_loss: 1.3243e-04 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7814e-05 - acc: 0.0000e+00 - val_loss: 2.3265e-04 - val_acc: 0.0000e+00\n",
      "Epoch 237/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5352e-05 - acc: 0.0000e+00 - val_loss: 6.4904e-05 - val_acc: 0.0000e+00\n",
      "Epoch 238/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6824e-05 - acc: 0.0000e+00 - val_loss: 1.7251e-04 - val_acc: 0.0000e+00\n",
      "Epoch 239/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3137e-05 - acc: 0.0000e+00 - val_loss: 1.8444e-04 - val_acc: 0.0000e+00\n",
      "Epoch 240/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3663e-05 - acc: 0.0000e+00 - val_loss: 8.5101e-05 - val_acc: 0.0000e+00\n",
      "Epoch 241/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.2951e-05 - acc: 0.0000e+00 - val_loss: 2.2989e-04 - val_acc: 0.0000e+00\n",
      "Epoch 242/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5780e-05 - acc: 0.0000e+00 - val_loss: 8.6253e-05 - val_acc: 0.0000e+00\n",
      "Epoch 243/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.1886e-05 - acc: 0.0000e+00 - val_loss: 7.0327e-05 - val_acc: 0.0000e+00\n",
      "Epoch 244/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.2341e-05 - acc: 0.0000e+00 - val_loss: 9.4763e-05 - val_acc: 0.0000e+00\n",
      "Epoch 245/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.9662e-05 - acc: 0.0000e+00 - val_loss: 7.4098e-05 - val_acc: 0.0000e+00\n",
      "Epoch 246/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.2758e-05 - acc: 0.0000e+00 - val_loss: 1.3092e-04 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.1486e-05 - acc: 0.0000e+00 - val_loss: 9.5257e-05 - val_acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6489e-05 - acc: 0.0000e+00 - val_loss: 7.2984e-05 - val_acc: 0.0000e+00\n",
      "Epoch 249/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0190e-05 - acc: 0.0000e+00 - val_loss: 6.8588e-05 - val_acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3485e-05 - acc: 0.0000e+00 - val_loss: 6.5575e-05 - val_acc: 0.0000e+00\n",
      "Epoch 251/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6691e-05 - acc: 0.0000e+00 - val_loss: 1.4712e-04 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6383e-05 - acc: 0.0000e+00 - val_loss: 1.9793e-04 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.1872e-05 - acc: 0.0000e+00 - val_loss: 1.6029e-04 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.1456e-05 - acc: 0.0000e+00 - val_loss: 3.7059e-04 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.2415e-05 - acc: 0.0000e+00 - val_loss: 1.2361e-04 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.9015e-05 - acc: 0.0000e+00 - val_loss: 8.3325e-05 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.1562e-05 - acc: 0.0000e+00 - val_loss: 9.2071e-05 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.1142e-05 - acc: 0.0000e+00 - val_loss: 1.0767e-04 - val_acc: 0.0000e+00\n",
      "Epoch 259/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.8319e-05 - acc: 0.0000e+00 - val_loss: 1.4129e-04 - val_acc: 0.0000e+00\n",
      "Epoch 260/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.9353e-05 - acc: 0.0000e+00 - val_loss: 8.5587e-05 - val_acc: 0.0000e+00\n",
      "Epoch 261/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3162e-05 - acc: 0.0000e+00 - val_loss: 9.9093e-05 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.0535e-05 - acc: 0.0000e+00 - val_loss: 1.0191e-04 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.9965e-05 - acc: 0.0000e+00 - val_loss: 1.5011e-04 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3050e-05 - acc: 0.0000e+00 - val_loss: 8.5766e-05 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3575e-05 - acc: 0.0000e+00 - val_loss: 1.6051e-04 - val_acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.1635e-05 - acc: 0.0000e+00 - val_loss: 6.4128e-05 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.8749e-05 - acc: 0.0000e+00 - val_loss: 1.2676e-04 - val_acc: 0.0000e+00\n",
      "Epoch 268/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.1074e-05 - acc: 0.0000e+00 - val_loss: 7.6019e-05 - val_acc: 0.0000e+00\n",
      "Epoch 269/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.0581e-05 - acc: 0.0000e+00 - val_loss: 6.2393e-05 - val_acc: 0.0000e+00\n",
      "Epoch 270/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.0540e-05 - acc: 0.0000e+00 - val_loss: 2.1982e-04 - val_acc: 0.0000e+00\n",
      "Epoch 271/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3590e-05 - acc: 0.0000e+00 - val_loss: 2.2748e-04 - val_acc: 0.0000e+00\n",
      "Epoch 272/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.0080e-05 - acc: 0.0000e+00 - val_loss: 8.4177e-05 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.2400e-05 - acc: 0.0000e+00 - val_loss: 1.2700e-04 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.0665e-05 - acc: 0.0000e+00 - val_loss: 1.4647e-04 - val_acc: 0.0000e+00\n",
      "Epoch 275/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.0920e-05 - acc: 0.0000e+00 - val_loss: 6.2339e-05 - val_acc: 0.0000e+00\n",
      "Epoch 276/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.9416e-05 - acc: 0.0000e+00 - val_loss: 2.0858e-04 - val_acc: 0.0000e+00\n",
      "Epoch 277/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.2133e-05 - acc: 0.0000e+00 - val_loss: 7.6705e-05 - val_acc: 0.0000e+00\n",
      "Epoch 278/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.0760e-05 - acc: 0.0000e+00 - val_loss: 2.1226e-04 - val_acc: 0.0000e+00\n",
      "Epoch 279/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.8622e-05 - acc: 0.0000e+00 - val_loss: 2.6111e-04 - val_acc: 0.0000e+00\n",
      "Epoch 280/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.8657e-05 - acc: 0.0000e+00 - val_loss: 1.1995e-04 - val_acc: 0.0000e+00\n",
      "Epoch 281/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.7849e-05 - acc: 0.0000e+00 - val_loss: 1.2580e-04 - val_acc: 0.0000e+00\n",
      "Epoch 282/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.0207e-05 - acc: 0.0000e+00 - val_loss: 1.4661e-04 - val_acc: 0.0000e+00\n",
      "Epoch 283/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.7598e-05 - acc: 0.0000e+00 - val_loss: 1.3652e-04 - val_acc: 0.0000e+00\n",
      "Epoch 284/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.9406e-05 - acc: 0.0000e+00 - val_loss: 8.6884e-05 - val_acc: 0.0000e+00\n",
      "Epoch 285/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.6210e-05 - acc: 0.0000e+00 - val_loss: 1.8194e-04 - val_acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.6365e-05 - acc: 0.0000e+00 - val_loss: 8.0718e-05 - val_acc: 0.0000e+00\n",
      "Epoch 287/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.9760e-05 - acc: 0.0000e+00 - val_loss: 1.2534e-04 - val_acc: 0.0000e+00\n",
      "Epoch 288/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.8396e-05 - acc: 0.0000e+00 - val_loss: 2.4286e-04 - val_acc: 0.0000e+00\n",
      "Epoch 289/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.1069e-05 - acc: 0.0000e+00 - val_loss: 2.5566e-04 - val_acc: 0.0000e+00\n",
      "Epoch 290/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2678e-05 - acc: 0.0000e+00 - val_loss: 1.5909e-04 - val_acc: 0.0000e+00\n",
      "Epoch 291/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.8637e-05 - acc: 0.0000e+00 - val_loss: 2.0567e-04 - val_acc: 0.0000e+00\n",
      "Epoch 292/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.7397e-05 - acc: 0.0000e+00 - val_loss: 1.5724e-04 - val_acc: 0.0000e+00\n",
      "Epoch 293/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.6234e-05 - acc: 0.0000e+00 - val_loss: 1.9301e-04 - val_acc: 0.0000e+00\n",
      "Epoch 294/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.8102e-05 - acc: 0.0000e+00 - val_loss: 1.9282e-04 - val_acc: 0.0000e+00\n",
      "Epoch 295/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.7154e-05 - acc: 0.0000e+00 - val_loss: 1.7692e-04 - val_acc: 0.0000e+00\n",
      "Epoch 296/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.8147e-05 - acc: 0.0000e+00 - val_loss: 1.1294e-04 - val_acc: 0.0000e+00\n",
      "Epoch 297/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.8676e-05 - acc: 0.0000e+00 - val_loss: 8.0000e-05 - val_acc: 0.0000e+00\n",
      "Epoch 298/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.7666e-05 - acc: 0.0000e+00 - val_loss: 1.6637e-04 - val_acc: 0.0000e+00\n",
      "Epoch 299/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.5921e-05 - acc: 0.0000e+00 - val_loss: 6.8973e-05 - val_acc: 0.0000e+00\n",
      "Epoch 300/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.8824e-05 - acc: 0.0000e+00 - val_loss: 2.7745e-04 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x291dc986b38>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=512,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.1,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Result on training set and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_score(model, X_train, y_train, X_test, y_test):\n",
    "    trainScore = model.evaluate(X_train, y_train, verbose=0)\n",
    "    print('Train Score: %.5f MSE (%.2f RMSE)' % (trainScore[0], math.sqrt(trainScore[0])))\n",
    "\n",
    "    testScore = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test Score: %.5f MSE (%.2f RMSE)' % (testScore[0], math.sqrt(testScore[0])))\n",
    "    return trainScore[0], testScore[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.00006 MSE (0.01 RMSE)\n",
      "Test Score: 0.00029 MSE (0.02 RMSE)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5.7438499461150269e-05, 0.00028581792180730253)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_score(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Prediction vs Real results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def percentage_difference(model, X_test, y_test):\n",
    "    percentage_diff=[]\n",
    "\n",
    "    p = model.predict(X_test)\n",
    "    for u in range(len(y_test)): # for each data index in test data\n",
    "        pr = p[u][0] # pr = prediction on day u\n",
    "\n",
    "        percentage_diff.append((pr-y_test[u]/pr)*100)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = percentage_difference(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Plot out prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def denormalize(stock_name, normalized_value):\n",
    "    start = datetime.datetime(2000, 1, 1)\n",
    "    end = datetime.date.today()\n",
    "    df = web.DataReader(stock_name, \"yahoo\", start, end)\n",
    "    \n",
    "    df = df['Adj Close'].values.reshape(-1,1)\n",
    "    normalized_value = normalized_value.reshape(-1,1)\n",
    "    \n",
    "    #return df.shape, p.shape\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    a = min_max_scaler.fit_transform(df)\n",
    "    new = min_max_scaler.inverse_transform(normalized_value)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_result(stock_name, normalized_value_p, normalized_value_y_test):\n",
    "    newp = denormalize(stock_name, normalized_value_p)\n",
    "    newy_test = denormalize(stock_name, normalized_value_y_test)\n",
    "    plt2.plot(newp, color='red', label='Prediction')\n",
    "    plt2.plot(newy_test,color='blue', label='Actual')\n",
    "    plt2.legend(loc='best')\n",
    "    plt2.title('The test result for {}'.format(stock_name))\n",
    "    plt2.xlabel('Days')\n",
    "    plt2.ylabel('Adjusted Close')\n",
    "    plt2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEWCAYAAACjYXoKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1jA3JmZm1jA3JmZm1jA3JmZm1rD/AyJm0Y8w/Eg4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x291dc7bff98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_result(stock_name, p, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Save for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.save('LSTM_Stock_prediction-20170429.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. Fine tune model\n",
    "# 11. Function to load data, train model and see score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stock_name = '^GSPC'\n",
    "seq_len = 22\n",
    "shape = [4, seq_len, 1] # feature, window, output\n",
    "neurons = [128, 128, 32, 1]\n",
    "epochs = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def quick_measure(stock_name, seq_len, d, shape, neurons, epochs):\n",
    "    df = get_stock_data(stock_name)\n",
    "    X_train, y_train, X_test, y_test = load_data(df, seq_len)\n",
    "    model = build_model2(shape, neurons, d)\n",
    "    model.fit(X_train, y_train, batch_size=512, epochs=epochs, validation_split=0.1, verbose=1)\n",
    "    # model.save('LSTM_Stock_prediction-20170429.h5')\n",
    "    trainScore, testScore = model_score(model, X_train, y_train, X_test, y_test)\n",
    "    return trainScore, testScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Fine tune hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.1 Optimial Dropout value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_17 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13702 samples, validate on 1523 samples\n",
      "Epoch 1/300\n",
      "13702/13702 [==============================] - 3s - loss: 0.0125 - acc: 0.0000e+00 - val_loss: 0.0042 - val_acc: 0.0000e+000\n",
      "Epoch 2/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1804e-04 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.5058e-04 - acc: 0.0000e+00 - val_loss: 5.7324e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6854e-04 - acc: 0.0000e+00 - val_loss: 3.3299e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3460e-04 - acc: 0.0000e+00 - val_loss: 2.6412e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4755e-04 - acc: 0.0000e+00 - val_loss: 3.4630e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4434e-04 - acc: 0.0000e+00 - val_loss: 2.6879e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3127e-04 - acc: 0.0000e+00 - val_loss: 2.3772e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2684e-04 - acc: 0.0000e+00 - val_loss: 3.5324e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2834e-04 - acc: 0.0000e+00 - val_loss: 2.5947e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2607e-04 - acc: 0.0000e+00 - val_loss: 2.4281e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1852e-04 - acc: 0.0000e+00 - val_loss: 3.0913e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2246e-04 - acc: 0.0000e+00 - val_loss: 3.9577e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2297e-04 - acc: 0.0000e+00 - val_loss: 2.1565e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1701e-04 - acc: 0.0000e+00 - val_loss: 3.2281e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1031e-04 - acc: 0.0000e+00 - val_loss: 2.1198e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0591e-04 - acc: 0.0000e+00 - val_loss: 2.7185e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1723e-04 - acc: 0.0000e+00 - val_loss: 4.2473e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0234e-04 - acc: 0.0000e+00 - val_loss: 2.0022e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1399e-04 - acc: 0.0000e+00 - val_loss: 3.9876e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2373e-04 - acc: 0.0000e+00 - val_loss: 2.4653e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1187e-04 - acc: 0.0000e+00 - val_loss: 4.2809e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3623e-04 - acc: 0.0000e+00 - val_loss: 2.3799e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0914e-04 - acc: 0.0000e+00 - val_loss: 2.4966e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0163e-04 - acc: 0.0000e+00 - val_loss: 1.7917e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0467e-04 - acc: 0.0000e+00 - val_loss: 2.2979e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0334e-04 - acc: 0.0000e+00 - val_loss: 1.7885e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0457e-04 - acc: 0.0000e+00 - val_loss: 1.8090e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0538e-04 - acc: 0.0000e+00 - val_loss: 1.7517e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1634e-04 - acc: 0.0000e+00 - val_loss: 1.8726e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0294e-04 - acc: 0.0000e+00 - val_loss: 1.7027e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.2477e-05 - acc: 0.0000e+00 - val_loss: 2.0702e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0008e-04 - acc: 0.0000e+00 - val_loss: 2.7150e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1197e-04 - acc: 0.0000e+00 - val_loss: 2.9585e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.9549e-05 - acc: 0.0000e+00 - val_loss: 3.1780e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1413e-04 - acc: 0.0000e+00 - val_loss: 3.9311e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.4315e-05 - acc: 0.0000e+00 - val_loss: 1.6544e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3231e-05 - acc: 0.0000e+00 - val_loss: 1.9984e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.7269e-05 - acc: 0.0000e+00 - val_loss: 2.7382e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2887e-04 - acc: 0.0000e+00 - val_loss: 2.5933e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1389e-04 - acc: 0.0000e+00 - val_loss: 4.4738e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3520e-05 - acc: 0.0000e+00 - val_loss: 2.5505e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.1500e-05 - acc: 0.0000e+00 - val_loss: 1.7357e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.1550e-05 - acc: 0.0000e+00 - val_loss: 1.4911e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.8440e-05 - acc: 0.0000e+00 - val_loss: 1.9152e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1258e-05 - acc: 0.0000e+00 - val_loss: 1.6780e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.9805e-05 - acc: 0.0000e+00 - val_loss: 2.6091e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.2405e-05 - acc: 0.0000e+00 - val_loss: 2.0304e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1249e-05 - acc: 0.0000e+00 - val_loss: 1.6803e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.1792e-05 - acc: 0.0000e+00 - val_loss: 4.1523e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.8591e-05 - acc: 0.0000e+00 - val_loss: 1.4510e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0371e-04 - acc: 0.0000e+00 - val_loss: 1.5422e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.6938e-05 - acc: 0.0000e+00 - val_loss: 2.7897e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.1394e-05 - acc: 0.0000e+00 - val_loss: 1.8889e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.7931e-05 - acc: 0.0000e+00 - val_loss: 1.3869e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0916e-05 - acc: 0.0000e+00 - val_loss: 1.3568e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3131e-05 - acc: 0.0000e+00 - val_loss: 1.4042e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3213e-05 - acc: 0.0000e+00 - val_loss: 1.4419e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.7929e-05 - acc: 0.0000e+00 - val_loss: 1.3178e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9790e-05 - acc: 0.0000e+00 - val_loss: 1.7678e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9061e-05 - acc: 0.0000e+00 - val_loss: 1.3136e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.4272e-05 - acc: 0.0000e+00 - val_loss: 1.3351e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.8430e-05 - acc: 0.0000e+00 - val_loss: 1.3938e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3179e-05 - acc: 0.0000e+00 - val_loss: 1.3191e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0624e-05 - acc: 0.0000e+00 - val_loss: 1.6184e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.5314e-05 - acc: 0.0000e+00 - val_loss: 1.2594e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9620e-05 - acc: 0.0000e+00 - val_loss: 4.9358e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1658e-05 - acc: 0.0000e+00 - val_loss: 1.2793e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9868e-05 - acc: 0.0000e+00 - val_loss: 1.7053e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0058e-05 - acc: 0.0000e+00 - val_loss: 2.7771e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.6162e-05 - acc: 0.0000e+00 - val_loss: 1.5282e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.0946e-05 - acc: 0.0000e+00 - val_loss: 1.4062e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.5089e-05 - acc: 0.0000e+00 - val_loss: 1.2988e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4359e-05 - acc: 0.0000e+00 - val_loss: 2.0560e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4188e-05 - acc: 0.0000e+00 - val_loss: 1.6070e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0277e-05 - acc: 0.0000e+00 - val_loss: 1.5223e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.8316e-05 - acc: 0.0000e+00 - val_loss: 1.2364e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.5891e-05 - acc: 0.0000e+00 - val_loss: 1.9934e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.6773e-05 - acc: 0.0000e+00 - val_loss: 1.1844e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7297e-05 - acc: 0.0000e+00 - val_loss: 1.1918e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1163e-05 - acc: 0.0000e+00 - val_loss: 1.5928e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8433e-05 - acc: 0.0000e+00 - val_loss: 2.8398e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9775e-05 - acc: 0.0000e+00 - val_loss: 1.7573e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0252e-05 - acc: 0.0000e+00 - val_loss: 1.1541e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7584e-05 - acc: 0.0000e+00 - val_loss: 1.1207e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.8474e-05 - acc: 0.0000e+00 - val_loss: 1.1507e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1574e-05 - acc: 0.0000e+00 - val_loss: 1.3375e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.9767e-05 - acc: 0.0000e+00 - val_loss: 4.0851e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2278e-05 - acc: 0.0000e+00 - val_loss: 1.1002e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7948e-05 - acc: 0.0000e+00 - val_loss: 1.7005e-04 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4060e-05 - acc: 0.0000e+00 - val_loss: 1.0776e-04 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.5775e-05 - acc: 0.0000e+00 - val_loss: 5.0202e-04 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.5600e-05 - acc: 0.0000e+00 - val_loss: 1.0738e-04 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.3064e-05 - acc: 0.0000e+00 - val_loss: 1.1468e-04 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4515e-05 - acc: 0.0000e+00 - val_loss: 1.0644e-04 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1642e-05 - acc: 0.0000e+00 - val_loss: 1.2517e-04 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4470e-05 - acc: 0.0000e+00 - val_loss: 3.9936e-04 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4401e-05 - acc: 0.0000e+00 - val_loss: 1.2387e-04 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0160e-05 - acc: 0.0000e+00 - val_loss: 1.1937e-04 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6937e-05 - acc: 0.0000e+00 - val_loss: 1.2306e-04 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7407e-05 - acc: 0.0000e+00 - val_loss: 1.2269e-04 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.8668e-05 - acc: 0.0000e+00 - val_loss: 1.0703e-04 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4473e-05 - acc: 0.0000e+00 - val_loss: 1.0153e-04 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3955e-05 - acc: 0.0000e+00 - val_loss: 9.8830e-05 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13702/13702 [==============================] - 1s - loss: 6.1786e-05 - acc: 0.0000e+00 - val_loss: 2.3667e-04 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4980e-05 - acc: 0.0000e+00 - val_loss: 1.2261e-04 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.8195e-05 - acc: 0.0000e+00 - val_loss: 1.3106e-04 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2237e-05 - acc: 0.0000e+00 - val_loss: 1.2377e-04 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.1468e-05 - acc: 0.0000e+00 - val_loss: 1.0991e-04 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7530e-05 - acc: 0.0000e+00 - val_loss: 1.1433e-04 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.1319e-05 - acc: 0.0000e+00 - val_loss: 9.6058e-05 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2212e-05 - acc: 0.0000e+00 - val_loss: 9.4320e-05 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.5771e-05 - acc: 0.0000e+00 - val_loss: 1.6074e-04 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.8031e-05 - acc: 0.0000e+00 - val_loss: 1.2573e-04 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.1193e-05 - acc: 0.0000e+00 - val_loss: 9.4208e-05 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7699e-05 - acc: 0.0000e+00 - val_loss: 2.1584e-04 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7743e-05 - acc: 0.0000e+00 - val_loss: 9.3458e-05 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4026e-05 - acc: 0.0000e+00 - val_loss: 1.2577e-04 - val_acc: 0.0000e+000\n",
      "Epoch 119/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8184e-05 - acc: 0.0000e+00 - val_loss: 9.8625e-05 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.1009e-05 - acc: 0.0000e+00 - val_loss: 9.4831e-05 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1501e-05 - acc: 0.0000e+00 - val_loss: 1.4569e-04 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2453e-05 - acc: 0.0000e+00 - val_loss: 1.1958e-04 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8398e-05 - acc: 0.0000e+00 - val_loss: 2.0335e-04 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.5667e-05 - acc: 0.0000e+00 - val_loss: 9.9490e-05 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8007e-05 - acc: 0.0000e+00 - val_loss: 2.0423e-04 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2200e-05 - acc: 0.0000e+00 - val_loss: 9.0454e-05 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.4705e-05 - acc: 0.0000e+00 - val_loss: 8.8123e-05 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.5682e-05 - acc: 0.0000e+00 - val_loss: 8.8921e-05 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.7765e-05 - acc: 0.0000e+00 - val_loss: 1.0062e-04 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.5074e-05 - acc: 0.0000e+00 - val_loss: 1.4419e-04 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.6703e-05 - acc: 0.0000e+00 - val_loss: 1.0327e-04 - val_acc: 0.0000e+00\n",
      "Epoch 132/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0477e-05 - acc: 0.0000e+00 - val_loss: 1.2665e-04 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3568e-05 - acc: 0.0000e+00 - val_loss: 1.2759e-04 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8359e-05 - acc: 0.0000e+00 - val_loss: 1.2939e-04 - val_acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.7925e-05 - acc: 0.0000e+00 - val_loss: 8.4155e-05 - val_acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3628e-05 - acc: 0.0000e+00 - val_loss: 8.6437e-05 - val_acc: 0.0000e+00\n",
      "Epoch 137/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.6880e-05 - acc: 0.0000e+00 - val_loss: 9.7719e-05 - val_acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.5505e-05 - acc: 0.0000e+00 - val_loss: 1.7345e-04 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3116e-05 - acc: 0.0000e+00 - val_loss: 1.1106e-04 - val_acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.6271e-05 - acc: 0.0000e+00 - val_loss: 2.3537e-04 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9915e-05 - acc: 0.0000e+00 - val_loss: 8.6074e-05 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.2216e-05 - acc: 0.0000e+00 - val_loss: 9.3876e-05 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.6524e-05 - acc: 0.0000e+00 - val_loss: 8.8528e-05 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.4530e-05 - acc: 0.0000e+00 - val_loss: 8.6354e-05 - val_acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.4430e-05 - acc: 0.0000e+00 - val_loss: 8.5768e-05 - val_acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8469e-05 - acc: 0.0000e+00 - val_loss: 8.1132e-05 - val_acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.1446e-05 - acc: 0.0000e+00 - val_loss: 8.1386e-05 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8661e-05 - acc: 0.0000e+00 - val_loss: 3.1817e-04 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3277e-05 - acc: 0.0000e+00 - val_loss: 1.0148e-04 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9854e-05 - acc: 0.0000e+00 - val_loss: 1.3226e-04 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.2323e-05 - acc: 0.0000e+00 - val_loss: 8.9075e-05 - val_acc: 0.0000e+00\n",
      "Epoch 152/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.2540e-05 - acc: 0.0000e+00 - val_loss: 2.1459e-04 - val_acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.8624e-05 - acc: 0.0000e+00 - val_loss: 1.1674e-04 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.7031e-05 - acc: 0.0000e+00 - val_loss: 1.0599e-04 - val_acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3968e-05 - acc: 0.0000e+00 - val_loss: 1.1632e-04 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9123e-05 - acc: 0.0000e+00 - val_loss: 2.2355e-04 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.7779e-05 - acc: 0.0000e+00 - val_loss: 7.7570e-05 - val_acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.4991e-05 - acc: 0.0000e+00 - val_loss: 9.6279e-05 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5642e-05 - acc: 0.0000e+00 - val_loss: 1.3818e-04 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8025e-05 - acc: 0.0000e+00 - val_loss: 1.0016e-04 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.3952e-05 - acc: 0.0000e+00 - val_loss: 8.8537e-05 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.4084e-05 - acc: 0.0000e+00 - val_loss: 9.0497e-05 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.0225e-05 - acc: 0.0000e+00 - val_loss: 8.4298e-05 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6301e-05 - acc: 0.0000e+00 - val_loss: 1.5655e-04 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.1345e-05 - acc: 0.0000e+00 - val_loss: 8.2517e-05 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9469e-05 - acc: 0.0000e+00 - val_loss: 1.1771e-04 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.0253e-05 - acc: 0.0000e+00 - val_loss: 7.3709e-05 - val_acc: 0.0000e+00\n",
      "Epoch 168/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3160e-05 - acc: 0.0000e+00 - val_loss: 1.1318e-04 - val_acc: 0.0000e+0000e+0\n",
      "Epoch 169/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0338e-05 - acc: 0.0000e+00 - val_loss: 7.5163e-05 - val_acc: 0.0000e+00\n",
      "Epoch 170/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5219e-05 - acc: 0.0000e+00 - val_loss: 7.6992e-05 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.7646e-05 - acc: 0.0000e+00 - val_loss: 1.3472e-04 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.1729e-05 - acc: 0.0000e+00 - val_loss: 1.4647e-04 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5697e-05 - acc: 0.0000e+00 - val_loss: 1.0430e-04 - val_acc: 0.0000e+00\n",
      "Epoch 174/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9417e-05 - acc: 0.0000e+00 - val_loss: 1.0401e-04 - val_acc: 0.0000e+00\n",
      "Epoch 175/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.3279e-05 - acc: 0.0000e+00 - val_loss: 7.7741e-05 - val_acc: 0.0000e+00\n",
      "Epoch 176/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.3057e-05 - acc: 0.0000e+00 - val_loss: 2.2752e-04 - val_acc: 0.0000e+00\n",
      "Epoch 177/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3651e-05 - acc: 0.0000e+00 - val_loss: 8.5790e-05 - val_acc: 0.0000e+00\n",
      "Epoch 178/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.4848e-05 - acc: 0.0000e+00 - val_loss: 8.4086e-05 - val_acc: 0.0000e+00\n",
      "Epoch 179/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2553e-05 - acc: 0.0000e+00 - val_loss: 7.3760e-05 - val_acc: 0.0000e+00\n",
      "Epoch 180/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0531e-05 - acc: 0.0000e+00 - val_loss: 8.0072e-05 - val_acc: 0.0000e+00\n",
      "Epoch 181/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5025e-05 - acc: 0.0000e+00 - val_loss: 7.7309e-05 - val_acc: 0.0000e+00\n",
      "Epoch 182/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1298e-05 - acc: 0.0000e+00 - val_loss: 1.4066e-04 - val_acc: 0.0000e+00\n",
      "Epoch 183/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2260e-05 - acc: 0.0000e+00 - val_loss: 8.5297e-05 - val_acc: 0.0000e+00\n",
      "Epoch 184/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1828e-05 - acc: 0.0000e+00 - val_loss: 8.2775e-05 - val_acc: 0.0000e+00\n",
      "Epoch 185/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2156e-05 - acc: 0.0000e+00 - val_loss: 7.7451e-05 - val_acc: 0.0000e+00\n",
      "Epoch 186/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6815e-05 - acc: 0.0000e+00 - val_loss: 7.2587e-05 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2749e-05 - acc: 0.0000e+00 - val_loss: 8.9476e-05 - val_acc: 0.0000e+00\n",
      "Epoch 188/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5322e-05 - acc: 0.0000e+00 - val_loss: 9.5393e-05 - val_acc: 0.0000e+00\n",
      "Epoch 189/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.3667e-05 - acc: 0.0000e+00 - val_loss: 7.1974e-05 - val_acc: 0.0000e+00\n",
      "Epoch 190/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.3043e-05 - acc: 0.0000e+00 - val_loss: 8.0163e-05 - val_acc: 0.0000e+000\n",
      "Epoch 191/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0775e-05 - acc: 0.0000e+00 - val_loss: 7.2108e-05 - val_acc: 0.0000e+00\n",
      "Epoch 192/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1936e-05 - acc: 0.0000e+00 - val_loss: 8.0526e-05 - val_acc: 0.0000e+00\n",
      "Epoch 193/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.9858e-05 - acc: 0.0000e+00 - val_loss: 7.6074e-05 - val_acc: 0.0000e+00\n",
      "Epoch 194/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0554e-05 - acc: 0.0000e+00 - val_loss: 7.5793e-05 - val_acc: 0.0000e+00\n",
      "Epoch 195/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0123e-05 - acc: 0.0000e+00 - val_loss: 1.4093e-04 - val_acc: 0.0000e+00\n",
      "Epoch 196/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1319e-05 - acc: 0.0000e+00 - val_loss: 7.1386e-05 - val_acc: 0.0000e+00\n",
      "Epoch 197/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.8639e-05 - acc: 0.0000e+00 - val_loss: 8.0636e-05 - val_acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7618e-05 - acc: 0.0000e+00 - val_loss: 9.2821e-05 - val_acc: 0.0000e+00\n",
      "Epoch 199/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.3011e-05 - acc: 0.0000e+00 - val_loss: 7.5260e-05 - val_acc: 0.0000e+00\n",
      "Epoch 200/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0749e-05 - acc: 0.0000e+00 - val_loss: 8.2678e-05 - val_acc: 0.0000e+00\n",
      "Epoch 201/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.3301e-05 - acc: 0.0000e+00 - val_loss: 1.2248e-04 - val_acc: 0.0000e+00\n",
      "Epoch 202/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1240e-05 - acc: 0.0000e+00 - val_loss: 8.5474e-05 - val_acc: 0.0000e+00\n",
      "Epoch 203/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0708e-05 - acc: 0.0000e+00 - val_loss: 1.0901e-04 - val_acc: 0.0000e+00\n",
      "Epoch 204/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8734e-05 - acc: 0.0000e+00 - val_loss: 1.3232e-04 - val_acc: 0.0000e+00\n",
      "Epoch 205/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0359e-05 - acc: 0.0000e+00 - val_loss: 7.5599e-05 - val_acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1969e-05 - acc: 0.0000e+00 - val_loss: 7.0787e-05 - val_acc: 0.0000e+00\n",
      "Epoch 207/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0159e-05 - acc: 0.0000e+00 - val_loss: 7.3812e-05 - val_acc: 0.0000e+00\n",
      "Epoch 208/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6949e-05 - acc: 0.0000e+00 - val_loss: 9.3191e-05 - val_acc: 0.0000e+00\n",
      "Epoch 209/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0511e-05 - acc: 0.0000e+00 - val_loss: 8.2620e-05 - val_acc: 0.0000e+00\n",
      "Epoch 210/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0671e-05 - acc: 0.0000e+00 - val_loss: 8.2122e-05 - val_acc: 0.0000e+00\n",
      "Epoch 211/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7721e-05 - acc: 0.0000e+00 - val_loss: 8.8690e-05 - val_acc: 0.0000e+00\n",
      "Epoch 212/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6845e-05 - acc: 0.0000e+00 - val_loss: 1.0747e-04 - val_acc: 0.0000e+00\n",
      "Epoch 213/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7450e-05 - acc: 0.0000e+00 - val_loss: 1.1586e-04 - val_acc: 0.0000e+00\n",
      "Epoch 214/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.9962e-05 - acc: 0.0000e+00 - val_loss: 1.3950e-04 - val_acc: 0.0000e+00\n",
      "Epoch 215/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.0234e-05 - acc: 0.0000e+00 - val_loss: 8.8173e-05 - val_acc: 0.0000e+00\n",
      "Epoch 216/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5143e-05 - acc: 0.0000e+00 - val_loss: 7.4419e-05 - val_acc: 0.0000e+00\n",
      "Epoch 217/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13702/13702 [==============================] - 1s - loss: 3.9481e-05 - acc: 0.0000e+00 - val_loss: 8.4440e-05 - val_acc: 0.0000e+00\n",
      "Epoch 218/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7271e-05 - acc: 0.0000e+00 - val_loss: 7.6987e-05 - val_acc: 0.0000e+00\n",
      "Epoch 219/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8756e-05 - acc: 0.0000e+00 - val_loss: 7.4955e-05 - val_acc: 0.0000e+00\n",
      "Epoch 220/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6757e-05 - acc: 0.0000e+00 - val_loss: 7.2061e-05 - val_acc: 0.0000e+00\n",
      "Epoch 221/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7897e-05 - acc: 0.0000e+00 - val_loss: 8.6368e-05 - val_acc: 0.0000e+00\n",
      "Epoch 222/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0011e-05 - acc: 0.0000e+00 - val_loss: 6.7412e-05 - val_acc: 0.0000e+00\n",
      "Epoch 223/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6490e-05 - acc: 0.0000e+00 - val_loss: 1.0807e-04 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1692e-05 - acc: 0.0000e+00 - val_loss: 1.4258e-04 - val_acc: 0.0000e+00\n",
      "Epoch 225/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2036e-05 - acc: 0.0000e+00 - val_loss: 1.8816e-04 - val_acc: 0.0000e+00\n",
      "Epoch 226/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0426e-05 - acc: 0.0000e+00 - val_loss: 7.8484e-05 - val_acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6608e-05 - acc: 0.0000e+00 - val_loss: 9.1184e-05 - val_acc: 0.0000e+00\n",
      "Epoch 228/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1540e-05 - acc: 0.0000e+00 - val_loss: 8.1842e-05 - val_acc: 0.0000e+00\n",
      "Epoch 229/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1842e-05 - acc: 0.0000e+00 - val_loss: 1.1252e-04 - val_acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6730e-05 - acc: 0.0000e+00 - val_loss: 7.4458e-05 - val_acc: 0.0000e+00\n",
      "Epoch 231/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5798e-05 - acc: 0.0000e+00 - val_loss: 7.8105e-05 - val_acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7380e-05 - acc: 0.0000e+00 - val_loss: 6.7593e-05 - val_acc: 0.0000e+00\n",
      "Epoch 233/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8452e-05 - acc: 0.0000e+00 - val_loss: 7.6469e-05 - val_acc: 0.0000e+00\n",
      "Epoch 234/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7764e-05 - acc: 0.0000e+00 - val_loss: 1.2494e-04 - val_acc: 0.0000e+00\n",
      "Epoch 235/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7386e-05 - acc: 0.0000e+00 - val_loss: 7.5680e-05 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.4086e-05 - acc: 0.0000e+00 - val_loss: 1.2589e-04 - val_acc: 0.0000e+00\n",
      "Epoch 237/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0590e-05 - acc: 0.0000e+00 - val_loss: 8.1866e-05 - val_acc: 0.0000e+00\n",
      "Epoch 238/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0282e-05 - acc: 0.0000e+00 - val_loss: 7.8637e-05 - val_acc: 0.0000e+00\n",
      "Epoch 239/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7946e-05 - acc: 0.0000e+00 - val_loss: 1.2135e-04 - val_acc: 0.0000e+00\n",
      "Epoch 240/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6448e-05 - acc: 0.0000e+00 - val_loss: 1.0066e-04 - val_acc: 0.0000e+00\n",
      "Epoch 241/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7334e-05 - acc: 0.0000e+00 - val_loss: 6.7278e-05 - val_acc: 0.0000e+00\n",
      "Epoch 242/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5057e-05 - acc: 0.0000e+00 - val_loss: 6.4258e-05 - val_acc: 0.0000e+00\n",
      "Epoch 243/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3849e-05 - acc: 0.0000e+00 - val_loss: 6.7222e-05 - val_acc: 0.0000e+00\n",
      "Epoch 244/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.9607e-05 - acc: 0.0000e+00 - val_loss: 8.1532e-05 - val_acc: 0.0000e+00\n",
      "Epoch 245/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7583e-05 - acc: 0.0000e+00 - val_loss: 6.4113e-05 - val_acc: 0.0000e+00\n",
      "Epoch 246/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7323e-05 - acc: 0.0000e+00 - val_loss: 6.3504e-05 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7508e-05 - acc: 0.0000e+00 - val_loss: 7.6140e-05 - val_acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0294e-05 - acc: 0.0000e+00 - val_loss: 1.5945e-04 - val_acc: 0.0000e+000\n",
      "Epoch 249/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8781e-05 - acc: 0.0000e+00 - val_loss: 1.3159e-04 - val_acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4642e-05 - acc: 0.0000e+00 - val_loss: 6.6366e-05 - val_acc: 0.0000e+00\n",
      "Epoch 251/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5554e-05 - acc: 0.0000e+00 - val_loss: 8.8685e-05 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3626e-05 - acc: 0.0000e+00 - val_loss: 8.5942e-05 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3702e-05 - acc: 0.0000e+00 - val_loss: 6.8794e-05 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4759e-05 - acc: 0.0000e+00 - val_loss: 8.6218e-05 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6676e-05 - acc: 0.0000e+00 - val_loss: 7.7165e-05 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7643e-05 - acc: 0.0000e+00 - val_loss: 1.2712e-04 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.9754e-05 - acc: 0.0000e+00 - val_loss: 1.0928e-04 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7634e-05 - acc: 0.0000e+00 - val_loss: 6.2637e-05 - val_acc: 0.0000e+00\n",
      "Epoch 259/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4605e-05 - acc: 0.0000e+00 - val_loss: 8.5917e-05 - val_acc: 0.0000e+00\n",
      "Epoch 260/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4135e-05 - acc: 0.0000e+00 - val_loss: 1.0912e-04 - val_acc: 0.0000e+00\n",
      "Epoch 261/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0075e-05 - acc: 0.0000e+00 - val_loss: 1.3387e-04 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0382e-05 - acc: 0.0000e+00 - val_loss: 6.0703e-05 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4520e-05 - acc: 0.0000e+00 - val_loss: 6.2738e-05 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4062e-05 - acc: 0.0000e+00 - val_loss: 6.8128e-05 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5214e-05 - acc: 0.0000e+00 - val_loss: 1.0929e-04 - val_acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3945e-05 - acc: 0.0000e+00 - val_loss: 6.0944e-05 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4340e-05 - acc: 0.0000e+00 - val_loss: 9.2843e-05 - val_acc: 0.0000e+00\n",
      "Epoch 268/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5414e-05 - acc: 0.0000e+00 - val_loss: 9.1970e-05 - val_acc: 0.0000e+00\n",
      "Epoch 269/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5919e-05 - acc: 0.0000e+00 - val_loss: 6.6458e-05 - val_acc: 0.0000e+00\n",
      "Epoch 270/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4528e-05 - acc: 0.0000e+00 - val_loss: 1.1939e-04 - val_acc: 0.0000e+00\n",
      "Epoch 271/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.2757e-05 - acc: 0.0000e+00 - val_loss: 6.1442e-05 - val_acc: 0.0000e+00\n",
      "Epoch 272/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.2306e-05 - acc: 0.0000e+00 - val_loss: 8.4997e-05 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4690e-05 - acc: 0.0000e+00 - val_loss: 6.1618e-05 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.1589e-05 - acc: 0.0000e+00 - val_loss: 6.4427e-05 - val_acc: 0.0000e+00\n",
      "Epoch 275/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5297e-05 - acc: 0.0000e+00 - val_loss: 5.9463e-05 - val_acc: 0.0000e+00\n",
      "Epoch 276/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.1783e-05 - acc: 0.0000e+00 - val_loss: 7.4361e-05 - val_acc: 0.0000e+00\n",
      "Epoch 277/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4933e-05 - acc: 0.0000e+00 - val_loss: 9.4194e-05 - val_acc: 0.0000e+00\n",
      "Epoch 278/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.2558e-05 - acc: 0.0000e+00 - val_loss: 6.1318e-05 - val_acc: 0.0000e+00\n",
      "Epoch 279/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8294e-05 - acc: 0.0000e+00 - val_loss: 8.8355e-05 - val_acc: 0.0000e+00\n",
      "Epoch 280/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3186e-05 - acc: 0.0000e+00 - val_loss: 5.9376e-05 - val_acc: 0.0000e+00\n",
      "Epoch 281/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3565e-05 - acc: 0.0000e+00 - val_loss: 6.9707e-05 - val_acc: 0.0000e+00\n",
      "Epoch 282/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3402e-05 - acc: 0.0000e+00 - val_loss: 9.9120e-05 - val_acc: 0.0000e+00\n",
      "Epoch 283/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.2211e-05 - acc: 0.0000e+00 - val_loss: 8.1142e-05 - val_acc: 0.0000e+00\n",
      "Epoch 284/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5021e-05 - acc: 0.0000e+00 - val_loss: 1.0247e-04 - val_acc: 0.0000e+00\n",
      "Epoch 285/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7491e-05 - acc: 0.0000e+00 - val_loss: 9.0636e-05 - val_acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5320e-05 - acc: 0.0000e+00 - val_loss: 1.1155e-04 - val_acc: 0.0000e+00\n",
      "Epoch 287/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4860e-05 - acc: 0.0000e+00 - val_loss: 6.0941e-05 - val_acc: 0.0000e+00\n",
      "Epoch 288/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3913e-05 - acc: 0.0000e+00 - val_loss: 6.2435e-05 - val_acc: 0.0000e+00\n",
      "Epoch 289/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3048e-05 - acc: 0.0000e+00 - val_loss: 6.6532e-05 - val_acc: 0.0000e+00\n",
      "Epoch 290/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.2583e-05 - acc: 0.0000e+00 - val_loss: 6.3181e-05 - val_acc: 0.0000e+00\n",
      "Epoch 291/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.0371e-05 - acc: 0.0000e+00 - val_loss: 6.9182e-05 - val_acc: 0.0000e+00\n",
      "Epoch 292/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7278e-05 - acc: 0.0000e+00 - val_loss: 5.7825e-05 - val_acc: 0.0000e+00\n",
      "Epoch 293/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7501e-05 - acc: 0.0000e+00 - val_loss: 6.0554e-05 - val_acc: 0.0000e+00\n",
      "Epoch 294/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5414e-05 - acc: 0.0000e+00 - val_loss: 6.7766e-05 - val_acc: 0.0000e+00\n",
      "Epoch 295/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3548e-05 - acc: 0.0000e+00 - val_loss: 1.3253e-04 - val_acc: 0.0000e+00\n",
      "Epoch 296/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4441e-05 - acc: 0.0000e+00 - val_loss: 2.0411e-04 - val_acc: 0.0000e+00\n",
      "Epoch 297/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8004e-05 - acc: 0.0000e+00 - val_loss: 6.6944e-05 - val_acc: 0.0000e+00\n",
      "Epoch 298/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.1322e-05 - acc: 0.0000e+00 - val_loss: 8.6315e-05 - val_acc: 0.0000e+00\n",
      "Epoch 299/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7320e-05 - acc: 0.0000e+00 - val_loss: 1.9673e-04 - val_acc: 0.0000e+00\n",
      "Epoch 300/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2219e-05 - acc: 0.0000e+00 - val_loss: 8.7802e-05 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00002 MSE (0.00 RMSE)\n",
      "Test Score: 0.00009 MSE (0.01 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_19 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_20 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13702 samples, validate on 1523 samples\n",
      "Epoch 1/300\n",
      "13702/13702 [==============================] - 3s - loss: 0.0119 - acc: 0.0000e+00 - val_loss: 0.0056 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9329e-04 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.1191e-04 - acc: 0.0000e+00 - val_loss: 7.3650e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.2691e-04 - acc: 0.0000e+00 - val_loss: 3.9015e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.1393e-04 - acc: 0.0000e+00 - val_loss: 3.4606e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9696e-04 - acc: 0.0000e+00 - val_loss: 3.3240e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.0872e-04 - acc: 0.0000e+00 - val_loss: 6.2244e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8165e-04 - acc: 0.0000e+00 - val_loss: 4.1681e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8759e-04 - acc: 0.0000e+00 - val_loss: 2.3860e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8010e-04 - acc: 0.0000e+00 - val_loss: 2.9187e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6749e-04 - acc: 0.0000e+00 - val_loss: 2.2259e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6794e-04 - acc: 0.0000e+00 - val_loss: 2.7659e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7119e-04 - acc: 0.0000e+00 - val_loss: 3.4938e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7055e-04 - acc: 0.0000e+00 - val_loss: 2.5959e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6964e-04 - acc: 0.0000e+00 - val_loss: 2.1851e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7247e-04 - acc: 0.0000e+00 - val_loss: 2.7470e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8090e-04 - acc: 0.0000e+00 - val_loss: 2.5204e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6944e-04 - acc: 0.0000e+00 - val_loss: 3.0941e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6486e-04 - acc: 0.0000e+00 - val_loss: 2.9131e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13702/13702 [==============================] - 1s - loss: 1.5562e-04 - acc: 0.0000e+00 - val_loss: 6.4125e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6698e-04 - acc: 0.0000e+00 - val_loss: 3.1872e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7413e-04 - acc: 0.0000e+00 - val_loss: 3.2942e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4956e-04 - acc: 0.0000e+00 - val_loss: 2.0891e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5216e-04 - acc: 0.0000e+00 - val_loss: 5.3458e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4924e-04 - acc: 0.0000e+00 - val_loss: 1.9061e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5519e-04 - acc: 0.0000e+00 - val_loss: 3.3778e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5656e-04 - acc: 0.0000e+00 - val_loss: 1.9585e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4528e-04 - acc: 0.0000e+00 - val_loss: 2.6235e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4306e-04 - acc: 0.0000e+00 - val_loss: 2.9175e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5168e-04 - acc: 0.0000e+00 - val_loss: 4.3717e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6246e-04 - acc: 0.0000e+00 - val_loss: 2.1126e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3043e-04 - acc: 0.0000e+00 - val_loss: 1.9429e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4148e-04 - acc: 0.0000e+00 - val_loss: 8.9457e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6039e-04 - acc: 0.0000e+00 - val_loss: 2.5770e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4683e-04 - acc: 0.0000e+00 - val_loss: 2.3320e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4566e-04 - acc: 0.0000e+00 - val_loss: 1.9916e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4164e-04 - acc: 0.0000e+00 - val_loss: 1.7462e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3509e-04 - acc: 0.0000e+00 - val_loss: 8.0245e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4891e-04 - acc: 0.0000e+00 - val_loss: 1.8696e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3936e-04 - acc: 0.0000e+00 - val_loss: 2.0472e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2747e-04 - acc: 0.0000e+00 - val_loss: 2.3549e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3513e-04 - acc: 0.0000e+00 - val_loss: 2.0077e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1995e-04 - acc: 0.0000e+00 - val_loss: 1.8170e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2854e-04 - acc: 0.0000e+00 - val_loss: 1.7043e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2401e-04 - acc: 0.0000e+00 - val_loss: 1.6290e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3657e-04 - acc: 0.0000e+00 - val_loss: 2.6007e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2806e-04 - acc: 0.0000e+00 - val_loss: 2.5595e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2807e-04 - acc: 0.0000e+00 - val_loss: 1.6139e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3190e-04 - acc: 0.0000e+00 - val_loss: 5.6456e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4592e-04 - acc: 0.0000e+00 - val_loss: 6.4682e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2683e-04 - acc: 0.0000e+00 - val_loss: 1.7727e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1944e-04 - acc: 0.0000e+00 - val_loss: 3.9883e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1767e-04 - acc: 0.0000e+00 - val_loss: 1.6873e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1247e-04 - acc: 0.0000e+00 - val_loss: 2.7337e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2147e-04 - acc: 0.0000e+00 - val_loss: 1.9300e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3180e-04 - acc: 0.0000e+00 - val_loss: 3.2518e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1381e-04 - acc: 0.0000e+00 - val_loss: 1.6086e-04 - val_acc: 0.0000e+000\n",
      "Epoch 58/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0861e-04 - acc: 0.0000e+00 - val_loss: 2.3723e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1677e-04 - acc: 0.0000e+00 - val_loss: 2.9337e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2100e-04 - acc: 0.0000e+00 - val_loss: 2.2275e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0981e-04 - acc: 0.0000e+00 - val_loss: 1.4173e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0934e-04 - acc: 0.0000e+00 - val_loss: 1.5673e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0645e-04 - acc: 0.0000e+00 - val_loss: 4.4192e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3360e-04 - acc: 0.0000e+00 - val_loss: 3.0335e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0373e-04 - acc: 0.0000e+00 - val_loss: 1.4227e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.8791e-05 - acc: 0.0000e+00 - val_loss: 1.3383e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0771e-04 - acc: 0.0000e+00 - val_loss: 1.3564e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0725e-04 - acc: 0.0000e+00 - val_loss: 1.3180e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0281e-04 - acc: 0.0000e+00 - val_loss: 2.4815e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1194e-04 - acc: 0.0000e+00 - val_loss: 1.6667e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0393e-04 - acc: 0.0000e+00 - val_loss: 1.3261e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0219e-04 - acc: 0.0000e+00 - val_loss: 1.2947e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0024e-04 - acc: 0.0000e+00 - val_loss: 1.2918e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0023e-04 - acc: 0.0000e+00 - val_loss: 2.9635e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0363e-04 - acc: 0.0000e+00 - val_loss: 1.8837e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.9489e-05 - acc: 0.0000e+00 - val_loss: 1.5120e-04 - val_acc: 0.0000e+0000e\n",
      "Epoch 77/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.4651e-05 - acc: 0.0000e+00 - val_loss: 1.7162e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.6063e-05 - acc: 0.0000e+00 - val_loss: 1.5722e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0355e-04 - acc: 0.0000e+00 - val_loss: 1.2651e-04 - val_acc: 0.0000e+0000e\n",
      "Epoch 80/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.6740e-05 - acc: 0.0000e+00 - val_loss: 1.9936e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.6821e-05 - acc: 0.0000e+00 - val_loss: 3.3484e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0375e-04 - acc: 0.0000e+00 - val_loss: 1.2630e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0363e-04 - acc: 0.0000e+00 - val_loss: 1.4048e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0136e-04 - acc: 0.0000e+00 - val_loss: 1.3304e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.2367e-05 - acc: 0.0000e+00 - val_loss: 1.5024e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.1556e-05 - acc: 0.0000e+00 - val_loss: 1.9688e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.4373e-05 - acc: 0.0000e+00 - val_loss: 1.3368e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3195e-05 - acc: 0.0000e+00 - val_loss: 1.3044e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.8044e-05 - acc: 0.0000e+00 - val_loss: 1.7294e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.9616e-05 - acc: 0.0000e+00 - val_loss: 1.2766e-04 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0064e-04 - acc: 0.0000e+00 - val_loss: 2.7610e-04 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0367e-04 - acc: 0.0000e+00 - val_loss: 1.1928e-04 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.4559e-05 - acc: 0.0000e+00 - val_loss: 2.3508e-04 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.7259e-05 - acc: 0.0000e+00 - val_loss: 1.1885e-04 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1769e-05 - acc: 0.0000e+00 - val_loss: 1.1800e-04 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3196e-05 - acc: 0.0000e+00 - val_loss: 1.2475e-04 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.2697e-05 - acc: 0.0000e+00 - val_loss: 1.3474e-04 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.5655e-05 - acc: 0.0000e+00 - val_loss: 1.2235e-04 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8750e-05 - acc: 0.0000e+00 - val_loss: 1.3564e-04 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8939e-05 - acc: 0.0000e+00 - val_loss: 1.1622e-04 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9343e-05 - acc: 0.0000e+00 - val_loss: 1.2561e-04 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.5494e-05 - acc: 0.0000e+00 - val_loss: 1.1863e-04 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0968e-05 - acc: 0.0000e+00 - val_loss: 1.2094e-04 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9299e-05 - acc: 0.0000e+00 - val_loss: 2.6767e-04 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1161e-05 - acc: 0.0000e+00 - val_loss: 1.5001e-04 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.3458e-05 - acc: 0.0000e+00 - val_loss: 1.2214e-04 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1224e-05 - acc: 0.0000e+00 - val_loss: 2.9244e-04 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.7165e-05 - acc: 0.0000e+00 - val_loss: 1.1771e-04 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8073e-05 - acc: 0.0000e+00 - val_loss: 1.2206e-04 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4322e-05 - acc: 0.0000e+00 - val_loss: 1.1852e-04 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.6335e-05 - acc: 0.0000e+00 - val_loss: 1.4050e-04 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0061e-05 - acc: 0.0000e+00 - val_loss: 2.0121e-04 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.5407e-05 - acc: 0.0000e+00 - val_loss: 1.6877e-04 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.5449e-05 - acc: 0.0000e+00 - val_loss: 2.5030e-04 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.6449e-05 - acc: 0.0000e+00 - val_loss: 1.7870e-04 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0849e-05 - acc: 0.0000e+00 - val_loss: 2.3038e-04 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0409e-05 - acc: 0.0000e+00 - val_loss: 2.4584e-04 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.5467e-05 - acc: 0.0000e+00 - val_loss: 2.5907e-04 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0237e-05 - acc: 0.0000e+00 - val_loss: 1.1274e-04 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0812e-05 - acc: 0.0000e+00 - val_loss: 1.1094e-04 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.6055e-05 - acc: 0.0000e+00 - val_loss: 1.1444e-04 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.7686e-05 - acc: 0.0000e+00 - val_loss: 2.2315e-04 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1818e-05 - acc: 0.0000e+00 - val_loss: 1.6184e-04 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.9144e-05 - acc: 0.0000e+00 - val_loss: 1.4485e-04 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1295e-05 - acc: 0.0000e+00 - val_loss: 2.8457e-04 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7553e-05 - acc: 0.0000e+00 - val_loss: 2.1662e-04 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4941e-05 - acc: 0.0000e+00 - val_loss: 1.4468e-04 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1972e-05 - acc: 0.0000e+00 - val_loss: 1.6068e-04 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0898e-05 - acc: 0.0000e+00 - val_loss: 1.5473e-04 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3745e-05 - acc: 0.0000e+00 - val_loss: 1.0981e-04 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4579e-05 - acc: 0.0000e+00 - val_loss: 1.0658e-04 - val_acc: 0.0000e+00\n",
      "Epoch 132/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13702/13702 [==============================] - 1s - loss: 6.3433e-05 - acc: 0.0000e+00 - val_loss: 2.7105e-04 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4739e-05 - acc: 0.0000e+00 - val_loss: 2.7288e-04 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7838e-05 - acc: 0.0000e+00 - val_loss: 1.0321e-04 - val_acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.9862e-05 - acc: 0.0000e+00 - val_loss: 1.3938e-04 - val_acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9317e-05 - acc: 0.0000e+00 - val_loss: 1.3731e-04 - val_acc: 0.0000e+00\n",
      "Epoch 137/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0154e-05 - acc: 0.0000e+00 - val_loss: 1.9247e-04 - val_acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4486e-05 - acc: 0.0000e+00 - val_loss: 1.5125e-04 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.1072e-05 - acc: 0.0000e+00 - val_loss: 1.0958e-04 - val_acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9677e-05 - acc: 0.0000e+00 - val_loss: 1.0424e-04 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7725e-05 - acc: 0.0000e+00 - val_loss: 1.7454e-04 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2214e-05 - acc: 0.0000e+00 - val_loss: 1.4798e-04 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.0318e-05 - acc: 0.0000e+00 - val_loss: 1.1087e-04 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4102e-05 - acc: 0.0000e+00 - val_loss: 1.1551e-04 - val_acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9907e-05 - acc: 0.0000e+00 - val_loss: 1.0189e-04 - val_acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9387e-05 - acc: 0.0000e+00 - val_loss: 1.5805e-04 - val_acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3418e-05 - acc: 0.0000e+00 - val_loss: 1.0517e-04 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.0501e-05 - acc: 0.0000e+00 - val_loss: 1.2135e-04 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2552e-05 - acc: 0.0000e+00 - val_loss: 1.0421e-04 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6797e-05 - acc: 0.0000e+00 - val_loss: 3.8725e-04 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.0978e-05 - acc: 0.0000e+00 - val_loss: 2.2032e-04 - val_acc: 0.0000e+00\n",
      "Epoch 152/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9420e-05 - acc: 0.0000e+00 - val_loss: 1.1117e-04 - val_acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.1105e-05 - acc: 0.0000e+00 - val_loss: 1.1714e-04 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2313e-05 - acc: 0.0000e+00 - val_loss: 9.8602e-05 - val_acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3480e-05 - acc: 0.0000e+00 - val_loss: 2.6229e-04 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3138e-05 - acc: 0.0000e+00 - val_loss: 1.3430e-04 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3961e-05 - acc: 0.0000e+00 - val_loss: 1.1436e-04 - val_acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2608e-05 - acc: 0.0000e+00 - val_loss: 1.6103e-04 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9241e-05 - acc: 0.0000e+00 - val_loss: 1.1385e-04 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.2693e-05 - acc: 0.0000e+00 - val_loss: 1.1039e-04 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9654e-05 - acc: 0.0000e+00 - val_loss: 1.4374e-04 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8400e-05 - acc: 0.0000e+00 - val_loss: 3.0981e-04 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.0255e-05 - acc: 0.0000e+00 - val_loss: 2.3080e-04 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.6711e-05 - acc: 0.0000e+00 - val_loss: 2.1065e-04 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2729e-05 - acc: 0.0000e+00 - val_loss: 7.7048e-04 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7525e-05 - acc: 0.0000e+00 - val_loss: 1.0705e-04 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2871e-05 - acc: 0.0000e+00 - val_loss: 3.4541e-04 - val_acc: 0.0000e+00\n",
      "Epoch 168/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.6869e-05 - acc: 0.0000e+00 - val_loss: 2.8644e-04 - val_acc: 0.0000e+00\n",
      "Epoch 169/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8582e-05 - acc: 0.0000e+00 - val_loss: 9.7128e-05 - val_acc: 0.0000e+00\n",
      "Epoch 170/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.4799e-05 - acc: 0.0000e+00 - val_loss: 9.4729e-05 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3059e-05 - acc: 0.0000e+00 - val_loss: 1.2937e-04 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.5151e-05 - acc: 0.0000e+00 - val_loss: 9.5984e-05 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.4372e-05 - acc: 0.0000e+00 - val_loss: 2.1266e-04 - val_acc: 0.0000e+00\n",
      "Epoch 174/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.2838e-05 - acc: 0.0000e+00 - val_loss: 2.1060e-04 - val_acc: 0.0000e+00\n",
      "Epoch 175/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.0908e-05 - acc: 0.0000e+00 - val_loss: 1.3188e-04 - val_acc: 0.0000e+00\n",
      "Epoch 176/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3162e-05 - acc: 0.0000e+00 - val_loss: 8.8861e-05 - val_acc: 0.0000e+00\n",
      "Epoch 177/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.1070e-05 - acc: 0.0000e+00 - val_loss: 1.3267e-04 - val_acc: 0.0000e+00\n",
      "Epoch 178/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3744e-05 - acc: 0.0000e+00 - val_loss: 1.2478e-04 - val_acc: 0.0000e+00\n",
      "Epoch 179/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.0087e-05 - acc: 0.0000e+00 - val_loss: 1.1719e-04 - val_acc: 0.0000e+00\n",
      "Epoch 180/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.5939e-05 - acc: 0.0000e+00 - val_loss: 2.2297e-04 - val_acc: 0.0000e+00\n",
      "Epoch 181/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.2949e-05 - acc: 0.0000e+00 - val_loss: 1.5936e-04 - val_acc: 0.0000e+00\n",
      "Epoch 182/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.5697e-05 - acc: 0.0000e+00 - val_loss: 4.1625e-04 - val_acc: 0.0000e+00\n",
      "Epoch 183/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.6044e-05 - acc: 0.0000e+00 - val_loss: 1.4011e-04 - val_acc: 0.0000e+00- loss: 5.6600e-05 - acc: 0.0000e+\n",
      "Epoch 184/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.5740e-05 - acc: 0.0000e+00 - val_loss: 9.5011e-05 - val_acc: 0.0000e+00\n",
      "Epoch 185/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.1277e-05 - acc: 0.0000e+00 - val_loss: 1.2430e-04 - val_acc: 0.0000e+00\n",
      "Epoch 186/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.7618e-05 - acc: 0.0000e+00 - val_loss: 1.6166e-04 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.0599e-05 - acc: 0.0000e+00 - val_loss: 1.2909e-04 - val_acc: 0.0000e+00\n",
      "Epoch 188/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.0851e-05 - acc: 0.0000e+00 - val_loss: 1.1446e-04 - val_acc: 0.0000e+00\n",
      "Epoch 189/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.2853e-05 - acc: 0.0000e+00 - val_loss: 1.2426e-04 - val_acc: 0.0000e+00\n",
      "Epoch 190/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9944e-05 - acc: 0.0000e+00 - val_loss: 1.5018e-04 - val_acc: 0.0000e+00\n",
      "Epoch 191/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.1618e-05 - acc: 0.0000e+00 - val_loss: 1.7918e-04 - val_acc: 0.0000e+00\n",
      "Epoch 192/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.4237e-05 - acc: 0.0000e+00 - val_loss: 1.4274e-04 - val_acc: 0.0000e+00\n",
      "Epoch 193/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6970e-05 - acc: 0.0000e+00 - val_loss: 1.9071e-04 - val_acc: 0.0000e+00\n",
      "Epoch 194/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9245e-05 - acc: 0.0000e+00 - val_loss: 5.2862e-04 - val_acc: 0.0000e+00\n",
      "Epoch 195/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.7839e-05 - acc: 0.0000e+00 - val_loss: 4.4721e-04 - val_acc: 0.0000e+00\n",
      "Epoch 196/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9013e-05 - acc: 0.0000e+00 - val_loss: 2.6655e-04 - val_acc: 0.0000e+00\n",
      "Epoch 197/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.6635e-05 - acc: 0.0000e+00 - val_loss: 1.5327e-04 - val_acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.0156e-05 - acc: 0.0000e+00 - val_loss: 3.9753e-04 - val_acc: 0.0000e+00\n",
      "Epoch 199/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6178e-05 - acc: 0.0000e+00 - val_loss: 1.4531e-04 - val_acc: 0.0000e+00\n",
      "Epoch 200/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.0364e-05 - acc: 0.0000e+00 - val_loss: 2.2693e-04 - val_acc: 0.0000e+00\n",
      "Epoch 201/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.0929e-05 - acc: 0.0000e+00 - val_loss: 2.5645e-04 - val_acc: 0.0000e+00\n",
      "Epoch 202/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5530e-05 - acc: 0.0000e+00 - val_loss: 2.2211e-04 - val_acc: 0.0000e+00\n",
      "Epoch 203/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.1057e-05 - acc: 0.0000e+00 - val_loss: 2.2898e-04 - val_acc: 0.0000e+00\n",
      "Epoch 204/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3156e-05 - acc: 0.0000e+00 - val_loss: 4.0469e-04 - val_acc: 0.0000e+00\n",
      "Epoch 205/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6560e-05 - acc: 0.0000e+00 - val_loss: 3.1460e-04 - val_acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.2696e-05 - acc: 0.0000e+00 - val_loss: 3.0310e-04 - val_acc: 0.0000e+00\n",
      "Epoch 207/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.4534e-05 - acc: 0.0000e+00 - val_loss: 2.4806e-04 - val_acc: 0.0000e+00\n",
      "Epoch 208/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.3620e-05 - acc: 0.0000e+00 - val_loss: 2.6803e-04 - val_acc: 0.0000e+00\n",
      "Epoch 209/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.8282e-05 - acc: 0.0000e+00 - val_loss: 4.5365e-04 - val_acc: 0.0000e+00\n",
      "Epoch 210/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9243e-05 - acc: 0.0000e+00 - val_loss: 2.9860e-04 - val_acc: 0.0000e+00\n",
      "Epoch 211/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9562e-05 - acc: 0.0000e+00 - val_loss: 3.7185e-04 - val_acc: 0.0000e+00\n",
      "Epoch 212/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.4081e-05 - acc: 0.0000e+00 - val_loss: 1.9620e-04 - val_acc: 0.0000e+00\n",
      "Epoch 213/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5634e-05 - acc: 0.0000e+00 - val_loss: 3.7626e-04 - val_acc: 0.0000e+00\n",
      "Epoch 214/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.3095e-05 - acc: 0.0000e+00 - val_loss: 4.4241e-04 - val_acc: 0.0000e+00\n",
      "Epoch 215/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.8171e-05 - acc: 0.0000e+00 - val_loss: 1.5349e-04 - val_acc: 0.0000e+00\n",
      "Epoch 216/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9549e-05 - acc: 0.0000e+00 - val_loss: 3.5179e-04 - val_acc: 0.0000e+00\n",
      "Epoch 217/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.4267e-05 - acc: 0.0000e+00 - val_loss: 3.2184e-04 - val_acc: 0.0000e+00\n",
      "Epoch 218/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.8565e-05 - acc: 0.0000e+00 - val_loss: 4.6950e-04 - val_acc: 0.0000e+00\n",
      "Epoch 219/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.3311e-05 - acc: 0.0000e+00 - val_loss: 7.0130e-04 - val_acc: 0.0000e+00\n",
      "Epoch 220/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.4961e-05 - acc: 0.0000e+00 - val_loss: 5.7976e-04 - val_acc: 0.0000e+00\n",
      "Epoch 221/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9112e-05 - acc: 0.0000e+00 - val_loss: 6.3798e-04 - val_acc: 0.0000e+00\n",
      "Epoch 222/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5547e-05 - acc: 0.0000e+00 - val_loss: 3.8607e-04 - val_acc: 0.0000e+00\n",
      "Epoch 223/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0416e-05 - acc: 0.0000e+00 - val_loss: 4.5483e-04 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5231e-05 - acc: 0.0000e+00 - val_loss: 3.7021e-04 - val_acc: 0.0000e+00\n",
      "Epoch 225/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.7328e-05 - acc: 0.0000e+00 - val_loss: 2.9372e-04 - val_acc: 0.0000e+00\n",
      "Epoch 226/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2335e-05 - acc: 0.0000e+00 - val_loss: 5.3925e-04 - val_acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0794e-05 - acc: 0.0000e+00 - val_loss: 3.1190e-04 - val_acc: 0.0000e+00\n",
      "Epoch 228/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6578e-05 - acc: 0.0000e+00 - val_loss: 4.9661e-04 - val_acc: 0.0000e+00\n",
      "Epoch 229/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.7412e-05 - acc: 0.0000e+00 - val_loss: 5.9925e-04 - val_acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6688e-05 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 231/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6717e-05 - acc: 0.0000e+00 - val_loss: 4.9957e-04 - val_acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9908e-05 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 233/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.3331e-05 - acc: 0.0000e+00 - val_loss: 6.7110e-04 - val_acc: 0.0000e+00\n",
      "Epoch 234/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.9649e-05 - acc: 0.0000e+00 - val_loss: 3.8010e-04 - val_acc: 0.0000e+00\n",
      "Epoch 235/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.9112e-05 - acc: 0.0000e+00 - val_loss: 6.3234e-04 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0891e-05 - acc: 0.0000e+00 - val_loss: 3.3754e-04 - val_acc: 0.0000e+00\n",
      "Epoch 237/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2709e-05 - acc: 0.0000e+00 - val_loss: 8.6715e-04 - val_acc: 0.0000e+00\n",
      "Epoch 238/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6157e-05 - acc: 0.0000e+00 - val_loss: 5.4450e-04 - val_acc: 0.0000e+00\n",
      "Epoch 239/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9385e-05 - acc: 0.0000e+00 - val_loss: 4.4275e-04 - val_acc: 0.0000e+00\n",
      "Epoch 240/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.7859e-05 - acc: 0.0000e+00 - val_loss: 6.4428e-04 - val_acc: 0.0000e+00\n",
      "Epoch 241/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2141e-05 - acc: 0.0000e+00 - val_loss: 8.1975e-04 - val_acc: 0.0000e+00\n",
      "Epoch 242/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5560e-05 - acc: 0.0000e+00 - val_loss: 3.4242e-04 - val_acc: 0.0000e+00\n",
      "Epoch 243/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13702/13702 [==============================] - 1s - loss: 3.9698e-05 - acc: 0.0000e+00 - val_loss: 8.6679e-04 - val_acc: 0.0000e+00\n",
      "Epoch 244/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0289e-05 - acc: 0.0000e+00 - val_loss: 6.7704e-04 - val_acc: 0.0000e+00\n",
      "Epoch 245/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5648e-05 - acc: 0.0000e+00 - val_loss: 5.4294e-04 - val_acc: 0.0000e+00\n",
      "Epoch 246/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.4502e-05 - acc: 0.0000e+00 - val_loss: 3.3888e-04 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0186e-05 - acc: 0.0000e+00 - val_loss: 3.5092e-04 - val_acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.7147e-05 - acc: 0.0000e+00 - val_loss: 4.3610e-04 - val_acc: 0.0000e+00\n",
      "Epoch 249/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8760e-05 - acc: 0.0000e+00 - val_loss: 6.7867e-04 - val_acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8832e-05 - acc: 0.0000e+00 - val_loss: 3.6523e-04 - val_acc: 0.0000e+00\n",
      "Epoch 251/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0648e-05 - acc: 0.0000e+00 - val_loss: 9.3012e-04 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.4399e-05 - acc: 0.0000e+00 - val_loss: 3.8663e-04 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.3185e-05 - acc: 0.0000e+00 - val_loss: 4.9197e-04 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.3924e-05 - acc: 0.0000e+00 - val_loss: 3.2221e-04 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2961e-05 - acc: 0.0000e+00 - val_loss: 5.6797e-04 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7599e-05 - acc: 0.0000e+00 - val_loss: 6.2306e-04 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8016e-05 - acc: 0.0000e+00 - val_loss: 6.2173e-04 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0209e-05 - acc: 0.0000e+00 - val_loss: 2.8032e-04 - val_acc: 0.0000e+00\n",
      "Epoch 259/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.7063e-05 - acc: 0.0000e+00 - val_loss: 4.6994e-04 - val_acc: 0.0000e+00\n",
      "Epoch 260/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2735e-05 - acc: 0.0000e+00 - val_loss: 4.1736e-04 - val_acc: 0.0000e+00\n",
      "Epoch 261/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6282e-05 - acc: 0.0000e+00 - val_loss: 6.3793e-04 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1539e-05 - acc: 0.0000e+00 - val_loss: 7.4030e-04 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.3086e-05 - acc: 0.0000e+00 - val_loss: 5.2698e-04 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0219e-05 - acc: 0.0000e+00 - val_loss: 5.7726e-04 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8289e-05 - acc: 0.0000e+00 - val_loss: 5.5163e-04 - val_acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7492e-05 - acc: 0.0000e+00 - val_loss: 6.1641e-04 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7846e-05 - acc: 0.0000e+00 - val_loss: 3.1007e-04 - val_acc: 0.0000e+00\n",
      "Epoch 268/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8842e-05 - acc: 0.0000e+00 - val_loss: 6.1031e-04 - val_acc: 0.0000e+00\n",
      "Epoch 269/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7726e-05 - acc: 0.0000e+00 - val_loss: 9.9901e-04 - val_acc: 0.0000e+00\n",
      "Epoch 270/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0212e-05 - acc: 0.0000e+00 - val_loss: 8.2007e-04 - val_acc: 0.0000e+00\n",
      "Epoch 271/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8043e-05 - acc: 0.0000e+00 - val_loss: 8.5960e-04 - val_acc: 0.0000e+00\n",
      "Epoch 272/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2605e-05 - acc: 0.0000e+00 - val_loss: 4.3719e-04 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0478e-05 - acc: 0.0000e+00 - val_loss: 4.2340e-04 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.9580e-05 - acc: 0.0000e+00 - val_loss: 3.7551e-04 - val_acc: 0.0000e+00\n",
      "Epoch 275/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5733e-05 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 276/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.9769e-05 - acc: 0.0000e+00 - val_loss: 7.1827e-04 - val_acc: 0.0000e+00\n",
      "Epoch 277/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.9066e-05 - acc: 0.0000e+00 - val_loss: 3.3978e-04 - val_acc: 0.0000e+00\n",
      "Epoch 278/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6380e-05 - acc: 0.0000e+00 - val_loss: 8.5174e-04 - val_acc: 0.0000e+00\n",
      "Epoch 279/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6578e-05 - acc: 0.0000e+00 - val_loss: 5.6161e-04 - val_acc: 0.0000e+00\n",
      "Epoch 280/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6997e-05 - acc: 0.0000e+00 - val_loss: 7.0406e-04 - val_acc: 0.0000e+00\n",
      "Epoch 281/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4575e-05 - acc: 0.0000e+00 - val_loss: 6.2905e-04 - val_acc: 0.0000e+00\n",
      "Epoch 282/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.9156e-05 - acc: 0.0000e+00 - val_loss: 7.7921e-04 - val_acc: 0.0000e+00\n",
      "Epoch 283/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6416e-05 - acc: 0.0000e+00 - val_loss: 7.2014e-04 - val_acc: 0.0000e+00\n",
      "Epoch 284/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8637e-05 - acc: 0.0000e+00 - val_loss: 9.1494e-04 - val_acc: 0.0000e+00\n",
      "Epoch 285/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8647e-05 - acc: 0.0000e+00 - val_loss: 6.2667e-04 - val_acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5288e-05 - acc: 0.0000e+00 - val_loss: 4.4665e-04 - val_acc: 0.0000e+00\n",
      "Epoch 287/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4588e-05 - acc: 0.0000e+00 - val_loss: 5.2453e-04 - val_acc: 0.0000e+00\n",
      "Epoch 288/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6369e-05 - acc: 0.0000e+00 - val_loss: 7.8817e-04 - val_acc: 0.0000e+00\n",
      "Epoch 289/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8175e-05 - acc: 0.0000e+00 - val_loss: 6.7251e-04 - val_acc: 0.0000e+00\n",
      "Epoch 290/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5433e-05 - acc: 0.0000e+00 - val_loss: 8.0439e-04 - val_acc: 0.0000e+00\n",
      "Epoch 291/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7328e-05 - acc: 0.0000e+00 - val_loss: 6.3759e-04 - val_acc: 0.0000e+00\n",
      "Epoch 292/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.9048e-05 - acc: 0.0000e+00 - val_loss: 4.4872e-04 - val_acc: 0.0000e+00\n",
      "Epoch 293/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5619e-05 - acc: 0.0000e+00 - val_loss: 8.6864e-04 - val_acc: 0.0000e+00\n",
      "Epoch 294/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6799e-05 - acc: 0.0000e+00 - val_loss: 7.3828e-04 - val_acc: 0.0000e+00\n",
      "Epoch 295/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6257e-05 - acc: 0.0000e+00 - val_loss: 8.0887e-04 - val_acc: 0.0000e+00\n",
      "Epoch 296/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3260e-05 - acc: 0.0000e+00 - val_loss: 5.9632e-04 - val_acc: 0.0000e+00\n",
      "Epoch 297/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.2596e-05 - acc: 0.0000e+00 - val_loss: 7.2372e-04 - val_acc: 0.0000e+00\n",
      "Epoch 298/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1466e-05 - acc: 0.0000e+00 - val_loss: 5.2079e-04 - val_acc: 0.0000e+00\n",
      "Epoch 299/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6802e-05 - acc: 0.0000e+00 - val_loss: 8.9757e-04 - val_acc: 0.0000e+00\n",
      "Epoch 300/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4732e-05 - acc: 0.0000e+00 - val_loss: 6.4950e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00013 MSE (0.01 RMSE)\n",
      "Test Score: 0.00223 MSE (0.05 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_21 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_22 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13702 samples, validate on 1523 samples\n",
      "Epoch 1/300\n",
      "13702/13702 [==============================] - 3s - loss: 0.0133 - acc: 0.0000e+00 - val_loss: 0.0033 - val_acc: 0.0000e+0000\n",
      "Epoch 2/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9394e-04 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5072e-04 - acc: 0.0000e+00 - val_loss: 5.8474e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3459e-04 - acc: 0.0000e+00 - val_loss: 3.7061e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.9244e-04 - acc: 0.0000e+00 - val_loss: 2.9118e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.7466e-04 - acc: 0.0000e+00 - val_loss: 2.5825e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.5256e-04 - acc: 0.0000e+00 - val_loss: 5.3940e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.5238e-04 - acc: 0.0000e+00 - val_loss: 2.4065e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.3486e-04 - acc: 0.0000e+00 - val_loss: 5.0852e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.5004e-04 - acc: 0.0000e+00 - val_loss: 6.2537e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.4572e-04 - acc: 0.0000e+00 - val_loss: 2.3107e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.3060e-04 - acc: 0.0000e+00 - val_loss: 2.8896e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.5588e-04 - acc: 0.0000e+00 - val_loss: 8.0898e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.2104e-04 - acc: 0.0000e+00 - val_loss: 2.1620e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.3444e-04 - acc: 0.0000e+00 - val_loss: 5.0109e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.1459e-04 - acc: 0.0000e+00 - val_loss: 2.1089e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.2692e-04 - acc: 0.0000e+00 - val_loss: 2.3349e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9929e-04 - acc: 0.0000e+00 - val_loss: 2.3987e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.0766e-04 - acc: 0.0000e+00 - val_loss: 2.0840e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.0740e-04 - acc: 0.0000e+00 - val_loss: 2.0594e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.1705e-04 - acc: 0.0000e+00 - val_loss: 2.4459e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.0874e-04 - acc: 0.0000e+00 - val_loss: 2.0697e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9554e-04 - acc: 0.0000e+00 - val_loss: 4.6310e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.1650e-04 - acc: 0.0000e+00 - val_loss: 2.1705e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.1688e-04 - acc: 0.0000e+00 - val_loss: 2.9588e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9864e-04 - acc: 0.0000e+00 - val_loss: 2.3274e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.0670e-04 - acc: 0.0000e+00 - val_loss: 2.3590e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.1198e-04 - acc: 0.0000e+00 - val_loss: 2.2135e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9162e-04 - acc: 0.0000e+00 - val_loss: 2.1607e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8902e-04 - acc: 0.0000e+00 - val_loss: 4.6749e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9698e-04 - acc: 0.0000e+00 - val_loss: 2.5019e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8899e-04 - acc: 0.0000e+00 - val_loss: 1.8822e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9212e-04 - acc: 0.0000e+00 - val_loss: 2.0576e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8264e-04 - acc: 0.0000e+00 - val_loss: 1.9257e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7753e-04 - acc: 0.0000e+00 - val_loss: 3.4138e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8731e-04 - acc: 0.0000e+00 - val_loss: 2.1759e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8391e-04 - acc: 0.0000e+00 - val_loss: 1.9001e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8392e-04 - acc: 0.0000e+00 - val_loss: 7.6525e-04 - val_acc: 0.0000e+0000e+0\n",
      "Epoch 39/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.0947e-04 - acc: 0.0000e+00 - val_loss: 1.7666e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7135e-04 - acc: 0.0000e+00 - val_loss: 1.7554e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7852e-04 - acc: 0.0000e+00 - val_loss: 2.5486e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6611e-04 - acc: 0.0000e+00 - val_loss: 2.6239e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8182e-04 - acc: 0.0000e+00 - val_loss: 1.8036e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7199e-04 - acc: 0.0000e+00 - val_loss: 1.7577e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5637e-04 - acc: 0.0000e+00 - val_loss: 2.1600e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8695e-04 - acc: 0.0000e+00 - val_loss: 7.4549e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13702/13702 [==============================] - 1s - loss: 1.8026e-04 - acc: 0.0000e+00 - val_loss: 2.4794e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7000e-04 - acc: 0.0000e+00 - val_loss: 3.5737e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6763e-04 - acc: 0.0000e+00 - val_loss: 1.6839e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5622e-04 - acc: 0.0000e+00 - val_loss: 1.7348e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5985e-04 - acc: 0.0000e+00 - val_loss: 1.6267e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6144e-04 - acc: 0.0000e+00 - val_loss: 3.1402e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7031e-04 - acc: 0.0000e+00 - val_loss: 8.4756e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6498e-04 - acc: 0.0000e+00 - val_loss: 1.6553e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5236e-04 - acc: 0.0000e+00 - val_loss: 1.5752e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6381e-04 - acc: 0.0000e+00 - val_loss: 1.5817e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6023e-04 - acc: 0.0000e+00 - val_loss: 2.7356e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3247e-04 - acc: 0.0000e+00 - val_loss: 1.6422e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4644e-04 - acc: 0.0000e+00 - val_loss: 1.5575e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6397e-04 - acc: 0.0000e+00 - val_loss: 1.5144e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5445e-04 - acc: 0.0000e+00 - val_loss: 2.7695e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4848e-04 - acc: 0.0000e+00 - val_loss: 1.7248e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3311e-04 - acc: 0.0000e+00 - val_loss: 4.0052e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4159e-04 - acc: 0.0000e+00 - val_loss: 2.3234e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4738e-04 - acc: 0.0000e+00 - val_loss: 1.4232e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4297e-04 - acc: 0.0000e+00 - val_loss: 1.4645e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3418e-04 - acc: 0.0000e+00 - val_loss: 1.4097e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3199e-04 - acc: 0.0000e+00 - val_loss: 3.6554e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4490e-04 - acc: 0.0000e+00 - val_loss: 1.7464e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2879e-04 - acc: 0.0000e+00 - val_loss: 1.6936e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2345e-04 - acc: 0.0000e+00 - val_loss: 1.6393e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2255e-04 - acc: 0.0000e+00 - val_loss: 1.8113e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3485e-04 - acc: 0.0000e+00 - val_loss: 1.3567e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2201e-04 - acc: 0.0000e+00 - val_loss: 1.4130e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2188e-04 - acc: 0.0000e+00 - val_loss: 1.9105e-04 - val_acc: 0.0000e+0000\n",
      "Epoch 76/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1391e-04 - acc: 0.0000e+00 - val_loss: 2.3136e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2012e-04 - acc: 0.0000e+00 - val_loss: 1.8512e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1108e-04 - acc: 0.0000e+00 - val_loss: 1.5274e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2238e-04 - acc: 0.0000e+00 - val_loss: 1.3438e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2524e-04 - acc: 0.0000e+00 - val_loss: 4.8044e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2214e-04 - acc: 0.0000e+00 - val_loss: 1.4596e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1457e-04 - acc: 0.0000e+00 - val_loss: 3.0914e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1937e-04 - acc: 0.0000e+00 - val_loss: 1.3383e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1249e-04 - acc: 0.0000e+00 - val_loss: 1.3054e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0861e-04 - acc: 0.0000e+00 - val_loss: 3.2082e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3097e-04 - acc: 0.0000e+00 - val_loss: 1.5170e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1506e-04 - acc: 0.0000e+00 - val_loss: 2.0245e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2407e-04 - acc: 0.0000e+00 - val_loss: 2.0201e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0012e-04 - acc: 0.0000e+00 - val_loss: 1.2907e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1059e-04 - acc: 0.0000e+00 - val_loss: 1.3377e-04 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1127e-04 - acc: 0.0000e+00 - val_loss: 2.1563e-04 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0752e-04 - acc: 0.0000e+00 - val_loss: 1.2963e-04 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0548e-04 - acc: 0.0000e+00 - val_loss: 1.4898e-04 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.7504e-05 - acc: 0.0000e+00 - val_loss: 1.2921e-04 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0204e-04 - acc: 0.0000e+00 - val_loss: 1.8416e-04 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.4265e-05 - acc: 0.0000e+00 - val_loss: 1.2894e-04 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3720e-05 - acc: 0.0000e+00 - val_loss: 1.2774e-04 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0131e-04 - acc: 0.0000e+00 - val_loss: 1.5685e-04 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.4044e-05 - acc: 0.0000e+00 - val_loss: 1.4545e-04 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.6335e-05 - acc: 0.0000e+00 - val_loss: 2.2784e-04 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3834e-05 - acc: 0.0000e+00 - val_loss: 1.9397e-04 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.2517e-05 - acc: 0.0000e+00 - val_loss: 1.2676e-04 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0039e-04 - acc: 0.0000e+00 - val_loss: 1.4698e-04 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.6438e-05 - acc: 0.0000e+00 - val_loss: 2.8614e-04 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0214e-04 - acc: 0.0000e+00 - val_loss: 1.2785e-04 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3759e-05 - acc: 0.0000e+00 - val_loss: 1.7592e-04 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.7740e-05 - acc: 0.0000e+00 - val_loss: 1.8724e-04 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.6387e-05 - acc: 0.0000e+00 - val_loss: 1.3339e-04 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.2106e-05 - acc: 0.0000e+00 - val_loss: 3.1184e-04 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.9505e-05 - acc: 0.0000e+00 - val_loss: 1.6738e-04 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.4567e-05 - acc: 0.0000e+00 - val_loss: 1.5068e-04 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.8620e-05 - acc: 0.0000e+00 - val_loss: 1.5387e-04 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.8195e-05 - acc: 0.0000e+00 - val_loss: 2.4338e-04 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.6478e-05 - acc: 0.0000e+00 - val_loss: 1.3077e-04 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.6121e-05 - acc: 0.0000e+00 - val_loss: 1.2244e-04 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.2299e-05 - acc: 0.0000e+00 - val_loss: 1.3208e-04 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.2623e-05 - acc: 0.0000e+00 - val_loss: 1.2590e-04 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3200e-05 - acc: 0.0000e+00 - val_loss: 1.4197e-04 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0783e-05 - acc: 0.0000e+00 - val_loss: 1.2855e-04 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.2233e-05 - acc: 0.0000e+00 - val_loss: 1.3273e-04 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0185e-05 - acc: 0.0000e+00 - val_loss: 2.2177e-04 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1807e-05 - acc: 0.0000e+00 - val_loss: 1.7995e-04 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0771e-05 - acc: 0.0000e+00 - val_loss: 1.2267e-04 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1813e-05 - acc: 0.0000e+00 - val_loss: 1.3659e-04 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2489e-05 - acc: 0.0000e+00 - val_loss: 1.3445e-04 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.7506e-05 - acc: 0.0000e+00 - val_loss: 3.8466e-04 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9159e-05 - acc: 0.0000e+00 - val_loss: 2.2810e-04 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8937e-05 - acc: 0.0000e+00 - val_loss: 1.2509e-04 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.7215e-05 - acc: 0.0000e+00 - val_loss: 1.3817e-04 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0868e-05 - acc: 0.0000e+00 - val_loss: 1.2075e-04 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.7859e-05 - acc: 0.0000e+00 - val_loss: 1.5659e-04 - val_acc: 0.0000e+00\n",
      "Epoch 132/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.9857e-05 - acc: 0.0000e+00 - val_loss: 1.1981e-04 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9683e-05 - acc: 0.0000e+00 - val_loss: 1.4242e-04 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.3464e-05 - acc: 0.0000e+00 - val_loss: 1.1791e-04 - val_acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.7422e-05 - acc: 0.0000e+00 - val_loss: 1.7474e-04 - val_acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.8859e-05 - acc: 0.0000e+00 - val_loss: 1.2569e-04 - val_acc: 0.0000e+00\n",
      "Epoch 137/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.5241e-05 - acc: 0.0000e+00 - val_loss: 1.1227e-04 - val_acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0622e-05 - acc: 0.0000e+00 - val_loss: 1.9055e-04 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2562e-05 - acc: 0.0000e+00 - val_loss: 1.1668e-04 - val_acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0783e-05 - acc: 0.0000e+00 - val_loss: 1.7992e-04 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1424e-05 - acc: 0.0000e+00 - val_loss: 1.9834e-04 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1905e-05 - acc: 0.0000e+00 - val_loss: 1.1222e-04 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6254e-05 - acc: 0.0000e+00 - val_loss: 1.5660e-04 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.5019e-05 - acc: 0.0000e+00 - val_loss: 1.8028e-04 - val_acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8853e-05 - acc: 0.0000e+00 - val_loss: 1.1951e-04 - val_acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.9495e-05 - acc: 0.0000e+00 - val_loss: 1.2143e-04 - val_acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1706e-05 - acc: 0.0000e+00 - val_loss: 2.0505e-04 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6048e-05 - acc: 0.0000e+00 - val_loss: 1.3667e-04 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2882e-05 - acc: 0.0000e+00 - val_loss: 1.2253e-04 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4999e-05 - acc: 0.0000e+00 - val_loss: 1.2375e-04 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.8232e-05 - acc: 0.0000e+00 - val_loss: 1.3332e-04 - val_acc: 0.0000e+00\n",
      "Epoch 152/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0559e-05 - acc: 0.0000e+00 - val_loss: 1.1764e-04 - val_acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6864e-05 - acc: 0.0000e+00 - val_loss: 1.4618e-04 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6028e-05 - acc: 0.0000e+00 - val_loss: 1.1745e-04 - val_acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.1782e-05 - acc: 0.0000e+00 - val_loss: 1.2184e-04 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6450e-05 - acc: 0.0000e+00 - val_loss: 1.2035e-04 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4612e-05 - acc: 0.0000e+00 - val_loss: 1.2221e-04 - val_acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0593e-05 - acc: 0.0000e+00 - val_loss: 2.7241e-04 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13702/13702 [==============================] - 1s - loss: 7.1296e-05 - acc: 0.0000e+00 - val_loss: 1.4057e-04 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.1691e-05 - acc: 0.0000e+00 - val_loss: 1.1298e-04 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.9301e-05 - acc: 0.0000e+00 - val_loss: 1.1585e-04 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4087e-05 - acc: 0.0000e+00 - val_loss: 1.5222e-04 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3793e-05 - acc: 0.0000e+00 - val_loss: 1.7010e-04 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.8608e-05 - acc: 0.0000e+00 - val_loss: 3.1628e-04 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0132e-05 - acc: 0.0000e+00 - val_loss: 1.1609e-04 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.9550e-05 - acc: 0.0000e+00 - val_loss: 1.1385e-04 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2328e-05 - acc: 0.0000e+00 - val_loss: 2.0685e-04 - val_acc: 0.0000e+00\n",
      "Epoch 168/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8998e-05 - acc: 0.0000e+00 - val_loss: 1.1409e-04 - val_acc: 0.0000e+00\n",
      "Epoch 169/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8152e-05 - acc: 0.0000e+00 - val_loss: 1.6447e-04 - val_acc: 0.0000e+0000e+\n",
      "Epoch 170/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3882e-05 - acc: 0.0000e+00 - val_loss: 1.2515e-04 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8797e-05 - acc: 0.0000e+00 - val_loss: 1.3338e-04 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3242e-05 - acc: 0.0000e+00 - val_loss: 1.1289e-04 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.1616e-05 - acc: 0.0000e+00 - val_loss: 1.5281e-04 - val_acc: 0.0000e+00\n",
      "Epoch 174/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9882e-05 - acc: 0.0000e+00 - val_loss: 1.2248e-04 - val_acc: 0.0000e+00\n",
      "Epoch 175/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4397e-05 - acc: 0.0000e+00 - val_loss: 1.1416e-04 - val_acc: 0.0000e+00\n",
      "Epoch 176/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.0084e-05 - acc: 0.0000e+00 - val_loss: 1.2345e-04 - val_acc: 0.0000e+00\n",
      "Epoch 177/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2322e-05 - acc: 0.0000e+00 - val_loss: 1.0766e-04 - val_acc: 0.0000e+00\n",
      "Epoch 178/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.6023e-05 - acc: 0.0000e+00 - val_loss: 1.1570e-04 - val_acc: 0.0000e+00\n",
      "Epoch 179/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7515e-05 - acc: 0.0000e+00 - val_loss: 1.1179e-04 - val_acc: 0.0000e+00\n",
      "Epoch 180/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.7967e-05 - acc: 0.0000e+00 - val_loss: 1.2051e-04 - val_acc: 0.0000e+00\n",
      "Epoch 181/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.5422e-05 - acc: 0.0000e+00 - val_loss: 1.7609e-04 - val_acc: 0.0000e+00\n",
      "Epoch 182/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.1599e-05 - acc: 0.0000e+00 - val_loss: 1.5782e-04 - val_acc: 0.0000e+00\n",
      "Epoch 183/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3628e-05 - acc: 0.0000e+00 - val_loss: 1.2488e-04 - val_acc: 0.0000e+00\n",
      "Epoch 184/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2825e-05 - acc: 0.0000e+00 - val_loss: 1.1283e-04 - val_acc: 0.0000e+00\n",
      "Epoch 185/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9425e-05 - acc: 0.0000e+00 - val_loss: 1.2524e-04 - val_acc: 0.0000e+00\n",
      "Epoch 186/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4888e-05 - acc: 0.0000e+00 - val_loss: 1.2252e-04 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8506e-05 - acc: 0.0000e+00 - val_loss: 1.4287e-04 - val_acc: 0.0000e+00\n",
      "Epoch 188/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.7745e-05 - acc: 0.0000e+00 - val_loss: 2.0512e-04 - val_acc: 0.0000e+00\n",
      "Epoch 189/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.1121e-05 - acc: 0.0000e+00 - val_loss: 1.9467e-04 - val_acc: 0.0000e+00\n",
      "Epoch 190/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2846e-05 - acc: 0.0000e+00 - val_loss: 1.2329e-04 - val_acc: 0.0000e+00\n",
      "Epoch 191/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.5664e-05 - acc: 0.0000e+00 - val_loss: 1.9110e-04 - val_acc: 0.0000e+00\n",
      "Epoch 192/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8697e-05 - acc: 0.0000e+00 - val_loss: 1.2126e-04 - val_acc: 0.0000e+00\n",
      "Epoch 193/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6038e-05 - acc: 0.0000e+00 - val_loss: 2.3818e-04 - val_acc: 0.0000e+00\n",
      "Epoch 194/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8044e-05 - acc: 0.0000e+00 - val_loss: 1.3099e-04 - val_acc: 0.0000e+00\n",
      "Epoch 195/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3732e-05 - acc: 0.0000e+00 - val_loss: 1.1213e-04 - val_acc: 0.0000e+00\n",
      "Epoch 196/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3969e-05 - acc: 0.0000e+00 - val_loss: 1.3187e-04 - val_acc: 0.0000e+00\n",
      "Epoch 197/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2717e-05 - acc: 0.0000e+00 - val_loss: 1.0646e-04 - val_acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.7569e-05 - acc: 0.0000e+00 - val_loss: 1.1197e-04 - val_acc: 0.0000e+00\n",
      "Epoch 199/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.7443e-05 - acc: 0.0000e+00 - val_loss: 1.0446e-04 - val_acc: 0.0000e+00\n",
      "Epoch 200/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2139e-05 - acc: 0.0000e+00 - val_loss: 1.0632e-04 - val_acc: 0.0000e+00\n",
      "Epoch 201/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.6544e-05 - acc: 0.0000e+00 - val_loss: 1.2540e-04 - val_acc: 0.0000e+00\n",
      "Epoch 202/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9468e-05 - acc: 0.0000e+00 - val_loss: 1.9867e-04 - val_acc: 0.0000e+00\n",
      "Epoch 203/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.1620e-05 - acc: 0.0000e+00 - val_loss: 1.0763e-04 - val_acc: 0.0000e+00\n",
      "Epoch 204/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.6003e-05 - acc: 0.0000e+00 - val_loss: 1.0648e-04 - val_acc: 0.0000e+00\n",
      "Epoch 205/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2303e-05 - acc: 0.0000e+00 - val_loss: 1.0303e-04 - val_acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9844e-05 - acc: 0.0000e+00 - val_loss: 1.0600e-04 - val_acc: 0.0000e+00\n",
      "Epoch 207/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2151e-05 - acc: 0.0000e+00 - val_loss: 1.4827e-04 - val_acc: 0.0000e+00\n",
      "Epoch 208/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4383e-05 - acc: 0.0000e+00 - val_loss: 1.1854e-04 - val_acc: 0.0000e+00\n",
      "Epoch 209/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9670e-05 - acc: 0.0000e+00 - val_loss: 1.0738e-04 - val_acc: 0.0000e+00\n",
      "Epoch 210/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8342e-05 - acc: 0.0000e+00 - val_loss: 1.0530e-04 - val_acc: 0.0000e+00\n",
      "Epoch 211/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3738e-05 - acc: 0.0000e+00 - val_loss: 1.0798e-04 - val_acc: 0.0000e+00\n",
      "Epoch 212/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.0454e-05 - acc: 0.0000e+00 - val_loss: 1.2263e-04 - val_acc: 0.0000e+00\n",
      "Epoch 213/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.1032e-05 - acc: 0.0000e+00 - val_loss: 1.3996e-04 - val_acc: 0.0000e+00\n",
      "Epoch 214/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9959e-05 - acc: 0.0000e+00 - val_loss: 1.1025e-04 - val_acc: 0.0000e+00\n",
      "Epoch 215/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.7925e-05 - acc: 0.0000e+00 - val_loss: 1.5510e-04 - val_acc: 0.0000e+00\n",
      "Epoch 216/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.1216e-05 - acc: 0.0000e+00 - val_loss: 1.9629e-04 - val_acc: 0.0000e+00\n",
      "Epoch 217/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.7475e-05 - acc: 0.0000e+00 - val_loss: 1.0115e-04 - val_acc: 0.0000e+00\n",
      "Epoch 218/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.1581e-05 - acc: 0.0000e+00 - val_loss: 1.1191e-04 - val_acc: 0.0000e+00\n",
      "Epoch 219/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.4284e-05 - acc: 0.0000e+00 - val_loss: 1.0124e-04 - val_acc: 0.0000e+00\n",
      "Epoch 220/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.7498e-05 - acc: 0.0000e+00 - val_loss: 1.1479e-04 - val_acc: 0.0000e+00\n",
      "Epoch 221/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8663e-05 - acc: 0.0000e+00 - val_loss: 1.7664e-04 - val_acc: 0.0000e+00\n",
      "Epoch 222/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.7405e-05 - acc: 0.0000e+00 - val_loss: 1.0198e-04 - val_acc: 0.0000e+00\n",
      "Epoch 223/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3040e-05 - acc: 0.0000e+00 - val_loss: 1.2547e-04 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.7431e-05 - acc: 0.0000e+00 - val_loss: 1.9220e-04 - val_acc: 0.0000e+00\n",
      "Epoch 225/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.5968e-05 - acc: 0.0000e+00 - val_loss: 1.5135e-04 - val_acc: 0.0000e+00\n",
      "Epoch 226/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2070e-05 - acc: 0.0000e+00 - val_loss: 1.4379e-04 - val_acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.4778e-05 - acc: 0.0000e+00 - val_loss: 1.2681e-04 - val_acc: 0.0000e+00\n",
      "Epoch 228/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3250e-05 - acc: 0.0000e+00 - val_loss: 9.7876e-05 - val_acc: 0.0000e+00\n",
      "Epoch 229/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.0361e-05 - acc: 0.0000e+00 - val_loss: 1.3320e-04 - val_acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8374e-05 - acc: 0.0000e+00 - val_loss: 1.3013e-04 - val_acc: 0.0000e+00\n",
      "Epoch 231/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.2750e-05 - acc: 0.0000e+00 - val_loss: 1.0110e-04 - val_acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3470e-05 - acc: 0.0000e+00 - val_loss: 1.1140e-04 - val_acc: 0.0000e+00\n",
      "Epoch 233/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.5594e-05 - acc: 0.0000e+00 - val_loss: 1.5273e-04 - val_acc: 0.0000e+00\n",
      "Epoch 234/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.2522e-05 - acc: 0.0000e+00 - val_loss: 1.1535e-04 - val_acc: 0.0000e+00\n",
      "Epoch 235/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.6578e-05 - acc: 0.0000e+00 - val_loss: 1.5998e-04 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.4088e-05 - acc: 0.0000e+00 - val_loss: 1.5390e-04 - val_acc: 0.0000e+00\n",
      "Epoch 237/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.6779e-05 - acc: 0.0000e+00 - val_loss: 1.4682e-04 - val_acc: 0.0000e+0000e+\n",
      "Epoch 238/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.7922e-05 - acc: 0.0000e+00 - val_loss: 9.3174e-05 - val_acc: 0.0000e+00\n",
      "Epoch 239/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3265e-05 - acc: 0.0000e+00 - val_loss: 1.8856e-04 - val_acc: 0.0000e+00\n",
      "Epoch 240/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9233e-05 - acc: 0.0000e+00 - val_loss: 1.8091e-04 - val_acc: 0.0000e+00\n",
      "Epoch 241/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3853e-05 - acc: 0.0000e+00 - val_loss: 3.0095e-04 - val_acc: 0.0000e+00\n",
      "Epoch 242/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.7781e-05 - acc: 0.0000e+00 - val_loss: 1.2316e-04 - val_acc: 0.0000e+00\n",
      "Epoch 243/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.1021e-05 - acc: 0.0000e+00 - val_loss: 1.5146e-04 - val_acc: 0.0000e+00\n",
      "Epoch 244/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.1456e-05 - acc: 0.0000e+00 - val_loss: 1.3466e-04 - val_acc: 0.0000e+00\n",
      "Epoch 245/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.5871e-05 - acc: 0.0000e+00 - val_loss: 1.2314e-04 - val_acc: 0.0000e+00\n",
      "Epoch 246/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3193e-05 - acc: 0.0000e+00 - val_loss: 1.0981e-04 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3116e-05 - acc: 0.0000e+00 - val_loss: 1.3150e-04 - val_acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.6954e-05 - acc: 0.0000e+00 - val_loss: 1.0201e-04 - val_acc: 0.0000e+00\n",
      "Epoch 249/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.1027e-05 - acc: 0.0000e+00 - val_loss: 2.4730e-04 - val_acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.0447e-05 - acc: 0.0000e+00 - val_loss: 1.1942e-04 - val_acc: 0.0000e+00\n",
      "Epoch 251/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.4079e-05 - acc: 0.0000e+00 - val_loss: 1.1747e-04 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.2458e-05 - acc: 0.0000e+00 - val_loss: 1.0363e-04 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.4177e-05 - acc: 0.0000e+00 - val_loss: 1.1266e-04 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3721e-05 - acc: 0.0000e+00 - val_loss: 1.1055e-04 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.0623e-05 - acc: 0.0000e+00 - val_loss: 1.2630e-04 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.7740e-05 - acc: 0.0000e+00 - val_loss: 1.0913e-04 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6993e-05 - acc: 0.0000e+00 - val_loss: 9.7524e-05 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.1242e-05 - acc: 0.0000e+00 - val_loss: 1.1515e-04 - val_acc: 0.0000e+00\n",
      "Epoch 259/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.2337e-05 - acc: 0.0000e+00 - val_loss: 9.7952e-05 - val_acc: 0.0000e+00\n",
      "Epoch 260/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.2440e-05 - acc: 0.0000e+00 - val_loss: 1.6855e-04 - val_acc: 0.0000e+00\n",
      "Epoch 261/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.5380e-05 - acc: 0.0000e+00 - val_loss: 1.2676e-04 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.0743e-05 - acc: 0.0000e+00 - val_loss: 2.2898e-04 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.5650e-05 - acc: 0.0000e+00 - val_loss: 1.0924e-04 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.8488e-05 - acc: 0.0000e+00 - val_loss: 8.8419e-05 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9993e-05 - acc: 0.0000e+00 - val_loss: 1.1606e-04 - val_acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9953e-05 - acc: 0.0000e+00 - val_loss: 1.3346e-04 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.1597e-05 - acc: 0.0000e+00 - val_loss: 1.6634e-04 - val_acc: 0.0000e+00\n",
      "Epoch 268/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3323e-05 - acc: 0.0000e+00 - val_loss: 1.3890e-04 - val_acc: 0.0000e+00\n",
      "Epoch 269/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.1693e-05 - acc: 0.0000e+00 - val_loss: 1.0279e-04 - val_acc: 0.0000e+00\n",
      "Epoch 270/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.0918e-05 - acc: 0.0000e+00 - val_loss: 9.3707e-05 - val_acc: 0.0000e+00\n",
      "Epoch 271/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13702/13702 [==============================] - 1s - loss: 4.9399e-05 - acc: 0.0000e+00 - val_loss: 1.0380e-04 - val_acc: 0.0000e+00\n",
      "Epoch 272/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3103e-05 - acc: 0.0000e+00 - val_loss: 1.4977e-04 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3189e-05 - acc: 0.0000e+00 - val_loss: 1.3721e-04 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.2630e-05 - acc: 0.0000e+00 - val_loss: 1.1542e-04 - val_acc: 0.0000e+00\n",
      "Epoch 275/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9756e-05 - acc: 0.0000e+00 - val_loss: 9.4683e-05 - val_acc: 0.0000e+00\n",
      "Epoch 276/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.7233e-05 - acc: 0.0000e+00 - val_loss: 9.0343e-05 - val_acc: 0.0000e+00\n",
      "Epoch 277/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5547e-05 - acc: 0.0000e+00 - val_loss: 9.0549e-05 - val_acc: 0.0000e+00\n",
      "Epoch 278/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.8327e-05 - acc: 0.0000e+00 - val_loss: 8.9974e-05 - val_acc: 0.0000e+00\n",
      "Epoch 279/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.7631e-05 - acc: 0.0000e+00 - val_loss: 9.6555e-05 - val_acc: 0.0000e+00\n",
      "Epoch 280/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.5944e-05 - acc: 0.0000e+00 - val_loss: 2.5733e-04 - val_acc: 0.0000e+00\n",
      "Epoch 281/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.1099e-05 - acc: 0.0000e+00 - val_loss: 1.9478e-04 - val_acc: 0.0000e+00\n",
      "Epoch 282/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.6470e-05 - acc: 0.0000e+00 - val_loss: 3.0808e-04 - val_acc: 0.0000e+00\n",
      "Epoch 283/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.4080e-05 - acc: 0.0000e+00 - val_loss: 1.0495e-04 - val_acc: 0.0000e+00\n",
      "Epoch 284/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9222e-05 - acc: 0.0000e+00 - val_loss: 8.4861e-05 - val_acc: 0.0000e+00\n",
      "Epoch 285/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.8117e-05 - acc: 0.0000e+00 - val_loss: 9.6464e-05 - val_acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8539e-05 - acc: 0.0000e+00 - val_loss: 9.0727e-05 - val_acc: 0.0000e+00\n",
      "Epoch 287/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9883e-05 - acc: 0.0000e+00 - val_loss: 8.1974e-05 - val_acc: 0.0000e+00\n",
      "Epoch 288/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5807e-05 - acc: 0.0000e+00 - val_loss: 1.4715e-04 - val_acc: 0.0000e+00\n",
      "Epoch 289/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.4835e-05 - acc: 0.0000e+00 - val_loss: 9.2197e-05 - val_acc: 0.0000e+00\n",
      "Epoch 290/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5945e-05 - acc: 0.0000e+00 - val_loss: 9.4772e-05 - val_acc: 0.0000e+00\n",
      "Epoch 291/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9566e-05 - acc: 0.0000e+00 - val_loss: 1.9376e-04 - val_acc: 0.0000e+00\n",
      "Epoch 292/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.0818e-05 - acc: 0.0000e+00 - val_loss: 1.0003e-04 - val_acc: 0.0000e+00\n",
      "Epoch 293/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9343e-05 - acc: 0.0000e+00 - val_loss: 9.5092e-05 - val_acc: 0.0000e+00\n",
      "Epoch 294/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9634e-05 - acc: 0.0000e+00 - val_loss: 1.1669e-04 - val_acc: 0.0000e+00\n",
      "Epoch 295/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.4528e-05 - acc: 0.0000e+00 - val_loss: 1.3761e-04 - val_acc: 0.0000e+00\n",
      "Epoch 296/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6013e-05 - acc: 0.0000e+00 - val_loss: 1.0861e-04 - val_acc: 0.0000e+00\n",
      "Epoch 297/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6978e-05 - acc: 0.0000e+00 - val_loss: 2.0963e-04 - val_acc: 0.0000e+00\n",
      "Epoch 298/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6692e-05 - acc: 0.0000e+00 - val_loss: 2.4573e-04 - val_acc: 0.0000e+00\n",
      "Epoch 299/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7129e-05 - acc: 0.0000e+00 - val_loss: 2.3804e-04 - val_acc: 0.0000e+00\n",
      "Epoch 300/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9061e-05 - acc: 0.0000e+00 - val_loss: 9.7557e-05 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00003 MSE (0.01 RMSE)\n",
      "Test Score: 0.01020 MSE (0.10 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_23 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_24 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13702 samples, validate on 1523 samples\n",
      "Epoch 1/300\n",
      "13702/13702 [==============================] - 3s - loss: 0.0122 - acc: 0.0000e+00 - val_loss: 0.0053 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.7047e-04 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.2440e-04 - acc: 0.0000e+00 - val_loss: 6.6885e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1595e-04 - acc: 0.0000e+00 - val_loss: 4.3015e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.9376e-04 - acc: 0.0000e+00 - val_loss: 4.0145e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6609e-04 - acc: 0.0000e+00 - val_loss: 4.6610e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.2988e-04 - acc: 0.0000e+00 - val_loss: 3.1850e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4119e-04 - acc: 0.0000e+00 - val_loss: 3.8677e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.1360e-04 - acc: 0.0000e+00 - val_loss: 3.4713e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.2563e-04 - acc: 0.0000e+00 - val_loss: 6.7438e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4692e-04 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3828e-04 - acc: 0.0000e+00 - val_loss: 2.6580e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.8596e-04 - acc: 0.0000e+00 - val_loss: 5.3410e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3137e-04 - acc: 0.0000e+00 - val_loss: 8.8481e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.0767e-04 - acc: 0.0000e+00 - val_loss: 4.8390e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.1022e-04 - acc: 0.0000e+00 - val_loss: 6.7400e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.8798e-04 - acc: 0.0000e+00 - val_loss: 9.7486e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.7987e-04 - acc: 0.0000e+00 - val_loss: 6.8535e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.8777e-04 - acc: 0.0000e+00 - val_loss: 5.7020e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.7076e-04 - acc: 0.0000e+00 - val_loss: 2.5843e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.2128e-04 - acc: 0.0000e+00 - val_loss: 2.6402e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.7462e-04 - acc: 0.0000e+00 - val_loss: 2.2810e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.6210e-04 - acc: 0.0000e+00 - val_loss: 3.5313e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.6585e-04 - acc: 0.0000e+00 - val_loss: 2.4631e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.1488e-04 - acc: 0.0000e+00 - val_loss: 3.3157e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.6708e-04 - acc: 0.0000e+00 - val_loss: 3.7416e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.5684e-04 - acc: 0.0000e+00 - val_loss: 7.9296e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.4138e-04 - acc: 0.0000e+00 - val_loss: 2.4181e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.3191e-04 - acc: 0.0000e+00 - val_loss: 2.1845e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.1511e-04 - acc: 0.0000e+00 - val_loss: 2.2446e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.2186e-04 - acc: 0.0000e+00 - val_loss: 2.0910e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.2725e-04 - acc: 0.0000e+00 - val_loss: 2.3561e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.2940e-04 - acc: 0.0000e+00 - val_loss: 3.1238e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.3394e-04 - acc: 0.0000e+00 - val_loss: 2.6932e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.1165e-04 - acc: 0.0000e+00 - val_loss: 2.1621e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.1584e-04 - acc: 0.0000e+00 - val_loss: 5.2774e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.5276e-04 - acc: 0.0000e+00 - val_loss: 8.2725e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.3478e-04 - acc: 0.0000e+00 - val_loss: 3.4009e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.3294e-04 - acc: 0.0000e+00 - val_loss: 3.9240e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.0828e-04 - acc: 0.0000e+00 - val_loss: 2.3799e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9982e-04 - acc: 0.0000e+00 - val_loss: 2.0431e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9265e-04 - acc: 0.0000e+00 - val_loss: 4.9360e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.0135e-04 - acc: 0.0000e+00 - val_loss: 4.0689e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9627e-04 - acc: 0.0000e+00 - val_loss: 1.8716e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7764e-04 - acc: 0.0000e+00 - val_loss: 1.8269e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7685e-04 - acc: 0.0000e+00 - val_loss: 2.4523e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8795e-04 - acc: 0.0000e+00 - val_loss: 1.9029e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6938e-04 - acc: 0.0000e+00 - val_loss: 2.9745e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7403e-04 - acc: 0.0000e+00 - val_loss: 3.7796e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.1103e-04 - acc: 0.0000e+00 - val_loss: 1.9371e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8192e-04 - acc: 0.0000e+00 - val_loss: 3.0683e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5982e-04 - acc: 0.0000e+00 - val_loss: 2.6178e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5126e-04 - acc: 0.0000e+00 - val_loss: 1.9760e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5014e-04 - acc: 0.0000e+00 - val_loss: 1.8921e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4582e-04 - acc: 0.0000e+00 - val_loss: 1.8051e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5007e-04 - acc: 0.0000e+00 - val_loss: 2.3593e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5949e-04 - acc: 0.0000e+00 - val_loss: 1.8523e-04 - val_acc: 0.0000e+0000e\n",
      "Epoch 58/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4790e-04 - acc: 0.0000e+00 - val_loss: 1.7967e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4080e-04 - acc: 0.0000e+00 - val_loss: 1.9178e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4572e-04 - acc: 0.0000e+00 - val_loss: 3.2454e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4715e-04 - acc: 0.0000e+00 - val_loss: 2.3090e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4608e-04 - acc: 0.0000e+00 - val_loss: 6.2801e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4033e-04 - acc: 0.0000e+00 - val_loss: 1.8970e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3022e-04 - acc: 0.0000e+00 - val_loss: 2.6361e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3015e-04 - acc: 0.0000e+00 - val_loss: 2.3959e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4517e-04 - acc: 0.0000e+00 - val_loss: 4.3565e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4071e-04 - acc: 0.0000e+00 - val_loss: 1.8595e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3564e-04 - acc: 0.0000e+00 - val_loss: 1.8283e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3175e-04 - acc: 0.0000e+00 - val_loss: 1.8106e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3212e-04 - acc: 0.0000e+00 - val_loss: 7.9079e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4142e-04 - acc: 0.0000e+00 - val_loss: 1.8438e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2241e-04 - acc: 0.0000e+00 - val_loss: 1.9637e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2134e-04 - acc: 0.0000e+00 - val_loss: 1.9795e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13702/13702 [==============================] - 1s - loss: 1.2303e-04 - acc: 0.0000e+00 - val_loss: 1.8200e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1591e-04 - acc: 0.0000e+00 - val_loss: 1.8617e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2509e-04 - acc: 0.0000e+00 - val_loss: 1.7907e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1656e-04 - acc: 0.0000e+00 - val_loss: 4.6717e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1367e-04 - acc: 0.0000e+00 - val_loss: 1.9309e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1463e-04 - acc: 0.0000e+00 - val_loss: 3.0223e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4130e-04 - acc: 0.0000e+00 - val_loss: 4.0616e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2613e-04 - acc: 0.0000e+00 - val_loss: 1.9107e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0481e-04 - acc: 0.0000e+00 - val_loss: 2.7407e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1483e-04 - acc: 0.0000e+00 - val_loss: 1.7773e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0660e-04 - acc: 0.0000e+00 - val_loss: 1.7335e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0524e-04 - acc: 0.0000e+00 - val_loss: 2.8505e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2553e-04 - acc: 0.0000e+00 - val_loss: 3.5930e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1682e-04 - acc: 0.0000e+00 - val_loss: 2.3035e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0375e-04 - acc: 0.0000e+00 - val_loss: 2.3473e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1400e-04 - acc: 0.0000e+00 - val_loss: 3.7711e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1315e-04 - acc: 0.0000e+00 - val_loss: 4.4780e-04 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0942e-04 - acc: 0.0000e+00 - val_loss: 1.8529e-04 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1823e-04 - acc: 0.0000e+00 - val_loss: 2.4751e-04 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0368e-04 - acc: 0.0000e+00 - val_loss: 1.8130e-04 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1755e-04 - acc: 0.0000e+00 - val_loss: 3.8385e-04 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1459e-04 - acc: 0.0000e+00 - val_loss: 1.7053e-04 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1151e-04 - acc: 0.0000e+00 - val_loss: 1.6789e-04 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0477e-04 - acc: 0.0000e+00 - val_loss: 2.1350e-04 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.4519e-05 - acc: 0.0000e+00 - val_loss: 2.1274e-04 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.8510e-05 - acc: 0.0000e+00 - val_loss: 2.3352e-04 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0034e-04 - acc: 0.0000e+00 - val_loss: 2.5685e-04 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3274e-05 - acc: 0.0000e+00 - val_loss: 2.0058e-04 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.9318e-05 - acc: 0.0000e+00 - val_loss: 1.5693e-04 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.7682e-05 - acc: 0.0000e+00 - val_loss: 1.6589e-04 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.4833e-05 - acc: 0.0000e+00 - val_loss: 1.7036e-04 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.0899e-05 - acc: 0.0000e+00 - val_loss: 1.6080e-04 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.7552e-05 - acc: 0.0000e+00 - val_loss: 1.7142e-04 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.7904e-05 - acc: 0.0000e+00 - val_loss: 2.0942e-04 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.9562e-05 - acc: 0.0000e+00 - val_loss: 1.8925e-04 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3547e-05 - acc: 0.0000e+00 - val_loss: 1.7102e-04 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3139e-05 - acc: 0.0000e+00 - val_loss: 1.5895e-04 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.2996e-05 - acc: 0.0000e+00 - val_loss: 2.3519e-04 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.4501e-05 - acc: 0.0000e+00 - val_loss: 2.2187e-04 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.8456e-05 - acc: 0.0000e+00 - val_loss: 1.5875e-04 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3571e-05 - acc: 0.0000e+00 - val_loss: 3.6666e-04 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1100e-04 - acc: 0.0000e+00 - val_loss: 2.5856e-04 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0639e-04 - acc: 0.0000e+00 - val_loss: 1.8973e-04 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.6261e-05 - acc: 0.0000e+00 - val_loss: 1.4700e-04 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.7523e-05 - acc: 0.0000e+00 - val_loss: 1.7699e-04 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3360e-05 - acc: 0.0000e+00 - val_loss: 2.2095e-04 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.2376e-05 - acc: 0.0000e+00 - val_loss: 1.4597e-04 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0325e-04 - acc: 0.0000e+00 - val_loss: 1.6012e-04 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.7587e-05 - acc: 0.0000e+00 - val_loss: 2.6337e-04 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.5263e-05 - acc: 0.0000e+00 - val_loss: 1.4663e-04 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.7693e-05 - acc: 0.0000e+00 - val_loss: 1.6658e-04 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3065e-05 - acc: 0.0000e+00 - val_loss: 1.5384e-04 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3290e-05 - acc: 0.0000e+00 - val_loss: 2.8128e-04 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.8766e-05 - acc: 0.0000e+00 - val_loss: 1.5554e-04 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.4625e-05 - acc: 0.0000e+00 - val_loss: 1.4093e-04 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9797e-05 - acc: 0.0000e+00 - val_loss: 1.6108e-04 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.7305e-05 - acc: 0.0000e+00 - val_loss: 1.5108e-04 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.4592e-05 - acc: 0.0000e+00 - val_loss: 2.5204e-04 - val_acc: 0.0000e+00\n",
      "Epoch 132/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9475e-05 - acc: 0.0000e+00 - val_loss: 2.6891e-04 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.8622e-05 - acc: 0.0000e+00 - val_loss: 1.7379e-04 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.6863e-05 - acc: 0.0000e+00 - val_loss: 1.4904e-04 - val_acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.7840e-05 - acc: 0.0000e+00 - val_loss: 1.4870e-04 - val_acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.1085e-05 - acc: 0.0000e+00 - val_loss: 1.6426e-04 - val_acc: 0.0000e+00\n",
      "Epoch 137/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3865e-05 - acc: 0.0000e+00 - val_loss: 1.3573e-04 - val_acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.4224e-05 - acc: 0.0000e+00 - val_loss: 1.4545e-04 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3954e-05 - acc: 0.0000e+00 - val_loss: 2.2154e-04 - val_acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.2639e-05 - acc: 0.0000e+00 - val_loss: 1.6129e-04 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.7703e-05 - acc: 0.0000e+00 - val_loss: 2.3872e-04 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.5087e-05 - acc: 0.0000e+00 - val_loss: 1.7779e-04 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3217e-05 - acc: 0.0000e+00 - val_loss: 3.8392e-04 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.5180e-05 - acc: 0.0000e+00 - val_loss: 1.4202e-04 - val_acc: 0.0000e+00- ETA: 0s - loss: 9.2897e-05 - \n",
      "Epoch 145/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1882e-05 - acc: 0.0000e+00 - val_loss: 4.0928e-04 - val_acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.8688e-05 - acc: 0.0000e+00 - val_loss: 1.6493e-04 - val_acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.4141e-05 - acc: 0.0000e+00 - val_loss: 1.4611e-04 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3430e-05 - acc: 0.0000e+00 - val_loss: 1.4648e-04 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.7399e-05 - acc: 0.0000e+00 - val_loss: 2.6628e-04 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.9887e-05 - acc: 0.0000e+00 - val_loss: 3.6011e-04 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9753e-05 - acc: 0.0000e+00 - val_loss: 1.6192e-04 - val_acc: 0.0000e+0000e+\n",
      "Epoch 152/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.1634e-05 - acc: 0.0000e+00 - val_loss: 2.2466e-04 - val_acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.4826e-05 - acc: 0.0000e+00 - val_loss: 2.2539e-04 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.6112e-05 - acc: 0.0000e+00 - val_loss: 2.3590e-04 - val_acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1982e-05 - acc: 0.0000e+00 - val_loss: 3.2697e-04 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.7359e-05 - acc: 0.0000e+00 - val_loss: 2.6198e-04 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8296e-05 - acc: 0.0000e+00 - val_loss: 1.4091e-04 - val_acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.6299e-05 - acc: 0.0000e+00 - val_loss: 1.3684e-04 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1581e-05 - acc: 0.0000e+00 - val_loss: 1.9708e-04 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3794e-05 - acc: 0.0000e+00 - val_loss: 1.6217e-04 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8962e-05 - acc: 0.0000e+00 - val_loss: 2.3966e-04 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.5534e-05 - acc: 0.0000e+00 - val_loss: 2.1543e-04 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.7931e-05 - acc: 0.0000e+00 - val_loss: 1.5492e-04 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2376e-05 - acc: 0.0000e+00 - val_loss: 2.6767e-04 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1835e-05 - acc: 0.0000e+00 - val_loss: 2.7275e-04 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3535e-05 - acc: 0.0000e+00 - val_loss: 1.8911e-04 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.6043e-05 - acc: 0.0000e+00 - val_loss: 1.3252e-04 - val_acc: 0.0000e+00\n",
      "Epoch 168/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2925e-05 - acc: 0.0000e+00 - val_loss: 2.0640e-04 - val_acc: 0.0000e+00\n",
      "Epoch 169/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.5092e-05 - acc: 0.0000e+00 - val_loss: 1.5972e-04 - val_acc: 0.0000e+00\n",
      "Epoch 170/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.6507e-05 - acc: 0.0000e+00 - val_loss: 1.5043e-04 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.7465e-05 - acc: 0.0000e+00 - val_loss: 1.6337e-04 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.3987e-05 - acc: 0.0000e+00 - val_loss: 1.7387e-04 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.6153e-05 - acc: 0.0000e+00 - val_loss: 3.8340e-04 - val_acc: 0.0000e+00\n",
      "Epoch 174/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8529e-05 - acc: 0.0000e+00 - val_loss: 1.9490e-04 - val_acc: 0.0000e+00\n",
      "Epoch 175/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1338e-05 - acc: 0.0000e+00 - val_loss: 1.6970e-04 - val_acc: 0.0000e+00\n",
      "Epoch 176/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3363e-05 - acc: 0.0000e+00 - val_loss: 3.0670e-04 - val_acc: 0.0000e+00\n",
      "Epoch 177/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.4150e-05 - acc: 0.0000e+00 - val_loss: 1.5438e-04 - val_acc: 0.0000e+00\n",
      "Epoch 178/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1480e-05 - acc: 0.0000e+00 - val_loss: 1.5380e-04 - val_acc: 0.0000e+00\n",
      "Epoch 179/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.2509e-05 - acc: 0.0000e+00 - val_loss: 2.7066e-04 - val_acc: 0.0000e+00\n",
      "Epoch 180/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.5510e-05 - acc: 0.0000e+00 - val_loss: 1.3650e-04 - val_acc: 0.0000e+00\n",
      "Epoch 181/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4630e-05 - acc: 0.0000e+00 - val_loss: 1.3353e-04 - val_acc: 0.0000e+00\n",
      "Epoch 182/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.5565e-05 - acc: 0.0000e+00 - val_loss: 1.4595e-04 - val_acc: 0.0000e+00\n",
      "Epoch 183/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.5393e-05 - acc: 0.0000e+00 - val_loss: 1.5411e-04 - val_acc: 0.0000e+00\n",
      "Epoch 184/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2473e-05 - acc: 0.0000e+00 - val_loss: 2.4780e-04 - val_acc: 0.0000e+00\n",
      "Epoch 185/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13702/13702 [==============================] - 1s - loss: 7.0011e-05 - acc: 0.0000e+00 - val_loss: 1.3751e-04 - val_acc: 0.0000e+00\n",
      "Epoch 186/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2437e-05 - acc: 0.0000e+00 - val_loss: 1.4915e-04 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0253e-05 - acc: 0.0000e+00 - val_loss: 1.3225e-04 - val_acc: 0.0000e+00\n",
      "Epoch 188/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2093e-05 - acc: 0.0000e+00 - val_loss: 1.9258e-04 - val_acc: 0.0000e+00\n",
      "Epoch 189/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4188e-05 - acc: 0.0000e+00 - val_loss: 1.4524e-04 - val_acc: 0.0000e+00\n",
      "Epoch 190/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2855e-05 - acc: 0.0000e+00 - val_loss: 2.9472e-04 - val_acc: 0.0000e+00\n",
      "Epoch 191/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2461e-05 - acc: 0.0000e+00 - val_loss: 1.4657e-04 - val_acc: 0.0000e+00\n",
      "Epoch 192/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6744e-05 - acc: 0.0000e+00 - val_loss: 1.6275e-04 - val_acc: 0.0000e+00\n",
      "Epoch 193/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.5481e-05 - acc: 0.0000e+00 - val_loss: 1.3530e-04 - val_acc: 0.0000e+00\n",
      "Epoch 194/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.8632e-05 - acc: 0.0000e+00 - val_loss: 1.2967e-04 - val_acc: 0.0000e+00\n",
      "Epoch 195/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9056e-05 - acc: 0.0000e+00 - val_loss: 3.0873e-04 - val_acc: 0.0000e+00\n",
      "Epoch 196/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2150e-05 - acc: 0.0000e+00 - val_loss: 1.6989e-04 - val_acc: 0.0000e+00\n",
      "Epoch 197/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2870e-05 - acc: 0.0000e+00 - val_loss: 1.4103e-04 - val_acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.8973e-05 - acc: 0.0000e+00 - val_loss: 2.6675e-04 - val_acc: 0.0000e+00\n",
      "Epoch 199/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4724e-05 - acc: 0.0000e+00 - val_loss: 2.9920e-04 - val_acc: 0.0000e+00\n",
      "Epoch 200/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7994e-05 - acc: 0.0000e+00 - val_loss: 1.4166e-04 - val_acc: 0.0000e+00\n",
      "Epoch 201/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2931e-05 - acc: 0.0000e+00 - val_loss: 1.3818e-04 - val_acc: 0.0000e+00\n",
      "Epoch 202/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0781e-05 - acc: 0.0000e+00 - val_loss: 1.9384e-04 - val_acc: 0.0000e+00\n",
      "Epoch 203/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.8066e-05 - acc: 0.0000e+00 - val_loss: 2.6163e-04 - val_acc: 0.0000e+00\n",
      "Epoch 204/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2765e-05 - acc: 0.0000e+00 - val_loss: 1.4740e-04 - val_acc: 0.0000e+00\n",
      "Epoch 205/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9020e-05 - acc: 0.0000e+00 - val_loss: 2.2461e-04 - val_acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4533e-05 - acc: 0.0000e+00 - val_loss: 1.2598e-04 - val_acc: 0.0000e+00\n",
      "Epoch 207/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4241e-05 - acc: 0.0000e+00 - val_loss: 1.3926e-04 - val_acc: 0.0000e+00\n",
      "Epoch 208/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.8445e-05 - acc: 0.0000e+00 - val_loss: 1.3943e-04 - val_acc: 0.0000e+00\n",
      "Epoch 209/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0971e-05 - acc: 0.0000e+00 - val_loss: 1.3019e-04 - val_acc: 0.0000e+00\n",
      "Epoch 210/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7642e-05 - acc: 0.0000e+00 - val_loss: 1.2290e-04 - val_acc: 0.0000e+00\n",
      "Epoch 211/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7466e-05 - acc: 0.0000e+00 - val_loss: 1.2665e-04 - val_acc: 0.0000e+00\n",
      "Epoch 212/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2971e-05 - acc: 0.0000e+00 - val_loss: 1.8148e-04 - val_acc: 0.0000e+00\n",
      "Epoch 213/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7039e-05 - acc: 0.0000e+00 - val_loss: 1.7107e-04 - val_acc: 0.0000e+00\n",
      "Epoch 214/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.3798e-05 - acc: 0.0000e+00 - val_loss: 1.8323e-04 - val_acc: 0.0000e+00\n",
      "Epoch 215/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8293e-05 - acc: 0.0000e+00 - val_loss: 1.3636e-04 - val_acc: 0.0000e+00\n",
      "Epoch 216/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.3974e-05 - acc: 0.0000e+00 - val_loss: 3.7898e-04 - val_acc: 0.0000e+00\n",
      "Epoch 217/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0591e-05 - acc: 0.0000e+00 - val_loss: 2.3778e-04 - val_acc: 0.0000e+00\n",
      "Epoch 218/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.8926e-05 - acc: 0.0000e+00 - val_loss: 1.1722e-04 - val_acc: 0.0000e+00\n",
      "Epoch 219/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.9471e-05 - acc: 0.0000e+00 - val_loss: 2.1587e-04 - val_acc: 0.0000e+00\n",
      "Epoch 220/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7361e-05 - acc: 0.0000e+00 - val_loss: 1.6339e-04 - val_acc: 0.0000e+00\n",
      "Epoch 221/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.6394e-05 - acc: 0.0000e+00 - val_loss: 2.5797e-04 - val_acc: 0.0000e+00\n",
      "Epoch 222/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1036e-05 - acc: 0.0000e+00 - val_loss: 1.2630e-04 - val_acc: 0.0000e+00\n",
      "Epoch 223/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4041e-05 - acc: 0.0000e+00 - val_loss: 1.7537e-04 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.5730e-05 - acc: 0.0000e+00 - val_loss: 1.6541e-04 - val_acc: 0.0000e+00\n",
      "Epoch 225/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7732e-05 - acc: 0.0000e+00 - val_loss: 1.4778e-04 - val_acc: 0.0000e+00\n",
      "Epoch 226/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.5896e-05 - acc: 0.0000e+00 - val_loss: 1.8634e-04 - val_acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0838e-05 - acc: 0.0000e+00 - val_loss: 1.3258e-04 - val_acc: 0.0000e+00\n",
      "Epoch 228/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.5321e-05 - acc: 0.0000e+00 - val_loss: 2.6912e-04 - val_acc: 0.0000e+00\n",
      "Epoch 229/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2472e-05 - acc: 0.0000e+00 - val_loss: 1.4378e-04 - val_acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.8706e-05 - acc: 0.0000e+00 - val_loss: 1.5918e-04 - val_acc: 0.0000e+00\n",
      "Epoch 231/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3799e-05 - acc: 0.0000e+00 - val_loss: 1.4681e-04 - val_acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0157e-05 - acc: 0.0000e+00 - val_loss: 1.2865e-04 - val_acc: 0.0000e+00\n",
      "Epoch 233/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7393e-05 - acc: 0.0000e+00 - val_loss: 1.6412e-04 - val_acc: 0.0000e+00\n",
      "Epoch 234/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6449e-05 - acc: 0.0000e+00 - val_loss: 1.2397e-04 - val_acc: 0.0000e+00\n",
      "Epoch 235/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6478e-05 - acc: 0.0000e+00 - val_loss: 4.2292e-04 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0995e-05 - acc: 0.0000e+00 - val_loss: 1.9373e-04 - val_acc: 0.0000e+00\n",
      "Epoch 237/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3382e-05 - acc: 0.0000e+00 - val_loss: 1.3537e-04 - val_acc: 0.0000e+00\n",
      "Epoch 238/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4566e-05 - acc: 0.0000e+00 - val_loss: 1.8424e-04 - val_acc: 0.0000e+00\n",
      "Epoch 239/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2515e-05 - acc: 0.0000e+00 - val_loss: 1.7937e-04 - val_acc: 0.0000e+00\n",
      "Epoch 240/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2237e-05 - acc: 0.0000e+00 - val_loss: 1.5285e-04 - val_acc: 0.0000e+00\n",
      "Epoch 241/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2276e-05 - acc: 0.0000e+00 - val_loss: 1.3065e-04 - val_acc: 0.0000e+00\n",
      "Epoch 242/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.3451e-05 - acc: 0.0000e+00 - val_loss: 1.2664e-04 - val_acc: 0.0000e+00\n",
      "Epoch 243/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.8749e-05 - acc: 0.0000e+00 - val_loss: 5.3545e-04 - val_acc: 0.0000e+00\n",
      "Epoch 244/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.5261e-05 - acc: 0.0000e+00 - val_loss: 1.8167e-04 - val_acc: 0.0000e+00\n",
      "Epoch 245/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.9969e-05 - acc: 0.0000e+00 - val_loss: 1.9029e-04 - val_acc: 0.0000e+00\n",
      "Epoch 246/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4475e-05 - acc: 0.0000e+00 - val_loss: 1.1217e-04 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.1917e-05 - acc: 0.0000e+00 - val_loss: 1.1719e-04 - val_acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.1874e-05 - acc: 0.0000e+00 - val_loss: 1.4093e-04 - val_acc: 0.0000e+00\n",
      "Epoch 249/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.1113e-05 - acc: 0.0000e+00 - val_loss: 2.7620e-04 - val_acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.5746e-05 - acc: 0.0000e+00 - val_loss: 3.2060e-04 - val_acc: 0.0000e+00\n",
      "Epoch 251/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2537e-05 - acc: 0.0000e+00 - val_loss: 1.6536e-04 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.0386e-05 - acc: 0.0000e+00 - val_loss: 1.8480e-04 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7452e-05 - acc: 0.0000e+00 - val_loss: 1.7845e-04 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.9035e-05 - acc: 0.0000e+00 - val_loss: 1.3608e-04 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6192e-05 - acc: 0.0000e+00 - val_loss: 1.4072e-04 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.0930e-05 - acc: 0.0000e+00 - val_loss: 1.5739e-04 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8575e-05 - acc: 0.0000e+00 - val_loss: 2.4562e-04 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6940e-05 - acc: 0.0000e+00 - val_loss: 1.1496e-04 - val_acc: 0.0000e+00\n",
      "Epoch 259/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9611e-05 - acc: 0.0000e+00 - val_loss: 1.3642e-04 - val_acc: 0.0000e+00\n",
      "Epoch 260/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6243e-05 - acc: 0.0000e+00 - val_loss: 1.6713e-04 - val_acc: 0.0000e+00\n",
      "Epoch 261/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2638e-05 - acc: 0.0000e+00 - val_loss: 1.3231e-04 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8092e-05 - acc: 0.0000e+00 - val_loss: 1.4920e-04 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2144e-05 - acc: 0.0000e+00 - val_loss: 1.2118e-04 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9098e-05 - acc: 0.0000e+00 - val_loss: 1.2568e-04 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3898e-05 - acc: 0.0000e+00 - val_loss: 1.3974e-04 - val_acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2485e-05 - acc: 0.0000e+00 - val_loss: 1.3433e-04 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9859e-05 - acc: 0.0000e+00 - val_loss: 1.7175e-04 - val_acc: 0.0000e+00\n",
      "Epoch 268/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8895e-05 - acc: 0.0000e+00 - val_loss: 2.5076e-04 - val_acc: 0.0000e+00\n",
      "Epoch 269/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.7728e-05 - acc: 0.0000e+00 - val_loss: 1.8304e-04 - val_acc: 0.0000e+00\n",
      "Epoch 270/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.5977e-05 - acc: 0.0000e+00 - val_loss: 1.4892e-04 - val_acc: 0.0000e+00\n",
      "Epoch 271/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9828e-05 - acc: 0.0000e+00 - val_loss: 1.1163e-04 - val_acc: 0.0000e+00\n",
      "Epoch 272/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.7622e-05 - acc: 0.0000e+00 - val_loss: 1.5074e-04 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2082e-05 - acc: 0.0000e+00 - val_loss: 1.5785e-04 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.0645e-05 - acc: 0.0000e+00 - val_loss: 1.9091e-04 - val_acc: 0.0000e+00\n",
      "Epoch 275/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.4244e-05 - acc: 0.0000e+00 - val_loss: 2.0193e-04 - val_acc: 0.0000e+00\n",
      "Epoch 276/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2321e-05 - acc: 0.0000e+00 - val_loss: 1.8155e-04 - val_acc: 0.0000e+00\n",
      "Epoch 277/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.5340e-05 - acc: 0.0000e+00 - val_loss: 1.2953e-04 - val_acc: 0.0000e+00\n",
      "Epoch 278/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8348e-05 - acc: 0.0000e+00 - val_loss: 1.3199e-04 - val_acc: 0.0000e+00\n",
      "Epoch 279/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3089e-05 - acc: 0.0000e+00 - val_loss: 1.1697e-04 - val_acc: 0.0000e+00\n",
      "Epoch 280/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8283e-05 - acc: 0.0000e+00 - val_loss: 1.5540e-04 - val_acc: 0.0000e+00\n",
      "Epoch 281/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.0832e-05 - acc: 0.0000e+00 - val_loss: 1.0603e-04 - val_acc: 0.0000e+00\n",
      "Epoch 282/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4353e-05 - acc: 0.0000e+00 - val_loss: 1.2747e-04 - val_acc: 0.0000e+00\n",
      "Epoch 283/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9952e-05 - acc: 0.0000e+00 - val_loss: 1.3812e-04 - val_acc: 0.0000e+00\n",
      "Epoch 284/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.7292e-05 - acc: 0.0000e+00 - val_loss: 1.3522e-04 - val_acc: 0.0000e+00\n",
      "Epoch 285/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8882e-05 - acc: 0.0000e+00 - val_loss: 1.1946e-04 - val_acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.5171e-05 - acc: 0.0000e+00 - val_loss: 1.1019e-04 - val_acc: 0.0000e+00\n",
      "Epoch 287/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9218e-05 - acc: 0.0000e+00 - val_loss: 4.5908e-04 - val_acc: 0.0000e+00\n",
      "Epoch 288/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.5222e-05 - acc: 0.0000e+00 - val_loss: 1.4138e-04 - val_acc: 0.0000e+00\n",
      "Epoch 289/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.0875e-05 - acc: 0.0000e+00 - val_loss: 1.6488e-04 - val_acc: 0.0000e+00\n",
      "Epoch 290/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8259e-05 - acc: 0.0000e+00 - val_loss: 1.0965e-04 - val_acc: 0.0000e+00\n",
      "Epoch 291/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2715e-05 - acc: 0.0000e+00 - val_loss: 1.2354e-04 - val_acc: 0.0000e+00\n",
      "Epoch 292/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.6251e-05 - acc: 0.0000e+00 - val_loss: 4.3120e-04 - val_acc: 0.0000e+00\n",
      "Epoch 293/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6403e-05 - acc: 0.0000e+00 - val_loss: 2.2879e-04 - val_acc: 0.0000e+00\n",
      "Epoch 294/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9023e-05 - acc: 0.0000e+00 - val_loss: 1.2297e-04 - val_acc: 0.0000e+00\n",
      "Epoch 295/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.6180e-05 - acc: 0.0000e+00 - val_loss: 1.2277e-04 - val_acc: 0.0000e+00\n",
      "Epoch 296/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8272e-05 - acc: 0.0000e+00 - val_loss: 1.1051e-04 - val_acc: 0.0000e+00\n",
      "Epoch 297/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13702/13702 [==============================] - 1s - loss: 5.6324e-05 - acc: 0.0000e+00 - val_loss: 2.8671e-04 - val_acc: 0.0000e+00\n",
      "Epoch 298/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9531e-05 - acc: 0.0000e+00 - val_loss: 2.0190e-04 - val_acc: 0.0000e+00\n",
      "Epoch 299/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.8640e-05 - acc: 0.0000e+00 - val_loss: 3.7049e-04 - val_acc: 0.0000e+00\n",
      "Epoch 300/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4655e-05 - acc: 0.0000e+00 - val_loss: 1.9034e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00004 MSE (0.01 RMSE)\n",
      "Test Score: 0.01902 MSE (0.14 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_25 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_26 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13702 samples, validate on 1523 samples\n",
      "Epoch 1/300\n",
      "13702/13702 [==============================] - 3s - loss: 0.0127 - acc: 0.0000e+00 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "13702/13702 [==============================] - 1s - loss: 0.0011 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4386e-04 - acc: 0.0000e+00 - val_loss: 5.4717e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.5911e-04 - acc: 0.0000e+00 - val_loss: 4.4798e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6878e-04 - acc: 0.0000e+00 - val_loss: 4.6753e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.0826e-04 - acc: 0.0000e+00 - val_loss: 7.1541e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.7876e-04 - acc: 0.0000e+00 - val_loss: 2.7994e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5514e-04 - acc: 0.0000e+00 - val_loss: 2.9044e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.3154e-04 - acc: 0.0000e+00 - val_loss: 2.6270e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1989e-04 - acc: 0.0000e+00 - val_loss: 2.5304e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0541e-04 - acc: 0.0000e+00 - val_loss: 2.9865e-04 - val_acc: 0.0000e+0000e\n",
      "Epoch 12/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.4254e-04 - acc: 0.0000e+00 - val_loss: 8.1913e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1472e-04 - acc: 0.0000e+00 - val_loss: 4.6979e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5242e-04 - acc: 0.0000e+00 - val_loss: 3.1256e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2801e-04 - acc: 0.0000e+00 - val_loss: 4.7598e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7100e-04 - acc: 0.0000e+00 - val_loss: 3.2847e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6308e-04 - acc: 0.0000e+00 - val_loss: 4.8486e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.9300e-04 - acc: 0.0000e+00 - val_loss: 2.7858e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7778e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5661e-04 - acc: 0.0000e+00 - val_loss: 4.5353e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3533e-04 - acc: 0.0000e+00 - val_loss: 3.3419e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4494e-04 - acc: 0.0000e+00 - val_loss: 2.2743e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.0804e-04 - acc: 0.0000e+00 - val_loss: 2.8642e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3852e-04 - acc: 0.0000e+00 - val_loss: 8.6978e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.1388e-04 - acc: 0.0000e+00 - val_loss: 3.2524e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.1022e-04 - acc: 0.0000e+00 - val_loss: 2.3178e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.8452e-04 - acc: 0.0000e+00 - val_loss: 2.4241e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.9892e-04 - acc: 0.0000e+00 - val_loss: 4.2017e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.9662e-04 - acc: 0.0000e+00 - val_loss: 2.4998e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.7747e-04 - acc: 0.0000e+00 - val_loss: 2.0171e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.6957e-04 - acc: 0.0000e+00 - val_loss: 3.4630e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.6704e-04 - acc: 0.0000e+00 - val_loss: 2.0108e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.5439e-04 - acc: 0.0000e+00 - val_loss: 2.1021e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.5575e-04 - acc: 0.0000e+00 - val_loss: 2.0457e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.4987e-04 - acc: 0.0000e+00 - val_loss: 1.9787e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.5587e-04 - acc: 0.0000e+00 - val_loss: 3.0186e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.3401e-04 - acc: 0.0000e+00 - val_loss: 3.8604e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.3493e-04 - acc: 0.0000e+00 - val_loss: 1.9353e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.3649e-04 - acc: 0.0000e+00 - val_loss: 3.4251e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.1416e-04 - acc: 0.0000e+00 - val_loss: 4.9627e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.1964e-04 - acc: 0.0000e+00 - val_loss: 4.9572e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9810e-04 - acc: 0.0000e+00 - val_loss: 2.1679e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.2570e-04 - acc: 0.0000e+00 - val_loss: 2.0586e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.0277e-04 - acc: 0.0000e+00 - val_loss: 3.8255e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9291e-04 - acc: 0.0000e+00 - val_loss: 3.8149e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9607e-04 - acc: 0.0000e+00 - val_loss: 9.4827e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.0954e-04 - acc: 0.0000e+00 - val_loss: 2.3133e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8128e-04 - acc: 0.0000e+00 - val_loss: 1.9753e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8207e-04 - acc: 0.0000e+00 - val_loss: 4.3097e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7184e-04 - acc: 0.0000e+00 - val_loss: 2.4755e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7364e-04 - acc: 0.0000e+00 - val_loss: 2.9544e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7096e-04 - acc: 0.0000e+00 - val_loss: 5.7128e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6964e-04 - acc: 0.0000e+00 - val_loss: 2.1292e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7671e-04 - acc: 0.0000e+00 - val_loss: 3.9969e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5702e-04 - acc: 0.0000e+00 - val_loss: 5.4666e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6992e-04 - acc: 0.0000e+00 - val_loss: 2.9789e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6094e-04 - acc: 0.0000e+00 - val_loss: 4.2323e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7045e-04 - acc: 0.0000e+00 - val_loss: 2.1987e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5717e-04 - acc: 0.0000e+00 - val_loss: 5.0090e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5769e-04 - acc: 0.0000e+00 - val_loss: 2.3909e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5693e-04 - acc: 0.0000e+00 - val_loss: 2.4203e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5487e-04 - acc: 0.0000e+00 - val_loss: 2.1495e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6468e-04 - acc: 0.0000e+00 - val_loss: 3.7309e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5239e-04 - acc: 0.0000e+00 - val_loss: 4.1053e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4429e-04 - acc: 0.0000e+00 - val_loss: 2.8143e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5112e-04 - acc: 0.0000e+00 - val_loss: 2.2238e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5104e-04 - acc: 0.0000e+00 - val_loss: 6.9409e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6073e-04 - acc: 0.0000e+00 - val_loss: 2.6559e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4011e-04 - acc: 0.0000e+00 - val_loss: 1.9698e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4121e-04 - acc: 0.0000e+00 - val_loss: 7.9541e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3430e-04 - acc: 0.0000e+00 - val_loss: 1.9281e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3912e-04 - acc: 0.0000e+00 - val_loss: 2.1734e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2586e-04 - acc: 0.0000e+00 - val_loss: 2.0766e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3371e-04 - acc: 0.0000e+00 - val_loss: 2.6869e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3078e-04 - acc: 0.0000e+00 - val_loss: 2.6931e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3657e-04 - acc: 0.0000e+00 - val_loss: 3.4031e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3356e-04 - acc: 0.0000e+00 - val_loss: 2.9700e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2530e-04 - acc: 0.0000e+00 - val_loss: 6.4052e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3424e-04 - acc: 0.0000e+00 - val_loss: 2.3059e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3022e-04 - acc: 0.0000e+00 - val_loss: 1.8061e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2594e-04 - acc: 0.0000e+00 - val_loss: 2.8664e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1836e-04 - acc: 0.0000e+00 - val_loss: 2.7994e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2215e-04 - acc: 0.0000e+00 - val_loss: 4.1451e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2452e-04 - acc: 0.0000e+00 - val_loss: 4.5247e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1907e-04 - acc: 0.0000e+00 - val_loss: 3.5772e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2178e-04 - acc: 0.0000e+00 - val_loss: 2.4325e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2205e-04 - acc: 0.0000e+00 - val_loss: 1.7202e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3277e-04 - acc: 0.0000e+00 - val_loss: 2.9559e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1644e-04 - acc: 0.0000e+00 - val_loss: 1.7751e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1919e-04 - acc: 0.0000e+00 - val_loss: 2.4570e-04 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1800e-04 - acc: 0.0000e+00 - val_loss: 2.8960e-04 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1036e-04 - acc: 0.0000e+00 - val_loss: 2.1366e-04 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2211e-04 - acc: 0.0000e+00 - val_loss: 2.0458e-04 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1221e-04 - acc: 0.0000e+00 - val_loss: 2.2724e-04 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0279e-04 - acc: 0.0000e+00 - val_loss: 1.8861e-04 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0649e-04 - acc: 0.0000e+00 - val_loss: 3.6068e-04 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1200e-04 - acc: 0.0000e+00 - val_loss: 2.7149e-04 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0834e-04 - acc: 0.0000e+00 - val_loss: 4.6287e-04 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3148e-04 - acc: 0.0000e+00 - val_loss: 2.2160e-04 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1892e-04 - acc: 0.0000e+00 - val_loss: 1.8485e-04 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13702/13702 [==============================] - 1s - loss: 1.0123e-04 - acc: 0.0000e+00 - val_loss: 4.0034e-04 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0113e-04 - acc: 0.0000e+00 - val_loss: 2.7637e-04 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0429e-04 - acc: 0.0000e+00 - val_loss: 1.7193e-04 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1349e-04 - acc: 0.0000e+00 - val_loss: 2.3464e-04 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1262e-04 - acc: 0.0000e+00 - val_loss: 1.6379e-04 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1030e-04 - acc: 0.0000e+00 - val_loss: 1.4948e-04 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0890e-04 - acc: 0.0000e+00 - val_loss: 1.7867e-04 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0323e-04 - acc: 0.0000e+00 - val_loss: 2.7668e-04 - val_acc: 0.0000e+00 ETA: 1s - loss: 1.0399e-04 -\n",
      "Epoch 109/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1591e-04 - acc: 0.0000e+00 - val_loss: 2.7390e-04 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0458e-04 - acc: 0.0000e+00 - val_loss: 1.7119e-04 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0202e-04 - acc: 0.0000e+00 - val_loss: 2.5151e-04 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1107e-04 - acc: 0.0000e+00 - val_loss: 2.6078e-04 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2399e-04 - acc: 0.0000e+00 - val_loss: 3.3143e-04 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1590e-04 - acc: 0.0000e+00 - val_loss: 1.8577e-04 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0652e-04 - acc: 0.0000e+00 - val_loss: 4.1832e-04 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0478e-04 - acc: 0.0000e+00 - val_loss: 1.7093e-04 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0557e-04 - acc: 0.0000e+00 - val_loss: 1.6134e-04 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0096e-04 - acc: 0.0000e+00 - val_loss: 3.1371e-04 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0885e-04 - acc: 0.0000e+00 - val_loss: 2.5236e-04 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0217e-04 - acc: 0.0000e+00 - val_loss: 2.6262e-04 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0019e-04 - acc: 0.0000e+00 - val_loss: 2.0006e-04 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.7932e-05 - acc: 0.0000e+00 - val_loss: 3.8748e-04 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0174e-04 - acc: 0.0000e+00 - val_loss: 1.8820e-04 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.4865e-05 - acc: 0.0000e+00 - val_loss: 2.5676e-04 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3420e-05 - acc: 0.0000e+00 - val_loss: 1.6266e-04 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0300e-04 - acc: 0.0000e+00 - val_loss: 1.7114e-04 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0958e-04 - acc: 0.0000e+00 - val_loss: 2.9933e-04 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0269e-04 - acc: 0.0000e+00 - val_loss: 1.4630e-04 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0454e-04 - acc: 0.0000e+00 - val_loss: 3.6714e-04 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0483e-04 - acc: 0.0000e+00 - val_loss: 4.5926e-04 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.4432e-05 - acc: 0.0000e+00 - val_loss: 1.5934e-04 - val_acc: 0.0000e+00\n",
      "Epoch 132/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.2716e-05 - acc: 0.0000e+00 - val_loss: 1.7572e-04 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.4678e-05 - acc: 0.0000e+00 - val_loss: 2.2130e-04 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.6648e-05 - acc: 0.0000e+00 - val_loss: 2.2840e-04 - val_acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0326e-04 - acc: 0.0000e+00 - val_loss: 1.5782e-04 - val_acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3905e-05 - acc: 0.0000e+00 - val_loss: 1.7204e-04 - val_acc: 0.0000e+00\n",
      "Epoch 137/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.4373e-05 - acc: 0.0000e+00 - val_loss: 1.7494e-04 - val_acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.6960e-05 - acc: 0.0000e+00 - val_loss: 1.5272e-04 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.8571e-05 - acc: 0.0000e+00 - val_loss: 4.9830e-04 - val_acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.0131e-05 - acc: 0.0000e+00 - val_loss: 2.0329e-04 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.1099e-05 - acc: 0.0000e+00 - val_loss: 4.8096e-04 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0184e-04 - acc: 0.0000e+00 - val_loss: 2.2018e-04 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.9399e-05 - acc: 0.0000e+00 - val_loss: 1.6973e-04 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.8588e-05 - acc: 0.0000e+00 - val_loss: 4.8580e-04 - val_acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.2787e-05 - acc: 0.0000e+00 - val_loss: 1.9445e-04 - val_acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.9057e-05 - acc: 0.0000e+00 - val_loss: 1.9007e-04 - val_acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3715e-05 - acc: 0.0000e+00 - val_loss: 5.7164e-04 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.7711e-05 - acc: 0.0000e+00 - val_loss: 2.9675e-04 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.9916e-05 - acc: 0.0000e+00 - val_loss: 1.4352e-04 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.2860e-05 - acc: 0.0000e+00 - val_loss: 1.8121e-04 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.2551e-05 - acc: 0.0000e+00 - val_loss: 5.3585e-04 - val_acc: 0.0000e+00\n",
      "Epoch 152/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0055e-04 - acc: 0.0000e+00 - val_loss: 2.9006e-04 - val_acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0379e-04 - acc: 0.0000e+00 - val_loss: 4.6684e-04 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.1671e-05 - acc: 0.0000e+00 - val_loss: 1.7542e-04 - val_acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.0315e-05 - acc: 0.0000e+00 - val_loss: 1.7235e-04 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.0181e-05 - acc: 0.0000e+00 - val_loss: 1.9466e-04 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13702/13702 [==============================] - 1s - loss: 9.7080e-05 - acc: 0.0000e+00 - val_loss: 1.6134e-04 - val_acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.8794e-05 - acc: 0.0000e+00 - val_loss: 1.9032e-04 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.6255e-05 - acc: 0.0000e+00 - val_loss: 1.8715e-04 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.5782e-05 - acc: 0.0000e+00 - val_loss: 1.8604e-04 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.1113e-05 - acc: 0.0000e+00 - val_loss: 2.5892e-04 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.7331e-05 - acc: 0.0000e+00 - val_loss: 2.1153e-04 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.6033e-05 - acc: 0.0000e+00 - val_loss: 2.3757e-04 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "13702/13702 [==============================] - 2s - loss: 8.4232e-05 - acc: 0.0000e+00 - val_loss: 1.7204e-04 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0269e-04 - acc: 0.0000e+00 - val_loss: 1.7793e-04 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.7834e-05 - acc: 0.0000e+00 - val_loss: 3.6255e-04 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "13702/13702 [==============================] - 2s - loss: 8.4666e-05 - acc: 0.0000e+00 - val_loss: 2.3223e-04 - val_acc: 0.0000e+00\n",
      "Epoch 168/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.2703e-05 - acc: 0.0000e+00 - val_loss: 1.6357e-04 - val_acc: 0.0000e+00\n",
      "Epoch 169/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.7699e-05 - acc: 0.0000e+00 - val_loss: 2.1625e-04 - val_acc: 0.0000e+00\n",
      "Epoch 170/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.1496e-05 - acc: 0.0000e+00 - val_loss: 2.6867e-04 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "13702/13702 [==============================] - 2s - loss: 8.7221e-05 - acc: 0.0000e+00 - val_loss: 2.0651e-04 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.6792e-05 - acc: 0.0000e+00 - val_loss: 4.4673e-04 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.2993e-05 - acc: 0.0000e+00 - val_loss: 1.7104e-04 - val_acc: 0.0000e+00\n",
      "Epoch 174/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.6934e-05 - acc: 0.0000e+00 - val_loss: 3.8071e-04 - val_acc: 0.0000e+00\n",
      "Epoch 175/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3658e-05 - acc: 0.0000e+00 - val_loss: 1.7402e-04 - val_acc: 0.0000e+00\n",
      "Epoch 176/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.1573e-05 - acc: 0.0000e+00 - val_loss: 4.2781e-04 - val_acc: 0.0000e+00\n",
      "Epoch 177/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.8046e-05 - acc: 0.0000e+00 - val_loss: 4.0356e-04 - val_acc: 0.0000e+00\n",
      "Epoch 178/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3971e-05 - acc: 0.0000e+00 - val_loss: 1.5127e-04 - val_acc: 0.0000e+00\n",
      "Epoch 179/300\n",
      "13702/13702 [==============================] - 2s - loss: 8.3811e-05 - acc: 0.0000e+00 - val_loss: 2.4027e-04 - val_acc: 0.0000e+00\n",
      "Epoch 180/300\n",
      "13702/13702 [==============================] - 2s - loss: 7.8286e-05 - acc: 0.0000e+00 - val_loss: 1.4240e-04 - val_acc: 0.0000e+00\n",
      "Epoch 181/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3377e-05 - acc: 0.0000e+00 - val_loss: 2.4492e-04 - val_acc: 0.0000e+0000e+0\n",
      "Epoch 182/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.0844e-05 - acc: 0.0000e+00 - val_loss: 2.9170e-04 - val_acc: 0.0000e+00\n",
      "Epoch 183/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.0601e-05 - acc: 0.0000e+00 - val_loss: 1.8117e-04 - val_acc: 0.0000e+00\n",
      "Epoch 184/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1868e-05 - acc: 0.0000e+00 - val_loss: 2.0404e-04 - val_acc: 0.0000e+00\n",
      "Epoch 185/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9355e-05 - acc: 0.0000e+00 - val_loss: 4.4221e-04 - val_acc: 0.0000e+00\n",
      "Epoch 186/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.2885e-05 - acc: 0.0000e+00 - val_loss: 2.8940e-04 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3434e-05 - acc: 0.0000e+00 - val_loss: 2.6970e-04 - val_acc: 0.0000e+00\n",
      "Epoch 188/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.7613e-05 - acc: 0.0000e+00 - val_loss: 1.3819e-04 - val_acc: 0.0000e+00\n",
      "Epoch 189/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.6766e-05 - acc: 0.0000e+00 - val_loss: 1.5381e-04 - val_acc: 0.0000e+00\n",
      "Epoch 190/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.5138e-05 - acc: 0.0000e+00 - val_loss: 3.1679e-04 - val_acc: 0.0000e+00 - ETA: 0s - loss: 8.8950e-05 - acc\n",
      "Epoch 191/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.7643e-05 - acc: 0.0000e+00 - val_loss: 2.2191e-04 - val_acc: 0.0000e+00\n",
      "Epoch 192/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8531e-05 - acc: 0.0000e+00 - val_loss: 1.5878e-04 - val_acc: 0.0000e+000\n",
      "Epoch 193/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.6755e-05 - acc: 0.0000e+00 - val_loss: 2.0950e-04 - val_acc: 0.0000e+00\n",
      "Epoch 194/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3127e-05 - acc: 0.0000e+00 - val_loss: 2.1628e-04 - val_acc: 0.0000e+00\n",
      "Epoch 195/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.8357e-05 - acc: 0.0000e+00 - val_loss: 2.2033e-04 - val_acc: 0.0000e+00\n",
      "Epoch 196/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9893e-05 - acc: 0.0000e+00 - val_loss: 1.6198e-04 - val_acc: 0.0000e+00\n",
      "Epoch 197/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1980e-05 - acc: 0.0000e+00 - val_loss: 1.4816e-04 - val_acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.4150e-05 - acc: 0.0000e+00 - val_loss: 2.9659e-04 - val_acc: 0.0000e+00\n",
      "Epoch 199/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.6184e-05 - acc: 0.0000e+00 - val_loss: 1.8203e-04 - val_acc: 0.0000e+00\n",
      "Epoch 200/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.0429e-05 - acc: 0.0000e+00 - val_loss: 1.9676e-04 - val_acc: 0.0000e+00\n",
      "Epoch 201/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8432e-05 - acc: 0.0000e+00 - val_loss: 1.7621e-04 - val_acc: 0.0000e+00\n",
      "Epoch 202/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.2099e-05 - acc: 0.0000e+00 - val_loss: 2.0047e-04 - val_acc: 0.0000e+00\n",
      "Epoch 203/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0038e-05 - acc: 0.0000e+00 - val_loss: 2.5995e-04 - val_acc: 0.0000e+00\n",
      "Epoch 204/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9615e-05 - acc: 0.0000e+00 - val_loss: 2.1900e-04 - val_acc: 0.0000e+00\n",
      "Epoch 205/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0319e-05 - acc: 0.0000e+00 - val_loss: 3.1494e-04 - val_acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.2696e-05 - acc: 0.0000e+00 - val_loss: 1.9053e-04 - val_acc: 0.0000e+00\n",
      "Epoch 207/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0010e-05 - acc: 0.0000e+00 - val_loss: 3.1766e-04 - val_acc: 0.0000e+00\n",
      "Epoch 208/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.7783e-05 - acc: 0.0000e+00 - val_loss: 1.7325e-04 - val_acc: 0.0000e+00\n",
      "Epoch 209/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.2373e-05 - acc: 0.0000e+00 - val_loss: 2.7009e-04 - val_acc: 0.0000e+00\n",
      "Epoch 210/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1575e-05 - acc: 0.0000e+00 - val_loss: 3.0607e-04 - val_acc: 0.0000e+00\n",
      "Epoch 211/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4362e-05 - acc: 0.0000e+00 - val_loss: 1.9781e-04 - val_acc: 0.0000e+00\n",
      "Epoch 212/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.6505e-05 - acc: 0.0000e+00 - val_loss: 2.0563e-04 - val_acc: 0.0000e+00\n",
      "Epoch 213/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1572e-05 - acc: 0.0000e+00 - val_loss: 1.5519e-04 - val_acc: 0.0000e+00\n",
      "Epoch 214/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.4095e-05 - acc: 0.0000e+00 - val_loss: 1.4218e-04 - val_acc: 0.0000e+00\n",
      "Epoch 215/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9674e-05 - acc: 0.0000e+00 - val_loss: 2.3033e-04 - val_acc: 0.0000e+00\n",
      "Epoch 216/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8890e-05 - acc: 0.0000e+00 - val_loss: 1.2473e-04 - val_acc: 0.0000e+00\n",
      "Epoch 217/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4772e-05 - acc: 0.0000e+00 - val_loss: 1.8648e-04 - val_acc: 0.0000e+00\n",
      "Epoch 218/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2462e-05 - acc: 0.0000e+00 - val_loss: 1.5368e-04 - val_acc: 0.0000e+00\n",
      "Epoch 219/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.7712e-05 - acc: 0.0000e+00 - val_loss: 1.7582e-04 - val_acc: 0.0000e+00\n",
      "Epoch 220/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.9960e-05 - acc: 0.0000e+00 - val_loss: 1.5407e-04 - val_acc: 0.0000e+00\n",
      "Epoch 221/300\n",
      "13702/13702 [==============================] - 2s - loss: 7.3900e-05 - acc: 0.0000e+00 - val_loss: 2.4410e-04 - val_acc: 0.0000e+00\n",
      "Epoch 222/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.6905e-05 - acc: 0.0000e+00 - val_loss: 1.4138e-04 - val_acc: 0.0000e+00\n",
      "Epoch 223/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3777e-05 - acc: 0.0000e+00 - val_loss: 1.9402e-04 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8529e-05 - acc: 0.0000e+00 - val_loss: 7.9249e-04 - val_acc: 0.0000e+00\n",
      "Epoch 225/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0925e-04 - acc: 0.0000e+00 - val_loss: 1.5116e-04 - val_acc: 0.0000e+00\n",
      "Epoch 226/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.4016e-05 - acc: 0.0000e+00 - val_loss: 1.7025e-04 - val_acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.6481e-05 - acc: 0.0000e+00 - val_loss: 4.6258e-04 - val_acc: 0.0000e+00\n",
      "Epoch 228/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.5338e-05 - acc: 0.0000e+00 - val_loss: 1.4189e-04 - val_acc: 0.0000e+00\n",
      "Epoch 229/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.5524e-05 - acc: 0.0000e+00 - val_loss: 3.5414e-04 - val_acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8513e-05 - acc: 0.0000e+00 - val_loss: 1.9358e-04 - val_acc: 0.0000e+00\n",
      "Epoch 231/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.5735e-05 - acc: 0.0000e+00 - val_loss: 1.6353e-04 - val_acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2876e-05 - acc: 0.0000e+00 - val_loss: 1.9740e-04 - val_acc: 0.0000e+0000\n",
      "Epoch 233/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4172e-05 - acc: 0.0000e+00 - val_loss: 2.1658e-04 - val_acc: 0.0000e+00\n",
      "Epoch 234/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9871e-05 - acc: 0.0000e+00 - val_loss: 1.4538e-04 - val_acc: 0.0000e+00\n",
      "Epoch 235/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4806e-05 - acc: 0.0000e+00 - val_loss: 3.2176e-04 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1779e-05 - acc: 0.0000e+00 - val_loss: 2.0520e-04 - val_acc: 0.0000e+00\n",
      "Epoch 237/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.3932e-05 - acc: 0.0000e+00 - val_loss: 1.8269e-04 - val_acc: 0.0000e+00\n",
      "Epoch 238/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0548e-05 - acc: 0.0000e+00 - val_loss: 1.4994e-04 - val_acc: 0.0000e+00\n",
      "Epoch 239/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.6985e-05 - acc: 0.0000e+00 - val_loss: 2.8457e-04 - val_acc: 0.0000e+00\n",
      "Epoch 240/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.2628e-05 - acc: 0.0000e+00 - val_loss: 2.2156e-04 - val_acc: 0.0000e+00\n",
      "Epoch 241/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1611e-05 - acc: 0.0000e+00 - val_loss: 1.6893e-04 - val_acc: 0.0000e+00\n",
      "Epoch 242/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4260e-05 - acc: 0.0000e+00 - val_loss: 2.5932e-04 - val_acc: 0.0000e+00\n",
      "Epoch 243/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.7109e-05 - acc: 0.0000e+00 - val_loss: 3.8726e-04 - val_acc: 0.0000e+00\n",
      "Epoch 244/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1603e-05 - acc: 0.0000e+00 - val_loss: 1.8377e-04 - val_acc: 0.0000e+00\n",
      "Epoch 245/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4708e-05 - acc: 0.0000e+00 - val_loss: 1.4539e-04 - val_acc: 0.0000e+00\n",
      "Epoch 246/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.3872e-05 - acc: 0.0000e+00 - val_loss: 1.5933e-04 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2336e-05 - acc: 0.0000e+00 - val_loss: 3.3052e-04 - val_acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9134e-05 - acc: 0.0000e+00 - val_loss: 1.7232e-04 - val_acc: 0.0000e+00\n",
      "Epoch 249/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8414e-05 - acc: 0.0000e+00 - val_loss: 5.2960e-04 - val_acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.3652e-05 - acc: 0.0000e+00 - val_loss: 7.1981e-04 - val_acc: 0.0000e+00\n",
      "Epoch 251/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8544e-05 - acc: 0.0000e+00 - val_loss: 1.9537e-04 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2959e-05 - acc: 0.0000e+00 - val_loss: 3.6408e-04 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6126e-05 - acc: 0.0000e+00 - val_loss: 2.6155e-04 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7503e-05 - acc: 0.0000e+00 - val_loss: 1.8498e-04 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1506e-05 - acc: 0.0000e+00 - val_loss: 1.9209e-04 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.8756e-05 - acc: 0.0000e+00 - val_loss: 2.7393e-04 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1139e-05 - acc: 0.0000e+00 - val_loss: 4.4331e-04 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.7433e-05 - acc: 0.0000e+00 - val_loss: 1.9213e-04 - val_acc: 0.0000e+00\n",
      "Epoch 259/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.3941e-05 - acc: 0.0000e+00 - val_loss: 1.5579e-04 - val_acc: 0.0000e+00\n",
      "Epoch 260/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4482e-05 - acc: 0.0000e+00 - val_loss: 4.4241e-04 - val_acc: 0.0000e+00\n",
      "Epoch 261/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0298e-05 - acc: 0.0000e+00 - val_loss: 2.7617e-04 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.6966e-05 - acc: 0.0000e+00 - val_loss: 2.7828e-04 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.5900e-05 - acc: 0.0000e+00 - val_loss: 1.7344e-04 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.3079e-05 - acc: 0.0000e+00 - val_loss: 4.6354e-04 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1835e-05 - acc: 0.0000e+00 - val_loss: 2.8672e-04 - val_acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4642e-05 - acc: 0.0000e+00 - val_loss: 3.2372e-04 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4722e-05 - acc: 0.0000e+00 - val_loss: 6.5295e-04 - val_acc: 0.0000e+00\n",
      "Epoch 268/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13702/13702 [==============================] - 1s - loss: 7.5105e-05 - acc: 0.0000e+00 - val_loss: 1.8325e-04 - val_acc: 0.0000e+00\n",
      "Epoch 269/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1055e-05 - acc: 0.0000e+00 - val_loss: 2.6456e-04 - val_acc: 0.0000e+00\n",
      "Epoch 270/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7923e-05 - acc: 0.0000e+00 - val_loss: 2.3129e-04 - val_acc: 0.0000e+00\n",
      "Epoch 271/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.9181e-05 - acc: 0.0000e+00 - val_loss: 2.7518e-04 - val_acc: 0.0000e+00\n",
      "Epoch 272/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.3365e-05 - acc: 0.0000e+00 - val_loss: 3.3132e-04 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.9777e-05 - acc: 0.0000e+00 - val_loss: 1.6098e-04 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0377e-05 - acc: 0.0000e+00 - val_loss: 2.4420e-04 - val_acc: 0.0000e+0000e+0\n",
      "Epoch 275/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4858e-05 - acc: 0.0000e+00 - val_loss: 1.4363e-04 - val_acc: 0.0000e+00\n",
      "Epoch 276/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0115e-05 - acc: 0.0000e+00 - val_loss: 2.0925e-04 - val_acc: 0.0000e+00\n",
      "Epoch 277/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1130e-05 - acc: 0.0000e+00 - val_loss: 1.2054e-04 - val_acc: 0.0000e+00\n",
      "Epoch 278/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.5693e-05 - acc: 0.0000e+00 - val_loss: 2.3336e-04 - val_acc: 0.0000e+00\n",
      "Epoch 279/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7777e-05 - acc: 0.0000e+00 - val_loss: 1.7634e-04 - val_acc: 0.0000e+00\n",
      "Epoch 280/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8940e-05 - acc: 0.0000e+00 - val_loss: 2.9703e-04 - val_acc: 0.0000e+00\n",
      "Epoch 281/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2386e-05 - acc: 0.0000e+00 - val_loss: 1.3204e-04 - val_acc: 0.0000e+00\n",
      "Epoch 282/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.9240e-05 - acc: 0.0000e+00 - val_loss: 3.1336e-04 - val_acc: 0.0000e+00\n",
      "Epoch 283/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0363e-05 - acc: 0.0000e+00 - val_loss: 2.3485e-04 - val_acc: 0.0000e+00\n",
      "Epoch 284/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.8012e-05 - acc: 0.0000e+00 - val_loss: 3.1219e-04 - val_acc: 0.0000e+00\n",
      "Epoch 285/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6163e-05 - acc: 0.0000e+00 - val_loss: 3.6892e-04 - val_acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3121e-05 - acc: 0.0000e+00 - val_loss: 4.4599e-04 - val_acc: 0.0000e+00\n",
      "Epoch 287/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0318e-05 - acc: 0.0000e+00 - val_loss: 2.9425e-04 - val_acc: 0.0000e+00\n",
      "Epoch 288/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0926e-05 - acc: 0.0000e+00 - val_loss: 7.8019e-04 - val_acc: 0.0000e+00\n",
      "Epoch 289/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0558e-05 - acc: 0.0000e+00 - val_loss: 2.0309e-04 - val_acc: 0.0000e+00\n",
      "Epoch 290/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.9708e-05 - acc: 0.0000e+00 - val_loss: 2.5192e-04 - val_acc: 0.0000e+00\n",
      "Epoch 291/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.5409e-05 - acc: 0.0000e+00 - val_loss: 3.6990e-04 - val_acc: 0.0000e+00\n",
      "Epoch 292/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3968e-05 - acc: 0.0000e+00 - val_loss: 1.5363e-04 - val_acc: 0.0000e+00\n",
      "Epoch 293/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.8142e-05 - acc: 0.0000e+00 - val_loss: 1.5397e-04 - val_acc: 0.0000e+00\n",
      "Epoch 294/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.3668e-05 - acc: 0.0000e+00 - val_loss: 1.4684e-04 - val_acc: 0.0000e+00\n",
      "Epoch 295/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0757e-05 - acc: 0.0000e+00 - val_loss: 2.9196e-04 - val_acc: 0.0000e+00\n",
      "Epoch 296/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2730e-05 - acc: 0.0000e+00 - val_loss: 2.6135e-04 - val_acc: 0.0000e+00\n",
      "Epoch 297/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6917e-05 - acc: 0.0000e+00 - val_loss: 6.9356e-04 - val_acc: 0.0000e+00\n",
      "Epoch 298/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.6131e-05 - acc: 0.0000e+00 - val_loss: 3.0078e-04 - val_acc: 0.0000e+00\n",
      "Epoch 299/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6266e-05 - acc: 0.0000e+00 - val_loss: 3.5602e-04 - val_acc: 0.0000e+00\n",
      "Epoch 300/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3080e-05 - acc: 0.0000e+00 - val_loss: 4.2830e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00008 MSE (0.01 RMSE)\n",
      "Test Score: 0.03805 MSE (0.20 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_27 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_28 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13702 samples, validate on 1523 samples\n",
      "Epoch 1/300\n",
      "13702/13702 [==============================] - 3s - loss: 0.0125 - acc: 0.0000e+00 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "13702/13702 [==============================] - 1s - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.8205e-04 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0464e-04 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0607e-04 - acc: 0.0000e+00 - val_loss: 3.5865e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4529e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6446e-04 - acc: 0.0000e+00 - val_loss: 4.7940e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0687e-04 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.8588e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2296e-04 - acc: 0.0000e+00 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3806e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.0633e-04 - acc: 0.0000e+00 - val_loss: 2.8050e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.5517e-04 - acc: 0.0000e+00 - val_loss: 2.7580e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9202e-04 - acc: 0.0000e+00 - val_loss: 3.9986e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.6628e-04 - acc: 0.0000e+00 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.9721e-04 - acc: 0.0000e+00 - val_loss: 0.0059 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.5008e-04 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.1979e-04 - acc: 0.0000e+00 - val_loss: 3.8112e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9234e-04 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.7317e-04 - acc: 0.0000e+00 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6351e-04 - acc: 0.0000e+00 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.8662e-04 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5858e-04 - acc: 0.0000e+00 - val_loss: 9.9145e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1628e-04 - acc: 0.0000e+00 - val_loss: 3.7363e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0881e-04 - acc: 0.0000e+00 - val_loss: 7.8377e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.9096e-04 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2150e-04 - acc: 0.0000e+00 - val_loss: 8.9764e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8239e-04 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7979e-04 - acc: 0.0000e+00 - val_loss: 3.0652e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4510e-04 - acc: 0.0000e+00 - val_loss: 2.9828e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5371e-04 - acc: 0.0000e+00 - val_loss: 2.3553e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.2689e-04 - acc: 0.0000e+00 - val_loss: 2.5611e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3701e-04 - acc: 0.0000e+00 - val_loss: 2.6443e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.0594e-04 - acc: 0.0000e+00 - val_loss: 7.7305e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.9524e-04 - acc: 0.0000e+00 - val_loss: 4.0189e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.1088e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.7307e-04 - acc: 0.0000e+00 - val_loss: 2.8868e-04 - val_acc: 0.0000e+0000e\n",
      "Epoch 38/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.7804e-04 - acc: 0.0000e+00 - val_loss: 2.8125e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.6431e-04 - acc: 0.0000e+00 - val_loss: 4.4726e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.4018e-04 - acc: 0.0000e+00 - val_loss: 2.6722e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.6175e-04 - acc: 0.0000e+00 - val_loss: 5.7507e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.3272e-04 - acc: 0.0000e+00 - val_loss: 8.0673e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.3516e-04 - acc: 0.0000e+00 - val_loss: 4.6058e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.2931e-04 - acc: 0.0000e+00 - val_loss: 3.1342e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.5078e-04 - acc: 0.0000e+00 - val_loss: 8.1869e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.5140e-04 - acc: 0.0000e+00 - val_loss: 5.7557e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.2200e-04 - acc: 0.0000e+00 - val_loss: 4.8446e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.3785e-04 - acc: 0.0000e+00 - val_loss: 5.3462e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.2596e-04 - acc: 0.0000e+00 - val_loss: 3.3617e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9799e-04 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9827e-04 - acc: 0.0000e+00 - val_loss: 5.7664e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8755e-04 - acc: 0.0000e+00 - val_loss: 3.6004e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9766e-04 - acc: 0.0000e+00 - val_loss: 2.9210e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9642e-04 - acc: 0.0000e+00 - val_loss: 3.9535e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.1163e-04 - acc: 0.0000e+00 - val_loss: 4.8770e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8221e-04 - acc: 0.0000e+00 - val_loss: 3.6152e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7873e-04 - acc: 0.0000e+00 - val_loss: 3.9166e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7510e-04 - acc: 0.0000e+00 - val_loss: 3.8632e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7604e-04 - acc: 0.0000e+00 - val_loss: 4.3733e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8173e-04 - acc: 0.0000e+00 - val_loss: 6.8579e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8676e-04 - acc: 0.0000e+00 - val_loss: 8.9812e-04 - val_acc: 0.0000e+0000e+0\n",
      "Epoch 62/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8157e-04 - acc: 0.0000e+00 - val_loss: 3.0229e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7360e-04 - acc: 0.0000e+00 - val_loss: 7.4918e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6384e-04 - acc: 0.0000e+00 - val_loss: 7.8085e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6542e-04 - acc: 0.0000e+00 - val_loss: 3.3013e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7062e-04 - acc: 0.0000e+00 - val_loss: 4.4724e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6574e-04 - acc: 0.0000e+00 - val_loss: 5.9483e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5794e-04 - acc: 0.0000e+00 - val_loss: 6.8203e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5336e-04 - acc: 0.0000e+00 - val_loss: 6.0593e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5521e-04 - acc: 0.0000e+00 - val_loss: 5.1038e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5413e-04 - acc: 0.0000e+00 - val_loss: 6.2599e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13702/13702 [==============================] - 1s - loss: 1.6657e-04 - acc: 0.0000e+00 - val_loss: 3.1592e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6380e-04 - acc: 0.0000e+00 - val_loss: 2.7866e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5932e-04 - acc: 0.0000e+00 - val_loss: 3.1835e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5005e-04 - acc: 0.0000e+00 - val_loss: 4.3268e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4746e-04 - acc: 0.0000e+00 - val_loss: 7.5370e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5394e-04 - acc: 0.0000e+00 - val_loss: 3.2292e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5239e-04 - acc: 0.0000e+00 - val_loss: 5.2693e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5191e-04 - acc: 0.0000e+00 - val_loss: 9.4634e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5957e-04 - acc: 0.0000e+00 - val_loss: 6.2523e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4833e-04 - acc: 0.0000e+00 - val_loss: 8.2942e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4711e-04 - acc: 0.0000e+00 - val_loss: 9.1043e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4169e-04 - acc: 0.0000e+00 - val_loss: 5.8362e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4260e-04 - acc: 0.0000e+00 - val_loss: 9.9053e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3548e-04 - acc: 0.0000e+00 - val_loss: 8.2100e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3962e-04 - acc: 0.0000e+00 - val_loss: 3.3916e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4152e-04 - acc: 0.0000e+00 - val_loss: 4.3366e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3337e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3334e-04 - acc: 0.0000e+00 - val_loss: 6.9874e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4250e-04 - acc: 0.0000e+00 - val_loss: 8.5213e-04 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3242e-04 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2681e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2801e-04 - acc: 0.0000e+00 - val_loss: 7.6735e-04 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3938e-04 - acc: 0.0000e+00 - val_loss: 5.2901e-04 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3808e-04 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4154e-04 - acc: 0.0000e+00 - val_loss: 9.8377e-04 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3216e-04 - acc: 0.0000e+00 - val_loss: 9.2387e-04 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3907e-04 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5309e-04 - acc: 0.0000e+00 - val_loss: 8.1559e-04 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2758e-04 - acc: 0.0000e+00 - val_loss: 5.3400e-04 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3170e-04 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2112e-04 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2947e-04 - acc: 0.0000e+00 - val_loss: 8.5040e-04 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3201e-04 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2085e-04 - acc: 0.0000e+00 - val_loss: 9.3465e-04 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2332e-04 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1724e-04 - acc: 0.0000e+00 - val_loss: 7.0489e-04 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2396e-04 - acc: 0.0000e+00 - val_loss: 9.8016e-04 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2234e-04 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1883e-04 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+000.000\n",
      "Epoch 111/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2514e-04 - acc: 0.0000e+00 - val_loss: 7.8593e-04 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2188e-04 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "13702/13702 [==============================] - 2s - loss: 1.3652e-04 - acc: 0.0000e+00 - val_loss: 6.2520e-04 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1921e-04 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+000.\n",
      "Epoch 115/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1932e-04 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2542e-04 - acc: 0.0000e+00 - val_loss: 6.3308e-04 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "13702/13702 [==============================] - 2s - loss: 1.4133e-04 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3027e-04 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1767e-04 - acc: 0.0000e+00 - val_loss: 6.0836e-04 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1301e-04 - acc: 0.0000e+00 - val_loss: 7.9080e-04 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "13702/13702 [==============================] - 2s - loss: 1.0753e-04 - acc: 0.0000e+00 - val_loss: 9.8405e-04 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1788e-04 - acc: 0.0000e+00 - val_loss: 3.8826e-04 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2423e-04 - acc: 0.0000e+00 - val_loss: 9.6733e-04 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2056e-04 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+000\n",
      "Epoch 125/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1005e-04 - acc: 0.0000e+00 - val_loss: 6.2626e-04 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1821e-04 - acc: 0.0000e+00 - val_loss: 4.8729e-04 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1375e-04 - acc: 0.0000e+00 - val_loss: 9.9913e-04 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1242e-04 - acc: 0.0000e+00 - val_loss: 6.5294e-04 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3210e-04 - acc: 0.0000e+00 - val_loss: 5.4471e-04 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1742e-04 - acc: 0.0000e+00 - val_loss: 9.6405e-04 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1917e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 132/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1449e-04 - acc: 0.0000e+00 - val_loss: 9.2000e-04 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0865e-04 - acc: 0.0000e+00 - val_loss: 8.0901e-04 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0866e-04 - acc: 0.0000e+00 - val_loss: 9.9810e-04 - val_acc: 0.0000e+0000e - ETA: 1s - loss: 1.0834e-04 - - ETA: 0s - loss: 1.0946e-04 - acc: 0.0000e+0\n",
      "Epoch 135/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1446e-04 - acc: 0.0000e+00 - val_loss: 8.6315e-04 - val_acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0892e-04 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 137/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1534e-04 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1257e-04 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1944e-04 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1707e-04 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1846e-04 - acc: 0.0000e+00 - val_loss: 5.2556e-04 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1968e-04 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0702e-04 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0427e-04 - acc: 0.0000e+00 - val_loss: 9.3992e-04 - val_acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0374e-04 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0725e-04 - acc: 0.0000e+00 - val_loss: 8.9807e-04 - val_acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0906e-04 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1253e-04 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0869e-04 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1532e-04 - acc: 0.0000e+00 - val_loss: 8.7471e-04 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1143e-04 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 152/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1022e-04 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0660e-04 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2214e-04 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0754e-04 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1264e-04 - acc: 0.0000e+00 - val_loss: 8.8631e-04 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1225e-04 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1725e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0691e-04 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0652e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0658e-04 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0331e-04 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1288e-04 - acc: 0.0000e+00 - val_loss: 8.6782e-04 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0991e-04 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0435e-04 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0656e-04 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1167e-04 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 168/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0109e-04 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 169/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0841e-04 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 170/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1717e-04 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2765e-04 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0331e-04 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0610e-04 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 174/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.8750e-05 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+000.0000e+ - ETA: 0s - loss: 9.3632e-05 - a\n",
      "Epoch 175/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.9783e-05 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 176/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0282e-04 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 177/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0446e-04 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 178/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0175e-04 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 179/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0271e-04 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 180/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0110e-04 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 181/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.6696e-05 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 182/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.7067e-05 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 183/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0208e-04 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 184/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13702/13702 [==============================] - 1s - loss: 1.0890e-04 - acc: 0.0000e+00 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 185/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0187e-04 - acc: 0.0000e+00 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 186/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1207e-04 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1059e-04 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 188/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0803e-04 - acc: 0.0000e+00 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 189/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0134e-04 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+000.000\n",
      "Epoch 190/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0001e-04 - acc: 0.0000e+00 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 191/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.8220e-05 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 192/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.8360e-05 - acc: 0.0000e+00 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 193/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0382e-04 - acc: 0.0000e+00 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 194/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.5931e-05 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 195/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0139e-04 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 196/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.8990e-05 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 197/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.5385e-05 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0146e-04 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 199/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0006e-04 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 200/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3053e-05 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 201/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.8905e-05 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 202/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0692e-04 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 203/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.4885e-05 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 204/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.8841e-05 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 205/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0503e-04 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.4537e-05 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 207/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0402e-04 - acc: 0.0000e+00 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 208/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.5872e-05 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 209/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.4978e-05 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 210/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3475e-05 - acc: 0.0000e+00 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 211/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.6428e-05 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 212/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.7085e-05 - acc: 0.0000e+00 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 213/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.7078e-05 - acc: 0.0000e+00 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 214/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.0278e-05 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 215/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.5531e-05 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 216/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.9501e-05 - acc: 0.0000e+00 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 217/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.8626e-05 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 218/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.1751e-05 - acc: 0.0000e+00 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 219/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.6242e-05 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 220/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.2380e-05 - acc: 0.0000e+00 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 221/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3692e-05 - acc: 0.0000e+00 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 222/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3870e-05 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 223/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0095e-04 - acc: 0.0000e+00 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.6934e-05 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 225/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.0423e-05 - acc: 0.0000e+00 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 226/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0342e-04 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.5432e-05 - acc: 0.0000e+00 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 228/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.6888e-05 - acc: 0.0000e+00 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 229/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.2719e-05 - acc: 0.0000e+00 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3481e-05 - acc: 0.0000e+00 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 231/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.2623e-05 - acc: 0.0000e+00 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.7488e-05 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+000.\n",
      "Epoch 233/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.2512e-05 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+000.0000\n",
      "Epoch 234/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.4039e-05 - acc: 0.0000e+00 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 235/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.6827e-05 - acc: 0.0000e+00 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.0347e-05 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+000.0000\n",
      "Epoch 237/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.8818e-05 - acc: 0.0000e+00 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 238/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.0575e-05 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 239/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.8994e-05 - acc: 0.0000e+00 - val_loss: 0.0029 - val_acc: 0.0000e+000.0000e+\n",
      "Epoch 240/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.4951e-05 - acc: 0.0000e+00 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 241/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.1674e-05 - acc: 0.0000e+00 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 242/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.6254e-05 - acc: 0.0000e+00 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 243/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.8824e-05 - acc: 0.0000e+00 - val_loss: 0.0044 - val_acc: 0.0000e+00\n",
      "Epoch 244/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.2132e-05 - acc: 0.0000e+00 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 245/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.5474e-05 - acc: 0.0000e+00 - val_loss: 0.0033 - val_acc: 0.0000e+000.000\n",
      "Epoch 246/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.7269e-05 - acc: 0.0000e+00 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.5431e-05 - acc: 0.0000e+00 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.5194e-05 - acc: 0.0000e+00 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 249/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.4119e-05 - acc: 0.0000e+00 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.4622e-05 - acc: 0.0000e+00 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
      "Epoch 251/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.7818e-05 - acc: 0.0000e+00 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.4167e-05 - acc: 0.0000e+00 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.1000e-05 - acc: 0.0000e+00 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3134e-05 - acc: 0.0000e+00 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3929e-05 - acc: 0.0000e+00 - val_loss: 0.0043 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.7647e-05 - acc: 0.0000e+00 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.7625e-05 - acc: 0.0000e+00 - val_loss: 0.0040 - val_acc: 0.0000e+000\n",
      "Epoch 258/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3267e-05 - acc: 0.0000e+00 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
      "Epoch 259/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0942e-05 - acc: 0.0000e+00 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 260/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3551e-05 - acc: 0.0000e+00 - val_loss: 0.0049 - val_acc: 0.0000e+00\n",
      "Epoch 261/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.0067e-05 - acc: 0.0000e+00 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.8477e-05 - acc: 0.0000e+00 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.2520e-05 - acc: 0.0000e+00 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.5144e-05 - acc: 0.0000e+00 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.4355e-05 - acc: 0.0000e+00 - val_loss: 0.0043 - val_acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0969e-05 - acc: 0.0000e+00 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1810e-05 - acc: 0.0000e+00 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
      "Epoch 268/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1823e-05 - acc: 0.0000e+00 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 269/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1051e-05 - acc: 0.0000e+00 - val_loss: 0.0044 - val_acc: 0.0000e+00s - loss: 7.9135e-05 - acc: 0.000\n",
      "Epoch 270/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.4315e-05 - acc: 0.0000e+00 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
      "Epoch 271/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.6115e-05 - acc: 0.0000e+00 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
      "Epoch 272/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.7298e-05 - acc: 0.0000e+00 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1670e-05 - acc: 0.0000e+00 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3702e-05 - acc: 0.0000e+00 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
      "Epoch 275/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.7613e-05 - acc: 0.0000e+00 - val_loss: 0.0045 - val_acc: 0.0000e+000.\n",
      "Epoch 276/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.6305e-05 - acc: 0.0000e+00 - val_loss: 0.0054 - val_acc: 0.0000e+00\n",
      "Epoch 277/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8780e-05 - acc: 0.0000e+00 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
      "Epoch 278/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3515e-05 - acc: 0.0000e+00 - val_loss: 0.0049 - val_acc: 0.0000e+00\n",
      "Epoch 279/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.5842e-05 - acc: 0.0000e+00 - val_loss: 0.0053 - val_acc: 0.0000e+00\n",
      "Epoch 280/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8655e-05 - acc: 0.0000e+00 - val_loss: 0.0047 - val_acc: 0.0000e+00\n",
      "Epoch 281/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1377e-05 - acc: 0.0000e+00 - val_loss: 0.0054 - val_acc: 0.0000e+000.0000e+0\n",
      "Epoch 282/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9263e-05 - acc: 0.0000e+00 - val_loss: 0.0044 - val_acc: 0.0000e+00\n",
      "Epoch 283/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3323e-05 - acc: 0.0000e+00 - val_loss: 0.0054 - val_acc: 0.0000e+00\n",
      "Epoch 284/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8771e-05 - acc: 0.0000e+00 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
      "Epoch 285/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.4792e-05 - acc: 0.0000e+00 - val_loss: 0.0054 - val_acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0443e-05 - acc: 0.0000e+00 - val_loss: 0.0043 - val_acc: 0.0000e+00\n",
      "Epoch 287/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.4249e-05 - acc: 0.0000e+00 - val_loss: 0.0053 - val_acc: 0.0000e+00\n",
      "Epoch 288/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.2886e-05 - acc: 0.0000e+00 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Epoch 289/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.4691e-05 - acc: 0.0000e+00 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
      "Epoch 290/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0465e-05 - acc: 0.0000e+00 - val_loss: 0.0058 - val_acc: 0.0000e+000.000\n",
      "Epoch 291/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8374e-05 - acc: 0.0000e+00 - val_loss: 0.0055 - val_acc: 0.0000e+00\n",
      "Epoch 292/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0230e-05 - acc: 0.0000e+00 - val_loss: 0.0052 - val_acc: 0.0000e+00\n",
      "Epoch 293/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.0778e-05 - acc: 0.0000e+00 - val_loss: 0.0053 - val_acc: 0.0000e+000.000\n",
      "Epoch 294/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8689e-05 - acc: 0.0000e+00 - val_loss: 0.0054 - val_acc: 0.0000e+00\n",
      "Epoch 295/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4792e-05 - acc: 0.0000e+00 - val_loss: 0.0055 - val_acc: 0.0000e+00\n",
      "Epoch 296/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.2182e-05 - acc: 0.0000e+00 - val_loss: 0.0056 - val_acc: 0.0000e+00\n",
      "Epoch 297/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.7594e-05 - acc: 0.0000e+00 - val_loss: 0.0061 - val_acc: 0.0000e+00\n",
      "Epoch 298/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13702/13702 [==============================] - 1s - loss: 7.9138e-05 - acc: 0.0000e+00 - val_loss: 0.0060 - val_acc: 0.0000e+00\n",
      "Epoch 299/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.6621e-05 - acc: 0.0000e+00 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Epoch 300/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.7939e-05 - acc: 0.0000e+00 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00119 MSE (0.03 RMSE)\n",
      "Test Score: 0.06796 MSE (0.26 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_29 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_30 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13702 samples, validate on 1523 samples\n",
      "Epoch 1/300\n",
      "13702/13702 [==============================] - 4s - loss: 0.0138 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "13702/13702 [==============================] - 1s - loss: 0.0017 - acc: 0.0000e+00 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "13702/13702 [==============================] - 1s - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 6.5230e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "13702/13702 [==============================] - 1s - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "13702/13702 [==============================] - 1s - loss: 0.0011 - acc: 0.0000e+00 - val_loss: 4.9021e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "13702/13702 [==============================] - 1s - loss: 0.0011 - acc: 0.0000e+00 - val_loss: 9.8289e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.6046e-04 - acc: 0.0000e+00 - val_loss: 3.3653e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "13702/13702 [==============================] - 1s - loss: 0.0010 - acc: 0.0000e+00 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.7068e-04 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3338e-04 - acc: 0.0000e+00 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.5037e-04 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.6161e-04 - acc: 0.0000e+00 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.6060e-04 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+000.0000e+\n",
      "Epoch 14/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9179e-04 - acc: 0.0000e+00 - val_loss: 0.0051 - val_acc: 0.0000e+000.000\n",
      "Epoch 15/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.6830e-04 - acc: 0.0000e+00 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4102e-04 - acc: 0.0000e+00 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.6332e-04 - acc: 0.0000e+00 - val_loss: 0.0058 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.3765e-04 - acc: 0.0000e+00 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6167e-04 - acc: 0.0000e+00 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6200e-04 - acc: 0.0000e+00 - val_loss: 0.0043 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6812e-04 - acc: 0.0000e+00 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4723e-04 - acc: 0.0000e+00 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9521e-04 - acc: 0.0000e+00 - val_loss: 0.0080 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3330e-04 - acc: 0.0000e+00 - val_loss: 0.0059 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9014e-04 - acc: 0.0000e+00 - val_loss: 0.0079 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8288e-04 - acc: 0.0000e+00 - val_loss: 0.0048 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8344e-04 - acc: 0.0000e+00 - val_loss: 0.0071 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.5036e-04 - acc: 0.0000e+00 - val_loss: 0.0051 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.1867e-04 - acc: 0.0000e+00 - val_loss: 0.0067 - val_acc: 0.0000e+000.0000\n",
      "Epoch 30/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9795e-04 - acc: 0.0000e+00 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9341e-04 - acc: 0.0000e+00 - val_loss: 0.0087 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.8631e-04 - acc: 0.0000e+00 - val_loss: 0.0070 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6503e-04 - acc: 0.0000e+00 - val_loss: 0.0078 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6121e-04 - acc: 0.0000e+00 - val_loss: 0.0086 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1851e-04 - acc: 0.0000e+00 - val_loss: 0.0109 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6903e-04 - acc: 0.0000e+00 - val_loss: 0.0087 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8107e-04 - acc: 0.0000e+00 - val_loss: 0.0087 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.9109e-04 - acc: 0.0000e+00 - val_loss: 0.0092 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7466e-04 - acc: 0.0000e+00 - val_loss: 0.0061 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5747e-04 - acc: 0.0000e+00 - val_loss: 0.0055 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3411e-04 - acc: 0.0000e+00 - val_loss: 0.0060 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.0964e-04 - acc: 0.0000e+00 - val_loss: 0.0074 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3134e-04 - acc: 0.0000e+00 - val_loss: 0.0063 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.1705e-04 - acc: 0.0000e+00 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.8323e-04 - acc: 0.0000e+00 - val_loss: 0.0074 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.8594e-04 - acc: 0.0000e+00 - val_loss: 0.0085 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.7427e-04 - acc: 0.0000e+00 - val_loss: 0.0074 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.8688e-04 - acc: 0.0000e+00 - val_loss: 0.0074 - val_acc: 0.0000e+000.000\n",
      "Epoch 49/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.7037e-04 - acc: 0.0000e+00 - val_loss: 0.0081 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.9036e-04 - acc: 0.0000e+00 - val_loss: 0.0077 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.5137e-04 - acc: 0.0000e+00 - val_loss: 0.0081 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.2770e-04 - acc: 0.0000e+00 - val_loss: 0.0064 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.5440e-04 - acc: 0.0000e+00 - val_loss: 0.0057 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.3051e-04 - acc: 0.0000e+00 - val_loss: 0.0090 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.5118e-04 - acc: 0.0000e+00 - val_loss: 0.0053 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.3575e-04 - acc: 0.0000e+00 - val_loss: 0.0063 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.2918e-04 - acc: 0.0000e+00 - val_loss: 0.0079 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.4577e-04 - acc: 0.0000e+00 - val_loss: 0.0073 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.2373e-04 - acc: 0.0000e+00 - val_loss: 0.0089 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.1266e-04 - acc: 0.0000e+00 - val_loss: 0.0092 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.1133e-04 - acc: 0.0000e+00 - val_loss: 0.0080 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.3447e-04 - acc: 0.0000e+00 - val_loss: 0.0120 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.2961e-04 - acc: 0.0000e+00 - val_loss: 0.0105 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.0946e-04 - acc: 0.0000e+00 - val_loss: 0.0084 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.1914e-04 - acc: 0.0000e+00 - val_loss: 0.0087 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.1934e-04 - acc: 0.0000e+00 - val_loss: 0.0107 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.0701e-04 - acc: 0.0000e+00 - val_loss: 0.0101 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9894e-04 - acc: 0.0000e+00 - val_loss: 0.0100 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9843e-04 - acc: 0.0000e+00 - val_loss: 0.0114 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.0821e-04 - acc: 0.0000e+00 - val_loss: 0.0098 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.0083e-04 - acc: 0.0000e+00 - val_loss: 0.0091 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9968e-04 - acc: 0.0000e+00 - val_loss: 0.0095 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9959e-04 - acc: 0.0000e+00 - val_loss: 0.0099 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9667e-04 - acc: 0.0000e+00 - val_loss: 0.0110 - val_acc: 0.0000e+000.0000e+\n",
      "Epoch 75/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.2525e-04 - acc: 0.0000e+00 - val_loss: 0.0105 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9806e-04 - acc: 0.0000e+00 - val_loss: 0.0115 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9375e-04 - acc: 0.0000e+00 - val_loss: 0.0106 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.0027e-04 - acc: 0.0000e+00 - val_loss: 0.0114 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9015e-04 - acc: 0.0000e+00 - val_loss: 0.0133 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.0844e-04 - acc: 0.0000e+00 - val_loss: 0.0134 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8935e-04 - acc: 0.0000e+00 - val_loss: 0.0117 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8755e-04 - acc: 0.0000e+00 - val_loss: 0.0143 - val_acc: 0.0000e+000.0000e+0\n",
      "Epoch 83/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.2090e-04 - acc: 0.0000e+00 - val_loss: 0.0169 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9312e-04 - acc: 0.0000e+00 - val_loss: 0.0129 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7749e-04 - acc: 0.0000e+00 - val_loss: 0.0097 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8486e-04 - acc: 0.0000e+00 - val_loss: 0.0147 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8044e-04 - acc: 0.0000e+00 - val_loss: 0.0127 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7809e-04 - acc: 0.0000e+00 - val_loss: 0.0128 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7205e-04 - acc: 0.0000e+00 - val_loss: 0.0142 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8813e-04 - acc: 0.0000e+00 - val_loss: 0.0150 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7716e-04 - acc: 0.0000e+00 - val_loss: 0.0155 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8283e-04 - acc: 0.0000e+00 - val_loss: 0.0148 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7787e-04 - acc: 0.0000e+00 - val_loss: 0.0140 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7191e-04 - acc: 0.0000e+00 - val_loss: 0.0163 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7666e-04 - acc: 0.0000e+00 - val_loss: 0.0143 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9055e-04 - acc: 0.0000e+00 - val_loss: 0.0178 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7386e-04 - acc: 0.0000e+00 - val_loss: 0.0179 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7108e-04 - acc: 0.0000e+00 - val_loss: 0.0157 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7312e-04 - acc: 0.0000e+00 - val_loss: 0.0162 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7301e-04 - acc: 0.0000e+00 - val_loss: 0.0190 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6941e-04 - acc: 0.0000e+00 - val_loss: 0.0179 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7502e-04 - acc: 0.0000e+00 - val_loss: 0.0181 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6959e-04 - acc: 0.0000e+00 - val_loss: 0.0185 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6169e-04 - acc: 0.0000e+00 - val_loss: 0.0175 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13702/13702 [==============================] - 1s - loss: 1.5937e-04 - acc: 0.0000e+00 - val_loss: 0.0191 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6408e-04 - acc: 0.0000e+00 - val_loss: 0.0204 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7346e-04 - acc: 0.0000e+00 - val_loss: 0.0188 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7607e-04 - acc: 0.0000e+00 - val_loss: 0.0209 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6748e-04 - acc: 0.0000e+00 - val_loss: 0.0222 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6552e-04 - acc: 0.0000e+00 - val_loss: 0.0213 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6837e-04 - acc: 0.0000e+00 - val_loss: 0.0215 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6661e-04 - acc: 0.0000e+00 - val_loss: 0.0216 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7291e-04 - acc: 0.0000e+00 - val_loss: 0.0204 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5704e-04 - acc: 0.0000e+00 - val_loss: 0.0206 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5654e-04 - acc: 0.0000e+00 - val_loss: 0.0218 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5805e-04 - acc: 0.0000e+00 - val_loss: 0.0249 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6865e-04 - acc: 0.0000e+00 - val_loss: 0.0212 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6981e-04 - acc: 0.0000e+00 - val_loss: 0.0217 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5490e-04 - acc: 0.0000e+00 - val_loss: 0.0229 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6080e-04 - acc: 0.0000e+00 - val_loss: 0.0234 - val_acc: 0.0000e+000.000\n",
      "Epoch 121/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5785e-04 - acc: 0.0000e+00 - val_loss: 0.0261 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6486e-04 - acc: 0.0000e+00 - val_loss: 0.0243 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4897e-04 - acc: 0.0000e+00 - val_loss: 0.0237 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4837e-04 - acc: 0.0000e+00 - val_loss: 0.0236 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6152e-04 - acc: 0.0000e+00 - val_loss: 0.0259 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5313e-04 - acc: 0.0000e+00 - val_loss: 0.0247 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5579e-04 - acc: 0.0000e+00 - val_loss: 0.0240 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5161e-04 - acc: 0.0000e+00 - val_loss: 0.0253 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4936e-04 - acc: 0.0000e+00 - val_loss: 0.0269 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4931e-04 - acc: 0.0000e+00 - val_loss: 0.0261 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5253e-04 - acc: 0.0000e+00 - val_loss: 0.0267 - val_acc: 0.0000e+00\n",
      "Epoch 132/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4954e-04 - acc: 0.0000e+00 - val_loss: 0.0299 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5850e-04 - acc: 0.0000e+00 - val_loss: 0.0278 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6176e-04 - acc: 0.0000e+00 - val_loss: 0.0302 - val_acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4731e-04 - acc: 0.0000e+00 - val_loss: 0.0300 - val_acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4503e-04 - acc: 0.0000e+00 - val_loss: 0.0260 - val_acc: 0.0000e+000.000\n",
      "Epoch 137/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4453e-04 - acc: 0.0000e+00 - val_loss: 0.0310 - val_acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5217e-04 - acc: 0.0000e+00 - val_loss: 0.0290 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6020e-04 - acc: 0.0000e+00 - val_loss: 0.0281 - val_acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5872e-04 - acc: 0.0000e+00 - val_loss: 0.0288 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5016e-04 - acc: 0.0000e+00 - val_loss: 0.0278 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5569e-04 - acc: 0.0000e+00 - val_loss: 0.0278 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6434e-04 - acc: 0.0000e+00 - val_loss: 0.0265 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6999e-04 - acc: 0.0000e+00 - val_loss: 0.0264 - val_acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4926e-04 - acc: 0.0000e+00 - val_loss: 0.0298 - val_acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5920e-04 - acc: 0.0000e+00 - val_loss: 0.0325 - val_acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4636e-04 - acc: 0.0000e+00 - val_loss: 0.0304 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5600e-04 - acc: 0.0000e+00 - val_loss: 0.0291 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6747e-04 - acc: 0.0000e+00 - val_loss: 0.0315 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5907e-04 - acc: 0.0000e+00 - val_loss: 0.0297 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4717e-04 - acc: 0.0000e+00 - val_loss: 0.0286 - val_acc: 0.0000e+00\n",
      "Epoch 152/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4868e-04 - acc: 0.0000e+00 - val_loss: 0.0306 - val_acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4513e-04 - acc: 0.0000e+00 - val_loss: 0.0310 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5364e-04 - acc: 0.0000e+00 - val_loss: 0.0283 - val_acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4171e-04 - acc: 0.0000e+00 - val_loss: 0.0310 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4190e-04 - acc: 0.0000e+00 - val_loss: 0.0313 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5245e-04 - acc: 0.0000e+00 - val_loss: 0.0319 - val_acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5031e-04 - acc: 0.0000e+00 - val_loss: 0.0347 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3929e-04 - acc: 0.0000e+00 - val_loss: 0.0304 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4962e-04 - acc: 0.0000e+00 - val_loss: 0.0315 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5208e-04 - acc: 0.0000e+00 - val_loss: 0.0313 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4527e-04 - acc: 0.0000e+00 - val_loss: 0.0314 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5024e-04 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4392e-04 - acc: 0.0000e+00 - val_loss: 0.0312 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3748e-04 - acc: 0.0000e+00 - val_loss: 0.0305 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4036e-04 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4800e-04 - acc: 0.0000e+00 - val_loss: 0.0317 - val_acc: 0.0000e+00\n",
      "Epoch 168/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5110e-04 - acc: 0.0000e+00 - val_loss: 0.0357 - val_acc: 0.0000e+00\n",
      "Epoch 169/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5115e-04 - acc: 0.0000e+00 - val_loss: 0.0310 - val_acc: 0.0000e+00\n",
      "Epoch 170/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4514e-04 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5196e-04 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4729e-04 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4233e-04 - acc: 0.0000e+00 - val_loss: 0.0347 - val_acc: 0.0000e+00\n",
      "Epoch 174/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4182e-04 - acc: 0.0000e+00 - val_loss: 0.0354 - val_acc: 0.0000e+00\n",
      "Epoch 175/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6596e-04 - acc: 0.0000e+00 - val_loss: 0.0349 - val_acc: 0.0000e+00\n",
      "Epoch 176/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4592e-04 - acc: 0.0000e+00 - val_loss: 0.0357 - val_acc: 0.0000e+00\n",
      "Epoch 177/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4454e-04 - acc: 0.0000e+00 - val_loss: 0.0346 - val_acc: 0.0000e+00\n",
      "Epoch 178/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4870e-04 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 179/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3853e-04 - acc: 0.0000e+00 - val_loss: 0.0304 - val_acc: 0.0000e+00\n",
      "Epoch 180/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4586e-04 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 181/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4767e-04 - acc: 0.0000e+00 - val_loss: 0.0350 - val_acc: 0.0000e+00\n",
      "Epoch 182/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3342e-04 - acc: 0.0000e+00 - val_loss: 0.0345 - val_acc: 0.0000e+00\n",
      "Epoch 183/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3567e-04 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 184/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3284e-04 - acc: 0.0000e+00 - val_loss: 0.0344 - val_acc: 0.0000e+00\n",
      "Epoch 185/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3521e-04 - acc: 0.0000e+00 - val_loss: 0.0341 - val_acc: 0.0000e+00\n",
      "Epoch 186/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4062e-04 - acc: 0.0000e+00 - val_loss: 0.0354 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3751e-04 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 188/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4756e-04 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 189/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4612e-04 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 190/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4534e-04 - acc: 0.0000e+00 - val_loss: 0.0341 - val_acc: 0.0000e+00\n",
      "Epoch 191/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3642e-04 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 192/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3641e-04 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 193/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4635e-04 - acc: 0.0000e+00 - val_loss: 0.0341 - val_acc: 0.0000e+00\n",
      "Epoch 194/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5511e-04 - acc: 0.0000e+00 - val_loss: 0.0353 - val_acc: 0.0000e+00\n",
      "Epoch 195/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3058e-04 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 196/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3434e-04 - acc: 0.0000e+00 - val_loss: 0.0325 - val_acc: 0.0000e+00\n",
      "Epoch 197/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3567e-04 - acc: 0.0000e+00 - val_loss: 0.0341 - val_acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3670e-04 - acc: 0.0000e+00 - val_loss: 0.0351 - val_acc: 0.0000e+00\n",
      "Epoch 199/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4268e-04 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 200/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3357e-04 - acc: 0.0000e+00 - val_loss: 0.0340 - val_acc: 0.0000e+00\n",
      "Epoch 201/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2925e-04 - acc: 0.0000e+00 - val_loss: 0.0353 - val_acc: 0.0000e+00\n",
      "Epoch 202/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3948e-04 - acc: 0.0000e+00 - val_loss: 0.0353 - val_acc: 0.0000e+00\n",
      "Epoch 203/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3250e-04 - acc: 0.0000e+00 - val_loss: 0.0359 - val_acc: 0.0000e+00\n",
      "Epoch 204/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2650e-04 - acc: 0.0000e+00 - val_loss: 0.0351 - val_acc: 0.0000e+00\n",
      "Epoch 205/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2902e-04 - acc: 0.0000e+00 - val_loss: 0.0355 - val_acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3395e-04 - acc: 0.0000e+00 - val_loss: 0.0359 - val_acc: 0.0000e+00\n",
      "Epoch 207/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3032e-04 - acc: 0.0000e+00 - val_loss: 0.0350 - val_acc: 0.0000e+00\n",
      "Epoch 208/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3161e-04 - acc: 0.0000e+00 - val_loss: 0.0361 - val_acc: 0.0000e+00\n",
      "Epoch 209/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3280e-04 - acc: 0.0000e+00 - val_loss: 0.0342 - val_acc: 0.0000e+00\n",
      "Epoch 210/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2652e-04 - acc: 0.0000e+00 - val_loss: 0.0345 - val_acc: 0.0000e+00\n",
      "Epoch 211/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2995e-04 - acc: 0.0000e+00 - val_loss: 0.0342 - val_acc: 0.0000e+00\n",
      "Epoch 212/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3373e-04 - acc: 0.0000e+00 - val_loss: 0.0342 - val_acc: 0.0000e+00\n",
      "Epoch 213/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2913e-04 - acc: 0.0000e+00 - val_loss: 0.0364 - val_acc: 0.0000e+00\n",
      "Epoch 214/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2724e-04 - acc: 0.0000e+00 - val_loss: 0.0356 - val_acc: 0.0000e+00\n",
      "Epoch 215/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3273e-04 - acc: 0.0000e+00 - val_loss: 0.0353 - val_acc: 0.0000e+00\n",
      "Epoch 216/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2514e-04 - acc: 0.0000e+00 - val_loss: 0.0347 - val_acc: 0.0000e+00\n",
      "Epoch 217/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2304e-04 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 218/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2463e-04 - acc: 0.0000e+00 - val_loss: 0.0363 - val_acc: 0.0000e+00\n",
      "Epoch 219/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13702/13702 [==============================] - 1s - loss: 1.2767e-04 - acc: 0.0000e+00 - val_loss: 0.0346 - val_acc: 0.0000e+00\n",
      "Epoch 220/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3333e-04 - acc: 0.0000e+00 - val_loss: 0.0350 - val_acc: 0.0000e+00\n",
      "Epoch 221/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2127e-04 - acc: 0.0000e+00 - val_loss: 0.0360 - val_acc: 0.0000e+00\n",
      "Epoch 222/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3149e-04 - acc: 0.0000e+00 - val_loss: 0.0349 - val_acc: 0.0000e+00\n",
      "Epoch 223/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3118e-04 - acc: 0.0000e+00 - val_loss: 0.0347 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3272e-04 - acc: 0.0000e+00 - val_loss: 0.0339 - val_acc: 0.0000e+00\n",
      "Epoch 225/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2200e-04 - acc: 0.0000e+00 - val_loss: 0.0352 - val_acc: 0.0000e+00\n",
      "Epoch 226/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2153e-04 - acc: 0.0000e+00 - val_loss: 0.0355 - val_acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3019e-04 - acc: 0.0000e+00 - val_loss: 0.0356 - val_acc: 0.0000e+00\n",
      "Epoch 228/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3147e-04 - acc: 0.0000e+00 - val_loss: 0.0341 - val_acc: 0.0000e+00\n",
      "Epoch 229/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2180e-04 - acc: 0.0000e+00 - val_loss: 0.0370 - val_acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2825e-04 - acc: 0.0000e+00 - val_loss: 0.0374 - val_acc: 0.0000e+00\n",
      "Epoch 231/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2662e-04 - acc: 0.0000e+00 - val_loss: 0.0359 - val_acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1807e-04 - acc: 0.0000e+00 - val_loss: 0.0357 - val_acc: 0.0000e+00\n",
      "Epoch 233/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3371e-04 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 234/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2195e-04 - acc: 0.0000e+00 - val_loss: 0.0346 - val_acc: 0.0000e+00\n",
      "Epoch 235/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1892e-04 - acc: 0.0000e+00 - val_loss: 0.0329 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4038e-04 - acc: 0.0000e+00 - val_loss: 0.0353 - val_acc: 0.0000e+00\n",
      "Epoch 237/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3148e-04 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 238/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1812e-04 - acc: 0.0000e+00 - val_loss: 0.0346 - val_acc: 0.0000e+00\n",
      "Epoch 239/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2764e-04 - acc: 0.0000e+00 - val_loss: 0.0368 - val_acc: 0.0000e+00\n",
      "Epoch 240/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2171e-04 - acc: 0.0000e+00 - val_loss: 0.0344 - val_acc: 0.0000e+00\n",
      "Epoch 241/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2066e-04 - acc: 0.0000e+00 - val_loss: 0.0339 - val_acc: 0.0000e+00\n",
      "Epoch 242/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1932e-04 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 243/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3358e-04 - acc: 0.0000e+00 - val_loss: 0.0339 - val_acc: 0.0000e+00\n",
      "Epoch 244/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3335e-04 - acc: 0.0000e+00 - val_loss: 0.0356 - val_acc: 0.0000e+00\n",
      "Epoch 245/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2209e-04 - acc: 0.0000e+00 - val_loss: 0.0357 - val_acc: 0.0000e+00\n",
      "Epoch 246/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2205e-04 - acc: 0.0000e+00 - val_loss: 0.0366 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1827e-04 - acc: 0.0000e+00 - val_loss: 0.0358 - val_acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2181e-04 - acc: 0.0000e+00 - val_loss: 0.0345 - val_acc: 0.0000e+00\n",
      "Epoch 249/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1912e-04 - acc: 0.0000e+00 - val_loss: 0.0348 - val_acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2018e-04 - acc: 0.0000e+00 - val_loss: 0.0362 - val_acc: 0.0000e+00\n",
      "Epoch 251/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3371e-04 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2450e-04 - acc: 0.0000e+00 - val_loss: 0.0351 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2947e-04 - acc: 0.0000e+00 - val_loss: 0.0368 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2153e-04 - acc: 0.0000e+00 - val_loss: 0.0329 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2082e-04 - acc: 0.0000e+00 - val_loss: 0.0342 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1632e-04 - acc: 0.0000e+00 - val_loss: 0.0346 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2359e-04 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1809e-04 - acc: 0.0000e+00 - val_loss: 0.0355 - val_acc: 0.0000e+00\n",
      "Epoch 259/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1676e-04 - acc: 0.0000e+00 - val_loss: 0.0346 - val_acc: 0.0000e+00\n",
      "Epoch 260/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1919e-04 - acc: 0.0000e+00 - val_loss: 0.0355 - val_acc: 0.0000e+00\n",
      "Epoch 261/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1845e-04 - acc: 0.0000e+00 - val_loss: 0.0353 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1971e-04 - acc: 0.0000e+00 - val_loss: 0.0361 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2047e-04 - acc: 0.0000e+00 - val_loss: 0.0345 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2095e-04 - acc: 0.0000e+00 - val_loss: 0.0348 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2234e-04 - acc: 0.0000e+00 - val_loss: 0.0362 - val_acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2183e-04 - acc: 0.0000e+00 - val_loss: 0.0346 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2994e-04 - acc: 0.0000e+00 - val_loss: 0.0375 - val_acc: 0.0000e+00\n",
      "Epoch 268/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1891e-04 - acc: 0.0000e+00 - val_loss: 0.0350 - val_acc: 0.0000e+00\n",
      "Epoch 269/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2397e-04 - acc: 0.0000e+00 - val_loss: 0.0361 - val_acc: 0.0000e+00\n",
      "Epoch 270/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2183e-04 - acc: 0.0000e+00 - val_loss: 0.0378 - val_acc: 0.0000e+00\n",
      "Epoch 271/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3585e-04 - acc: 0.0000e+00 - val_loss: 0.0369 - val_acc: 0.0000e+00\n",
      "Epoch 272/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2164e-04 - acc: 0.0000e+00 - val_loss: 0.0360 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1416e-04 - acc: 0.0000e+00 - val_loss: 0.0368 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1925e-04 - acc: 0.0000e+00 - val_loss: 0.0346 - val_acc: 0.0000e+00\n",
      "Epoch 275/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2074e-04 - acc: 0.0000e+00 - val_loss: 0.0364 - val_acc: 0.0000e+00\n",
      "Epoch 276/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1966e-04 - acc: 0.0000e+00 - val_loss: 0.0360 - val_acc: 0.0000e+00\n",
      "Epoch 277/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1957e-04 - acc: 0.0000e+00 - val_loss: 0.0357 - val_acc: 0.0000e+00\n",
      "Epoch 278/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2117e-04 - acc: 0.0000e+00 - val_loss: 0.0358 - val_acc: 0.0000e+00\n",
      "Epoch 279/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1540e-04 - acc: 0.0000e+00 - val_loss: 0.0361 - val_acc: 0.0000e+00\n",
      "Epoch 280/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1603e-04 - acc: 0.0000e+00 - val_loss: 0.0372 - val_acc: 0.0000e+00\n",
      "Epoch 281/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1518e-04 - acc: 0.0000e+00 - val_loss: 0.0354 - val_acc: 0.0000e+00\n",
      "Epoch 282/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1142e-04 - acc: 0.0000e+00 - val_loss: 0.0377 - val_acc: 0.0000e+00\n",
      "Epoch 283/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3169e-04 - acc: 0.0000e+00 - val_loss: 0.0380 - val_acc: 0.0000e+00\n",
      "Epoch 284/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1358e-04 - acc: 0.0000e+00 - val_loss: 0.0364 - val_acc: 0.0000e+00\n",
      "Epoch 285/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1650e-04 - acc: 0.0000e+00 - val_loss: 0.0365 - val_acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1636e-04 - acc: 0.0000e+00 - val_loss: 0.0363 - val_acc: 0.0000e+00\n",
      "Epoch 287/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2818e-04 - acc: 0.0000e+00 - val_loss: 0.0357 - val_acc: 0.0000e+00\n",
      "Epoch 288/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1816e-04 - acc: 0.0000e+00 - val_loss: 0.0349 - val_acc: 0.0000e+00\n",
      "Epoch 289/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0846e-04 - acc: 0.0000e+00 - val_loss: 0.0374 - val_acc: 0.0000e+00\n",
      "Epoch 290/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1562e-04 - acc: 0.0000e+00 - val_loss: 0.0356 - val_acc: 0.0000e+00\n",
      "Epoch 291/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1277e-04 - acc: 0.0000e+00 - val_loss: 0.0368 - val_acc: 0.0000e+00\n",
      "Epoch 292/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1469e-04 - acc: 0.0000e+00 - val_loss: 0.0353 - val_acc: 0.0000e+00\n",
      "Epoch 293/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1035e-04 - acc: 0.0000e+00 - val_loss: 0.0346 - val_acc: 0.0000e+00\n",
      "Epoch 294/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1818e-04 - acc: 0.0000e+00 - val_loss: 0.0352 - val_acc: 0.0000e+00\n",
      "Epoch 295/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1572e-04 - acc: 0.0000e+00 - val_loss: 0.0359 - val_acc: 0.0000e+00\n",
      "Epoch 296/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1498e-04 - acc: 0.0000e+00 - val_loss: 0.0373 - val_acc: 0.0000e+00\n",
      "Epoch 297/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1335e-04 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 298/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0915e-04 - acc: 0.0000e+00 - val_loss: 0.0350 - val_acc: 0.0000e+00\n",
      "Epoch 299/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0312e-04 - acc: 0.0000e+00 - val_loss: 0.0351 - val_acc: 0.0000e+00\n",
      "Epoch 300/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1049e-04 - acc: 0.0000e+00 - val_loss: 0.0340 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00651 MSE (0.08 RMSE)\n",
      "Test Score: 0.15820 MSE (0.40 RMSE)\n"
     ]
    }
   ],
   "source": [
    "dlist = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "neurons_LSTM = [32, 64, 128, 256, 512, 1024, 2048]\n",
    "dropout_result = {}\n",
    "\n",
    "for d in dlist:    \n",
    "    trainScore, testScore = quick_measure(stock_name, seq_len, d, shape, neurons, epochs)\n",
    "    dropout_result[d] = testScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.2: 9.0012162654516434e-05, 0.3: 0.0022254438251234927, 0.8: 0.15819754752706974, 0.5: 0.01902325010867283, 0.7: 0.067955376763099332, 0.4: 0.01020233225110141, 0.6: 0.038046965636445065}\n",
      "[0.2]\n"
     ]
    }
   ],
   "source": [
    "min_val = min(dropout_result.values())\n",
    "min_val_key = [k for k, v in dropout_result.items() if v == min_val]\n",
    "print (dropout_result)\n",
    "print (min_val_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYZiZWS5OGGZmlosThpmZ5eKEYWZmufx/Q4p/4M9qMKYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2dec19908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lists = sorted(dropout_result.items())\n",
    "x,y = zip(*lists)\n",
    "plt.plot(x,y)\n",
    "plt.title('Finding the best hyperparameter')\n",
    "plt.xlabel('Dropout')\n",
    "plt.ylabel('Mean Square Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.2 Optimial epochs value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stock_name = '^GSPC'\n",
    "seq_len = 22\n",
    "shape = [4, seq_len, 1] # feature, window, output\n",
    "neurons = [128, 128, 32, 1]\n",
    "epochslist = [10,20,30,40,50,60,70,80,90,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_11 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13702 samples, validate on 1523 samples\n",
      "Epoch 1/10\n",
      "13702/13702 [==============================] - 3s - loss: 0.0129 - acc: 0.0000e+00 - val_loss: 0.0048 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "13702/13702 [==============================] - 1s - loss: 6.0977e-04 - acc: 0.0000e+00 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "13702/13702 [==============================] - 1s - loss: 2.5514e-04 - acc: 0.0000e+00 - val_loss: 5.4461e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "13702/13702 [==============================] - 1s - loss: 1.7068e-04 - acc: 0.0000e+00 - val_loss: 3.1617e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "13702/13702 [==============================] - 1s - loss: 1.3632e-04 - acc: 0.0000e+00 - val_loss: 2.5412e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "13702/13702 [==============================] - 1s - loss: 1.4826e-04 - acc: 0.0000e+00 - val_loss: 3.8467e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "13702/13702 [==============================] - 1s - loss: 1.5060e-04 - acc: 0.0000e+00 - val_loss: 2.4584e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "13702/13702 [==============================] - 1s - loss: 1.3162e-04 - acc: 0.0000e+00 - val_loss: 4.6549e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "13702/13702 [==============================] - 1s - loss: 1.2821e-04 - acc: 0.0000e+00 - val_loss: 2.3023e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "13702/13702 [==============================] - 1s - loss: 1.1644e-04 - acc: 0.0000e+00 - val_loss: 2.2494e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00005 MSE (0.01 RMSE)\n",
      "Test Score: 0.00688 MSE (0.08 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_13 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13702 samples, validate on 1523 samples\n",
      "Epoch 1/20\n",
      "13702/13702 [==============================] - 3s - loss: 0.0133 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 2/20\n",
      "13702/13702 [==============================] - 1s - loss: 5.7648e-04 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 3/20\n",
      "13702/13702 [==============================] - 1s - loss: 2.3047e-04 - acc: 0.0000e+00 - val_loss: 4.4981e-04 - val_acc: 0.0000e+000\n",
      "Epoch 4/20\n",
      "13702/13702 [==============================] - 1s - loss: 1.4836e-04 - acc: 0.0000e+00 - val_loss: 3.9520e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/20\n",
      "13702/13702 [==============================] - 1s - loss: 1.4473e-04 - acc: 0.0000e+00 - val_loss: 2.7514e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/20\n",
      "13702/13702 [==============================] - 1s - loss: 1.3865e-04 - acc: 0.0000e+00 - val_loss: 2.5957e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/20\n",
      "13702/13702 [==============================] - 1s - loss: 1.3782e-04 - acc: 0.0000e+00 - val_loss: 2.3727e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/20\n",
      "13702/13702 [==============================] - 1s - loss: 1.3275e-04 - acc: 0.0000e+00 - val_loss: 2.5933e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/20\n",
      "13702/13702 [==============================] - 1s - loss: 1.3449e-04 - acc: 0.0000e+00 - val_loss: 2.6785e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/20\n",
      "13702/13702 [==============================] - 1s - loss: 1.2307e-04 - acc: 0.0000e+00 - val_loss: 2.4295e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/20\n",
      "13702/13702 [==============================] - 1s - loss: 1.2362e-04 - acc: 0.0000e+00 - val_loss: 2.2618e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/20\n",
      "13702/13702 [==============================] - 1s - loss: 1.3013e-04 - acc: 0.0000e+00 - val_loss: 3.5044e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/20\n",
      "13702/13702 [==============================] - 1s - loss: 1.2809e-04 - acc: 0.0000e+00 - val_loss: 2.9878e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/20\n",
      "13702/13702 [==============================] - 1s - loss: 1.2076e-04 - acc: 0.0000e+00 - val_loss: 2.2057e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/20\n",
      "13702/13702 [==============================] - 1s - loss: 1.2301e-04 - acc: 0.0000e+00 - val_loss: 2.4244e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/20\n",
      "13702/13702 [==============================] - 1s - loss: 1.0470e-04 - acc: 0.0000e+00 - val_loss: 2.4535e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/20\n",
      "13702/13702 [==============================] - 1s - loss: 1.1185e-04 - acc: 0.0000e+00 - val_loss: 2.7684e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/20\n",
      "13702/13702 [==============================] - 1s - loss: 1.1273e-04 - acc: 0.0000e+00 - val_loss: 2.0549e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/20\n",
      "13702/13702 [==============================] - 1s - loss: 1.0107e-04 - acc: 0.0000e+00 - val_loss: 2.0827e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/20\n",
      "13702/13702 [==============================] - 1s - loss: 1.1576e-04 - acc: 0.0000e+00 - val_loss: 1.9721e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00005 MSE (0.01 RMSE)\n",
      "Test Score: 0.00399 MSE (0.06 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_15 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_16 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13702 samples, validate on 1523 samples\n",
      "Epoch 1/30\n",
      "13702/13702 [==============================] - 3s - loss: 0.0130 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 2/30\n",
      "13702/13702 [==============================] - 1s - loss: 7.0148e-04 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 3/30\n",
      "13702/13702 [==============================] - 1s - loss: 2.9509e-04 - acc: 0.0000e+00 - val_loss: 6.0482e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.7697e-04 - acc: 0.0000e+00 - val_loss: 3.1067e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.5215e-04 - acc: 0.0000e+00 - val_loss: 4.4219e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.4073e-04 - acc: 0.0000e+00 - val_loss: 2.6874e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.3135e-04 - acc: 0.0000e+00 - val_loss: 2.7715e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.3380e-04 - acc: 0.0000e+00 - val_loss: 2.3787e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.2737e-04 - acc: 0.0000e+00 - val_loss: 2.4054e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.2328e-04 - acc: 0.0000e+00 - val_loss: 2.3832e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.2693e-04 - acc: 0.0000e+00 - val_loss: 2.9406e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.1905e-04 - acc: 0.0000e+00 - val_loss: 2.9851e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.1706e-04 - acc: 0.0000e+00 - val_loss: 3.2124e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.2192e-04 - acc: 0.0000e+00 - val_loss: 2.5944e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.2931e-04 - acc: 0.0000e+00 - val_loss: 2.6223e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.1747e-04 - acc: 0.0000e+00 - val_loss: 2.4936e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.0972e-04 - acc: 0.0000e+00 - val_loss: 2.3647e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.0306e-04 - acc: 0.0000e+00 - val_loss: 2.2543e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.1887e-04 - acc: 0.0000e+00 - val_loss: 2.0989e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.0859e-04 - acc: 0.0000e+00 - val_loss: 3.8667e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.1471e-04 - acc: 0.0000e+00 - val_loss: 3.6375e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.2573e-04 - acc: 0.0000e+00 - val_loss: 2.6742e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.1244e-04 - acc: 0.0000e+00 - val_loss: 2.6535e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.0619e-04 - acc: 0.0000e+00 - val_loss: 2.1584e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.1700e-04 - acc: 0.0000e+00 - val_loss: 2.0474e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.0436e-04 - acc: 0.0000e+00 - val_loss: 2.3404e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.0469e-04 - acc: 0.0000e+00 - val_loss: 2.2938e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.0402e-04 - acc: 0.0000e+00 - val_loss: 2.4717e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.1419e-04 - acc: 0.0000e+00 - val_loss: 1.8406e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.0101e-04 - acc: 0.0000e+00 - val_loss: 2.2434e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00005 MSE (0.01 RMSE)\n",
      "Test Score: 0.00248 MSE (0.05 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_17 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13702 samples, validate on 1523 samples\n",
      "Epoch 1/40\n",
      "13702/13702 [==============================] - 3s - loss: 0.0123 - acc: 0.0000e+00 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 2/40\n",
      "13702/13702 [==============================] - 1s - loss: 7.2688e-04 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 3/40\n",
      "13702/13702 [==============================] - 1s - loss: 2.6004e-04 - acc: 0.0000e+00 - val_loss: 6.3789e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.6260e-04 - acc: 0.0000e+00 - val_loss: 3.7565e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.5108e-04 - acc: 0.0000e+00 - val_loss: 3.0041e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.4047e-04 - acc: 0.0000e+00 - val_loss: 2.4641e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.3508e-04 - acc: 0.0000e+00 - val_loss: 2.3550e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.3071e-04 - acc: 0.0000e+00 - val_loss: 2.3340e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.2566e-04 - acc: 0.0000e+00 - val_loss: 4.3926e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.3430e-04 - acc: 0.0000e+00 - val_loss: 4.6782e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.3022e-04 - acc: 0.0000e+00 - val_loss: 3.2948e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.3279e-04 - acc: 0.0000e+00 - val_loss: 4.6956e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.2543e-04 - acc: 0.0000e+00 - val_loss: 2.7856e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.2903e-04 - acc: 0.0000e+00 - val_loss: 3.0534e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.1479e-04 - acc: 0.0000e+00 - val_loss: 2.4125e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.1614e-04 - acc: 0.0000e+00 - val_loss: 2.1554e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.1369e-04 - acc: 0.0000e+00 - val_loss: 2.4213e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.0457e-04 - acc: 0.0000e+00 - val_loss: 2.7168e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.0646e-04 - acc: 0.0000e+00 - val_loss: 2.0539e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13702/13702 [==============================] - 1s - loss: 1.1510e-04 - acc: 0.0000e+00 - val_loss: 2.0423e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.3198e-04 - acc: 0.0000e+00 - val_loss: 3.1054e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.1354e-04 - acc: 0.0000e+00 - val_loss: 3.9297e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.1534e-04 - acc: 0.0000e+00 - val_loss: 2.6460e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.0624e-04 - acc: 0.0000e+00 - val_loss: 2.4153e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.1315e-04 - acc: 0.0000e+00 - val_loss: 2.5060e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.0642e-04 - acc: 0.0000e+00 - val_loss: 2.1543e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/40\n",
      "13702/13702 [==============================] - 1s - loss: 9.6967e-05 - acc: 0.0000e+00 - val_loss: 2.0206e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.0736e-04 - acc: 0.0000e+00 - val_loss: 2.9245e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.0128e-04 - acc: 0.0000e+00 - val_loss: 2.7116e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/40\n",
      "13702/13702 [==============================] - 1s - loss: 9.9848e-05 - acc: 0.0000e+00 - val_loss: 1.7949e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.1545e-04 - acc: 0.0000e+00 - val_loss: 6.1536e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.0434e-04 - acc: 0.0000e+00 - val_loss: 1.9542e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/40\n",
      "13702/13702 [==============================] - 1s - loss: 9.5638e-05 - acc: 0.0000e+00 - val_loss: 1.7668e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/40\n",
      "13702/13702 [==============================] - 1s - loss: 9.9248e-05 - acc: 0.0000e+00 - val_loss: 1.8277e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.0626e-04 - acc: 0.0000e+00 - val_loss: 1.6658e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/40\n",
      "13702/13702 [==============================] - 1s - loss: 9.3601e-05 - acc: 0.0000e+00 - val_loss: 1.7512e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/40\n",
      "13702/13702 [==============================] - 1s - loss: 9.3409e-05 - acc: 0.0000e+00 - val_loss: 5.2558e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.1318e-04 - acc: 0.0000e+00 - val_loss: 1.6685e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.0324e-04 - acc: 0.0000e+00 - val_loss: 3.4065e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/40\n",
      "13702/13702 [==============================] - 1s - loss: 9.8323e-05 - acc: 0.0000e+00 - val_loss: 1.6378e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00004 MSE (0.01 RMSE)\n",
      "Test Score: 0.00154 MSE (0.04 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_19 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_20 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13702 samples, validate on 1523 samples\n",
      "Epoch 1/50\n",
      "13702/13702 [==============================] - 3s - loss: 0.0128 - acc: 0.0000e+00 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "13702/13702 [==============================] - 1s - loss: 6.1155e-04 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "13702/13702 [==============================] - 1s - loss: 2.3406e-04 - acc: 0.0000e+00 - val_loss: 5.1013e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.5794e-04 - acc: 0.0000e+00 - val_loss: 3.3826e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.3746e-04 - acc: 0.0000e+00 - val_loss: 2.8517e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.3370e-04 - acc: 0.0000e+00 - val_loss: 3.0560e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.3598e-04 - acc: 0.0000e+00 - val_loss: 2.5555e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.3494e-04 - acc: 0.0000e+00 - val_loss: 2.4354e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.2616e-04 - acc: 0.0000e+00 - val_loss: 2.4152e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.2931e-04 - acc: 0.0000e+00 - val_loss: 2.3151e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.2589e-04 - acc: 0.0000e+00 - val_loss: 2.2615e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.1997e-04 - acc: 0.0000e+00 - val_loss: 2.9215e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.2614e-04 - acc: 0.0000e+00 - val_loss: 2.4829e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.2350e-04 - acc: 0.0000e+00 - val_loss: 2.4059e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.1747e-04 - acc: 0.0000e+00 - val_loss: 2.8092e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.2386e-04 - acc: 0.0000e+00 - val_loss: 2.1389e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "13702/13702 [==============================] - 2s - loss: 1.5281e-04 - acc: 0.0000e+00 - val_loss: 7.2467e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.3556e-04 - acc: 0.0000e+00 - val_loss: 2.1918e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.2646e-04 - acc: 0.0000e+00 - val_loss: 6.1137e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.1138e-04 - acc: 0.0000e+00 - val_loss: 2.0882e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.0793e-04 - acc: 0.0000e+00 - val_loss: 3.8489e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.1824e-04 - acc: 0.0000e+00 - val_loss: 3.1272e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.1111e-04 - acc: 0.0000e+00 - val_loss: 3.2462e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.0455e-04 - acc: 0.0000e+00 - val_loss: 2.5115e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.1037e-04 - acc: 0.0000e+00 - val_loss: 2.3322e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.0611e-04 - acc: 0.0000e+00 - val_loss: 2.0152e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.2070e-04 - acc: 0.0000e+00 - val_loss: 2.0877e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.1532e-04 - acc: 0.0000e+00 - val_loss: 3.0907e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.0028e-04 - acc: 0.0000e+00 - val_loss: 1.8533e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "13702/13702 [==============================] - 1s - loss: 9.8638e-05 - acc: 0.0000e+00 - val_loss: 1.9049e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "13702/13702 [==============================] - 1s - loss: 9.9254e-05 - acc: 0.0000e+00 - val_loss: 1.9360e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.0794e-04 - acc: 0.0000e+00 - val_loss: 1.9874e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.0507e-04 - acc: 0.0000e+00 - val_loss: 4.4674e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.0573e-04 - acc: 0.0000e+00 - val_loss: 4.1609e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.0865e-04 - acc: 0.0000e+00 - val_loss: 1.7750e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "13702/13702 [==============================] - 1s - loss: 9.2070e-05 - acc: 0.0000e+00 - val_loss: 1.7007e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.0111e-04 - acc: 0.0000e+00 - val_loss: 1.8545e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "13702/13702 [==============================] - 1s - loss: 9.9522e-05 - acc: 0.0000e+00 - val_loss: 1.8062e-04 - val_acc: 0.0000e+0000e+\n",
      "Epoch 39/50\n",
      "13702/13702 [==============================] - 1s - loss: 9.3203e-05 - acc: 0.0000e+00 - val_loss: 1.7256e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.0144e-04 - acc: 0.0000e+00 - val_loss: 4.2150e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "13702/13702 [==============================] - 1s - loss: 9.6557e-05 - acc: 0.0000e+00 - val_loss: 1.9540e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "13702/13702 [==============================] - 1s - loss: 9.6155e-05 - acc: 0.0000e+00 - val_loss: 1.6172e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.0363e-04 - acc: 0.0000e+00 - val_loss: 5.1332e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.1237e-04 - acc: 0.0000e+00 - val_loss: 1.6689e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "13702/13702 [==============================] - 1s - loss: 9.0297e-05 - acc: 0.0000e+00 - val_loss: 2.2556e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "13702/13702 [==============================] - 1s - loss: 9.7386e-05 - acc: 0.0000e+00 - val_loss: 2.3616e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "13702/13702 [==============================] - 1s - loss: 8.8869e-05 - acc: 0.0000e+00 - val_loss: 4.3205e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "13702/13702 [==============================] - 1s - loss: 9.0987e-05 - acc: 0.0000e+00 - val_loss: 2.0496e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "13702/13702 [==============================] - 1s - loss: 8.6313e-05 - acc: 0.0000e+00 - val_loss: 2.4355e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.0821e-04 - acc: 0.0000e+00 - val_loss: 1.5587e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00004 MSE (0.01 RMSE)\n",
      "Test Score: 0.00170 MSE (0.04 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_21 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_22 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13702 samples, validate on 1523 samples\n",
      "Epoch 1/60\n",
      "13702/13702 [==============================] - 4s - loss: 0.0134 - acc: 0.0000e+00 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
      "Epoch 2/60\n",
      "13702/13702 [==============================] - 1s - loss: 6.2190e-04 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 3/60\n",
      "13702/13702 [==============================] - 1s - loss: 2.6113e-04 - acc: 0.0000e+00 - val_loss: 7.6390e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.7826e-04 - acc: 0.0000e+00 - val_loss: 4.4907e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.5425e-04 - acc: 0.0000e+00 - val_loss: 2.5851e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.3637e-04 - acc: 0.0000e+00 - val_loss: 2.5611e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.2954e-04 - acc: 0.0000e+00 - val_loss: 4.1833e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.2692e-04 - acc: 0.0000e+00 - val_loss: 3.0945e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.2373e-04 - acc: 0.0000e+00 - val_loss: 2.2293e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.1538e-04 - acc: 0.0000e+00 - val_loss: 2.7871e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.2489e-04 - acc: 0.0000e+00 - val_loss: 3.6884e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.1446e-04 - acc: 0.0000e+00 - val_loss: 2.9499e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.1719e-04 - acc: 0.0000e+00 - val_loss: 2.2603e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.0939e-04 - acc: 0.0000e+00 - val_loss: 2.8784e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.1245e-04 - acc: 0.0000e+00 - val_loss: 2.1426e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.1381e-04 - acc: 0.0000e+00 - val_loss: 2.2118e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.0448e-04 - acc: 0.0000e+00 - val_loss: 6.2976e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.2278e-04 - acc: 0.0000e+00 - val_loss: 2.6181e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.0484e-04 - acc: 0.0000e+00 - val_loss: 2.0276e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.0132e-04 - acc: 0.0000e+00 - val_loss: 2.2941e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.0528e-04 - acc: 0.0000e+00 - val_loss: 2.3044e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.0038e-04 - acc: 0.0000e+00 - val_loss: 1.9034e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/60\n",
      "13702/13702 [==============================] - 1s - loss: 9.8397e-05 - acc: 0.0000e+00 - val_loss: 4.0959e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.1769e-04 - acc: 0.0000e+00 - val_loss: 2.9766e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.0180e-04 - acc: 0.0000e+00 - val_loss: 4.3567e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13702/13702 [==============================] - 1s - loss: 1.0523e-04 - acc: 0.0000e+00 - val_loss: 3.1456e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.1944e-04 - acc: 0.0000e+00 - val_loss: 1.8995e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/60\n",
      "13702/13702 [==============================] - 1s - loss: 9.7833e-05 - acc: 0.0000e+00 - val_loss: 5.1928e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.0059e-04 - acc: 0.0000e+00 - val_loss: 2.1230e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/60\n",
      "13702/13702 [==============================] - 1s - loss: 9.8660e-05 - acc: 0.0000e+00 - val_loss: 1.8401e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/60\n",
      "13702/13702 [==============================] - 1s - loss: 9.4840e-05 - acc: 0.0000e+00 - val_loss: 1.7217e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.0168e-04 - acc: 0.0000e+00 - val_loss: 6.7779e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.0824e-04 - acc: 0.0000e+00 - val_loss: 2.2220e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.0420e-04 - acc: 0.0000e+00 - val_loss: 2.2613e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/60\n",
      "13702/13702 [==============================] - 1s - loss: 9.5481e-05 - acc: 0.0000e+00 - val_loss: 1.6422e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/60\n",
      "13702/13702 [==============================] - 1s - loss: 8.8293e-05 - acc: 0.0000e+00 - val_loss: 1.6237e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/60\n",
      "13702/13702 [==============================] - 1s - loss: 9.4743e-05 - acc: 0.0000e+00 - val_loss: 1.8087e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.0063e-04 - acc: 0.0000e+00 - val_loss: 3.6150e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/60\n",
      "13702/13702 [==============================] - 1s - loss: 9.1039e-05 - acc: 0.0000e+00 - val_loss: 1.6905e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.0646e-04 - acc: 0.0000e+00 - val_loss: 1.7894e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.0141e-04 - acc: 0.0000e+00 - val_loss: 2.6292e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.0765e-04 - acc: 0.0000e+00 - val_loss: 1.5605e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/60\n",
      "13702/13702 [==============================] - 1s - loss: 9.4441e-05 - acc: 0.0000e+00 - val_loss: 1.7894e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/60\n",
      "13702/13702 [==============================] - 1s - loss: 9.1358e-05 - acc: 0.0000e+00 - val_loss: 2.0495e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/60\n",
      "13702/13702 [==============================] - 1s - loss: 9.7955e-05 - acc: 0.0000e+00 - val_loss: 2.2358e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.0812e-04 - acc: 0.0000e+00 - val_loss: 1.5931e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/60\n",
      "13702/13702 [==============================] - 1s - loss: 8.4419e-05 - acc: 0.0000e+00 - val_loss: 2.1661e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/60\n",
      "13702/13702 [==============================] - 1s - loss: 9.6623e-05 - acc: 0.0000e+00 - val_loss: 3.0909e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/60\n",
      "13702/13702 [==============================] - 1s - loss: 9.6570e-05 - acc: 0.0000e+00 - val_loss: 1.7505e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/60\n",
      "13702/13702 [==============================] - 1s - loss: 9.9247e-05 - acc: 0.0000e+00 - val_loss: 3.6997e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/60\n",
      "13702/13702 [==============================] - 1s - loss: 9.2225e-05 - acc: 0.0000e+00 - val_loss: 1.4757e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/60\n",
      "13702/13702 [==============================] - 1s - loss: 8.3969e-05 - acc: 0.0000e+00 - val_loss: 2.3041e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/60\n",
      "13702/13702 [==============================] - 1s - loss: 8.8529e-05 - acc: 0.0000e+00 - val_loss: 1.5467e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/60\n",
      "13702/13702 [==============================] - 1s - loss: 8.9060e-05 - acc: 0.0000e+00 - val_loss: 1.4755e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/60\n",
      "13702/13702 [==============================] - 1s - loss: 8.3598e-05 - acc: 0.0000e+00 - val_loss: 1.3752e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/60\n",
      "13702/13702 [==============================] - 1s - loss: 8.8377e-05 - acc: 0.0000e+00 - val_loss: 2.4285e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/60\n",
      "13702/13702 [==============================] - 1s - loss: 9.5100e-05 - acc: 0.0000e+00 - val_loss: 1.7516e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/60\n",
      "13702/13702 [==============================] - 1s - loss: 8.7111e-05 - acc: 0.0000e+00 - val_loss: 2.2360e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.1126e-04 - acc: 0.0000e+00 - val_loss: 4.3956e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/60\n",
      "13702/13702 [==============================] - 1s - loss: 9.5998e-05 - acc: 0.0000e+00 - val_loss: 2.6369e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00006 MSE (0.01 RMSE)\n",
      "Test Score: 0.00199 MSE (0.04 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_23 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_24 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13702 samples, validate on 1523 samples\n",
      "Epoch 1/70\n",
      "13702/13702 [==============================] - 3s - loss: 0.0114 - acc: 0.0000e+00 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
      "Epoch 2/70\n",
      "13702/13702 [==============================] - 1s - loss: 5.3582e-04 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 3/70\n",
      "13702/13702 [==============================] - 1s - loss: 2.2881e-04 - acc: 0.0000e+00 - val_loss: 5.0299e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.6550e-04 - acc: 0.0000e+00 - val_loss: 5.0301e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.4928e-04 - acc: 0.0000e+00 - val_loss: 3.9074e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.4639e-04 - acc: 0.0000e+00 - val_loss: 2.5880e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.3689e-04 - acc: 0.0000e+00 - val_loss: 2.6389e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.2885e-04 - acc: 0.0000e+00 - val_loss: 2.6504e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.3452e-04 - acc: 0.0000e+00 - val_loss: 2.2839e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.1642e-04 - acc: 0.0000e+00 - val_loss: 3.1370e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.1932e-04 - acc: 0.0000e+00 - val_loss: 2.2707e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.1174e-04 - acc: 0.0000e+00 - val_loss: 3.0295e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.2153e-04 - acc: 0.0000e+00 - val_loss: 2.5243e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.1446e-04 - acc: 0.0000e+00 - val_loss: 2.4334e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.0439e-04 - acc: 0.0000e+00 - val_loss: 2.2274e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.0652e-04 - acc: 0.0000e+00 - val_loss: 2.2469e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.1017e-04 - acc: 0.0000e+00 - val_loss: 2.8146e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.3383e-04 - acc: 0.0000e+00 - val_loss: 6.2469e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.2334e-04 - acc: 0.0000e+00 - val_loss: 2.2057e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.0665e-04 - acc: 0.0000e+00 - val_loss: 1.9796e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.0551e-04 - acc: 0.0000e+00 - val_loss: 2.3774e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.0147e-04 - acc: 0.0000e+00 - val_loss: 3.9446e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.0268e-04 - acc: 0.0000e+00 - val_loss: 2.1510e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.1566e-04 - acc: 0.0000e+00 - val_loss: 3.7664e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.0949e-04 - acc: 0.0000e+00 - val_loss: 1.9650e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.0191e-04 - acc: 0.0000e+00 - val_loss: 1.8888e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.0533e-04 - acc: 0.0000e+00 - val_loss: 1.8349e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/70\n",
      "13702/13702 [==============================] - 1s - loss: 9.6611e-05 - acc: 0.0000e+00 - val_loss: 1.7928e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.0848e-04 - acc: 0.0000e+00 - val_loss: 3.2516e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.0761e-04 - acc: 0.0000e+00 - val_loss: 2.0436e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/70\n",
      "13702/13702 [==============================] - 1s - loss: 9.5905e-05 - acc: 0.0000e+00 - val_loss: 5.1163e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.0422e-04 - acc: 0.0000e+00 - val_loss: 3.6409e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.0747e-04 - acc: 0.0000e+00 - val_loss: 3.8852e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/70\n",
      "13702/13702 [==============================] - 1s - loss: 9.8784e-05 - acc: 0.0000e+00 - val_loss: 1.7454e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/70\n",
      "13702/13702 [==============================] - 1s - loss: 9.3227e-05 - acc: 0.0000e+00 - val_loss: 2.0640e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/70\n",
      "13702/13702 [==============================] - 1s - loss: 8.9350e-05 - acc: 0.0000e+00 - val_loss: 1.7662e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/70\n",
      "13702/13702 [==============================] - 1s - loss: 9.1767e-05 - acc: 0.0000e+00 - val_loss: 1.8748e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/70\n",
      "13702/13702 [==============================] - 1s - loss: 9.5590e-05 - acc: 0.0000e+00 - val_loss: 1.7979e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/70\n",
      "13702/13702 [==============================] - 1s - loss: 9.2854e-05 - acc: 0.0000e+00 - val_loss: 1.6606e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/70\n",
      "13702/13702 [==============================] - 1s - loss: 9.2675e-05 - acc: 0.0000e+00 - val_loss: 2.9546e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/70\n",
      "13702/13702 [==============================] - 1s - loss: 9.6049e-05 - acc: 0.0000e+00 - val_loss: 3.1068e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/70\n",
      "13702/13702 [==============================] - 1s - loss: 9.5226e-05 - acc: 0.0000e+00 - val_loss: 1.7401e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/70\n",
      "13702/13702 [==============================] - 1s - loss: 8.7237e-05 - acc: 0.0000e+00 - val_loss: 5.6944e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/70\n",
      "13702/13702 [==============================] - 1s - loss: 9.8594e-05 - acc: 0.0000e+00 - val_loss: 2.1229e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/70\n",
      "13702/13702 [==============================] - 1s - loss: 8.6426e-05 - acc: 0.0000e+00 - val_loss: 1.6023e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/70\n",
      "13702/13702 [==============================] - 1s - loss: 9.6209e-05 - acc: 0.0000e+00 - val_loss: 1.8303e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/70\n",
      "13702/13702 [==============================] - 1s - loss: 9.9519e-05 - acc: 0.0000e+00 - val_loss: 2.6528e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/70\n",
      "13702/13702 [==============================] - 1s - loss: 9.9857e-05 - acc: 0.0000e+00 - val_loss: 1.9774e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/70\n",
      "13702/13702 [==============================] - 1s - loss: 8.9208e-05 - acc: 0.0000e+00 - val_loss: 1.4867e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/70\n",
      "13702/13702 [==============================] - 1s - loss: 8.8011e-05 - acc: 0.0000e+00 - val_loss: 3.8530e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/70\n",
      "13702/13702 [==============================] - 1s - loss: 9.6348e-05 - acc: 0.0000e+00 - val_loss: 2.3431e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/70\n",
      "13702/13702 [==============================] - 1s - loss: 8.5395e-05 - acc: 0.0000e+00 - val_loss: 3.0095e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/70\n",
      "13702/13702 [==============================] - 1s - loss: 9.2310e-05 - acc: 0.0000e+00 - val_loss: 4.1776e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.1565e-04 - acc: 0.0000e+00 - val_loss: 4.8927e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/70\n",
      "13702/13702 [==============================] - 1s - loss: 9.4294e-05 - acc: 0.0000e+00 - val_loss: 2.3631e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/70\n",
      "13702/13702 [==============================] - 1s - loss: 9.2164e-05 - acc: 0.0000e+00 - val_loss: 4.0009e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.0545e-04 - acc: 0.0000e+00 - val_loss: 5.7392e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/70\n",
      "13702/13702 [==============================] - 1s - loss: 8.5057e-05 - acc: 0.0000e+00 - val_loss: 1.4124e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/70\n",
      "13702/13702 [==============================] - 1s - loss: 8.9082e-05 - acc: 0.0000e+00 - val_loss: 3.3778e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/70\n",
      "13702/13702 [==============================] - 1s - loss: 8.0651e-05 - acc: 0.0000e+00 - val_loss: 1.5310e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/70\n",
      "13702/13702 [==============================] - 1s - loss: 8.5129e-05 - acc: 0.0000e+00 - val_loss: 1.3490e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/70\n",
      "13702/13702 [==============================] - 1s - loss: 7.9467e-05 - acc: 0.0000e+00 - val_loss: 1.9223e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/70\n",
      "13702/13702 [==============================] - 1s - loss: 8.2660e-05 - acc: 0.0000e+00 - val_loss: 1.6330e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/70\n",
      "13702/13702 [==============================] - 1s - loss: 8.1874e-05 - acc: 0.0000e+00 - val_loss: 1.2952e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/70\n",
      "13702/13702 [==============================] - 1s - loss: 7.7345e-05 - acc: 0.0000e+00 - val_loss: 1.3393e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/70\n",
      "13702/13702 [==============================] - 1s - loss: 8.8544e-05 - acc: 0.0000e+00 - val_loss: 1.6032e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/70\n",
      "13702/13702 [==============================] - 1s - loss: 8.1075e-05 - acc: 0.0000e+00 - val_loss: 1.5639e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/70\n",
      "13702/13702 [==============================] - 1s - loss: 8.7115e-05 - acc: 0.0000e+00 - val_loss: 2.3282e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.0141e-04 - acc: 0.0000e+00 - val_loss: 1.8696e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13702/13702 [==============================] - 1s - loss: 7.5550e-05 - acc: 0.0000e+00 - val_loss: 1.2372e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00003 MSE (0.01 RMSE)\n",
      "Test Score: 0.00077 MSE (0.03 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_25 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_26 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13702 samples, validate on 1523 samples\n",
      "Epoch 1/80\n",
      "13702/13702 [==============================] - 3s - loss: 0.0138 - acc: 0.0000e+00 - val_loss: 0.0059 - val_acc: 0.0000e+00\n",
      "Epoch 2/80\n",
      "13702/13702 [==============================] - 1s - loss: 6.6267e-04 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 3/80\n",
      "13702/13702 [==============================] - 1s - loss: 2.4498e-04 - acc: 0.0000e+00 - val_loss: 5.5771e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.7450e-04 - acc: 0.0000e+00 - val_loss: 3.4238e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.4284e-04 - acc: 0.0000e+00 - val_loss: 2.8612e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.4325e-04 - acc: 0.0000e+00 - val_loss: 2.5068e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.2786e-04 - acc: 0.0000e+00 - val_loss: 2.4169e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.3242e-04 - acc: 0.0000e+00 - val_loss: 2.5684e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.3923e-04 - acc: 0.0000e+00 - val_loss: 2.4193e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.2400e-04 - acc: 0.0000e+00 - val_loss: 2.2988e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.1814e-04 - acc: 0.0000e+00 - val_loss: 2.4150e-04 - val_acc: 0.0000e+0000e+0\n",
      "Epoch 12/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.1486e-04 - acc: 0.0000e+00 - val_loss: 2.5128e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.1179e-04 - acc: 0.0000e+00 - val_loss: 2.5135e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.1877e-04 - acc: 0.0000e+00 - val_loss: 2.2166e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.2411e-04 - acc: 0.0000e+00 - val_loss: 2.5036e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.0942e-04 - acc: 0.0000e+00 - val_loss: 3.0699e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.1899e-04 - acc: 0.0000e+00 - val_loss: 2.7711e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.0949e-04 - acc: 0.0000e+00 - val_loss: 2.3521e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.1111e-04 - acc: 0.0000e+00 - val_loss: 4.0093e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.1555e-04 - acc: 0.0000e+00 - val_loss: 2.0657e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.1336e-04 - acc: 0.0000e+00 - val_loss: 6.0995e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.1706e-04 - acc: 0.0000e+00 - val_loss: 1.9505e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.0549e-04 - acc: 0.0000e+00 - val_loss: 3.7993e-04 - val_acc: 0.0000e+0000\n",
      "Epoch 24/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.0323e-04 - acc: 0.0000e+00 - val_loss: 4.6305e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.0563e-04 - acc: 0.0000e+00 - val_loss: 1.9053e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.0076e-04 - acc: 0.0000e+00 - val_loss: 1.9249e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.0156e-04 - acc: 0.0000e+00 - val_loss: 1.7626e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.0609e-04 - acc: 0.0000e+00 - val_loss: 2.2839e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.2693e-04 - acc: 0.0000e+00 - val_loss: 3.9463e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/80\n",
      "13702/13702 [==============================] - 1s - loss: 9.6310e-05 - acc: 0.0000e+00 - val_loss: 1.7287e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/80\n",
      "13702/13702 [==============================] - 1s - loss: 9.8896e-05 - acc: 0.0000e+00 - val_loss: 2.1525e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.0166e-04 - acc: 0.0000e+00 - val_loss: 2.3176e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/80\n",
      "13702/13702 [==============================] - 1s - loss: 9.4258e-05 - acc: 0.0000e+00 - val_loss: 2.6754e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/80\n",
      "13702/13702 [==============================] - 1s - loss: 9.6097e-05 - acc: 0.0000e+00 - val_loss: 1.6225e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/80\n",
      "13702/13702 [==============================] - 1s - loss: 9.8813e-05 - acc: 0.0000e+00 - val_loss: 1.6897e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/80\n",
      "13702/13702 [==============================] - 1s - loss: 9.3064e-05 - acc: 0.0000e+00 - val_loss: 1.7338e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.2087e-04 - acc: 0.0000e+00 - val_loss: 1.8374e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.0334e-04 - acc: 0.0000e+00 - val_loss: 1.7992e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.0013e-04 - acc: 0.0000e+00 - val_loss: 1.7599e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/80\n",
      "13702/13702 [==============================] - 1s - loss: 9.7584e-05 - acc: 0.0000e+00 - val_loss: 2.8530e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/80\n",
      "13702/13702 [==============================] - 1s - loss: 9.0456e-05 - acc: 0.0000e+00 - val_loss: 1.5835e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/80\n",
      "13702/13702 [==============================] - 1s - loss: 8.7274e-05 - acc: 0.0000e+00 - val_loss: 3.0339e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/80\n",
      "13702/13702 [==============================] - 1s - loss: 8.9506e-05 - acc: 0.0000e+00 - val_loss: 1.7252e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/80\n",
      "13702/13702 [==============================] - 1s - loss: 9.5057e-05 - acc: 0.0000e+00 - val_loss: 2.2257e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/80\n",
      "13702/13702 [==============================] - 1s - loss: 8.5424e-05 - acc: 0.0000e+00 - val_loss: 2.0976e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/80\n",
      "13702/13702 [==============================] - 1s - loss: 9.1165e-05 - acc: 0.0000e+00 - val_loss: 2.2740e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/80\n",
      "13702/13702 [==============================] - 1s - loss: 9.0630e-05 - acc: 0.0000e+00 - val_loss: 1.6769e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/80\n",
      "13702/13702 [==============================] - 1s - loss: 8.8074e-05 - acc: 0.0000e+00 - val_loss: 1.4536e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/80\n",
      "13702/13702 [==============================] - 1s - loss: 9.2209e-05 - acc: 0.0000e+00 - val_loss: 1.7540e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/80\n",
      "13702/13702 [==============================] - 1s - loss: 9.2851e-05 - acc: 0.0000e+00 - val_loss: 2.5243e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/80\n",
      "13702/13702 [==============================] - 1s - loss: 8.7746e-05 - acc: 0.0000e+00 - val_loss: 1.4287e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/80\n",
      "13702/13702 [==============================] - 1s - loss: 9.5136e-05 - acc: 0.0000e+00 - val_loss: 1.7713e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/80\n",
      "13702/13702 [==============================] - 1s - loss: 8.4671e-05 - acc: 0.0000e+00 - val_loss: 1.5599e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/80\n",
      "13702/13702 [==============================] - 1s - loss: 9.1294e-05 - acc: 0.0000e+00 - val_loss: 5.7339e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/80\n",
      "13702/13702 [==============================] - 1s - loss: 8.7756e-05 - acc: 0.0000e+00 - val_loss: 2.1205e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/80\n",
      "13702/13702 [==============================] - 1s - loss: 9.5863e-05 - acc: 0.0000e+00 - val_loss: 2.8925e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/80\n",
      "13702/13702 [==============================] - 1s - loss: 9.4177e-05 - acc: 0.0000e+00 - val_loss: 2.1622e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/80\n",
      "13702/13702 [==============================] - 1s - loss: 8.4812e-05 - acc: 0.0000e+00 - val_loss: 4.5734e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/80\n",
      "13702/13702 [==============================] - 1s - loss: 9.0191e-05 - acc: 0.0000e+00 - val_loss: 1.3329e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/80\n",
      "13702/13702 [==============================] - 1s - loss: 7.9338e-05 - acc: 0.0000e+00 - val_loss: 1.4307e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/80\n",
      "13702/13702 [==============================] - 1s - loss: 7.8886e-05 - acc: 0.0000e+00 - val_loss: 1.3166e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/80\n",
      "13702/13702 [==============================] - 1s - loss: 8.0856e-05 - acc: 0.0000e+00 - val_loss: 4.1046e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/80\n",
      "13702/13702 [==============================] - 1s - loss: 8.5818e-05 - acc: 0.0000e+00 - val_loss: 1.5463e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/80\n",
      "13702/13702 [==============================] - 1s - loss: 7.6955e-05 - acc: 0.0000e+00 - val_loss: 2.3536e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/80\n",
      "13702/13702 [==============================] - 1s - loss: 8.5087e-05 - acc: 0.0000e+00 - val_loss: 1.3392e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/80\n",
      "13702/13702 [==============================] - 1s - loss: 8.4392e-05 - acc: 0.0000e+00 - val_loss: 2.1612e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/80\n",
      "13702/13702 [==============================] - 1s - loss: 8.1212e-05 - acc: 0.0000e+00 - val_loss: 1.4533e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/80\n",
      "13702/13702 [==============================] - 1s - loss: 7.6028e-05 - acc: 0.0000e+00 - val_loss: 1.2536e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/80\n",
      "13702/13702 [==============================] - 1s - loss: 7.5669e-05 - acc: 0.0000e+00 - val_loss: 1.2413e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/80\n",
      "13702/13702 [==============================] - 1s - loss: 8.5304e-05 - acc: 0.0000e+00 - val_loss: 4.5873e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/80\n",
      "13702/13702 [==============================] - 1s - loss: 9.2571e-05 - acc: 0.0000e+00 - val_loss: 1.8844e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/80\n",
      "13702/13702 [==============================] - 1s - loss: 7.7260e-05 - acc: 0.0000e+00 - val_loss: 1.3345e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/80\n",
      "13702/13702 [==============================] - 1s - loss: 7.1495e-05 - acc: 0.0000e+00 - val_loss: 1.5215e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/80\n",
      "13702/13702 [==============================] - 1s - loss: 8.2013e-05 - acc: 0.0000e+00 - val_loss: 1.5635e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/80\n",
      "13702/13702 [==============================] - 1s - loss: 7.6542e-05 - acc: 0.0000e+00 - val_loss: 2.3782e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/80\n",
      "13702/13702 [==============================] - 1s - loss: 7.9235e-05 - acc: 0.0000e+00 - val_loss: 1.4939e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/80\n",
      "13702/13702 [==============================] - 1s - loss: 8.4172e-05 - acc: 0.0000e+00 - val_loss: 1.2089e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/80\n",
      "13702/13702 [==============================] - 1s - loss: 7.3653e-05 - acc: 0.0000e+00 - val_loss: 1.7867e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/80\n",
      "13702/13702 [==============================] - 1s - loss: 8.6238e-05 - acc: 0.0000e+00 - val_loss: 1.2428e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/80\n",
      "13702/13702 [==============================] - 1s - loss: 7.3179e-05 - acc: 0.0000e+00 - val_loss: 1.3517e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00003 MSE (0.01 RMSE)\n",
      "Test Score: 0.00088 MSE (0.03 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_27 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_28 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13702 samples, validate on 1523 samples\n",
      "Epoch 1/90\n",
      "13702/13702 [==============================] - 3s - loss: 0.0121 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "13702/13702 [==============================] - 1s - loss: 6.6089e-04 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "13702/13702 [==============================] - 1s - loss: 2.5927e-04 - acc: 0.0000e+00 - val_loss: 5.5867e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.6719e-04 - acc: 0.0000e+00 - val_loss: 3.8243e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.5463e-04 - acc: 0.0000e+00 - val_loss: 3.4004e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.4104e-04 - acc: 0.0000e+00 - val_loss: 2.8467e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.4020e-04 - acc: 0.0000e+00 - val_loss: 2.3961e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.4476e-04 - acc: 0.0000e+00 - val_loss: 2.4082e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.2445e-04 - acc: 0.0000e+00 - val_loss: 2.7234e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.3098e-04 - acc: 0.0000e+00 - val_loss: 2.3597e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.3057e-04 - acc: 0.0000e+00 - val_loss: 2.2887e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.5747e-04 - acc: 0.0000e+00 - val_loss: 3.1798e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.2063e-04 - acc: 0.0000e+00 - val_loss: 2.2660e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.2787e-04 - acc: 0.0000e+00 - val_loss: 4.2290e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.2890e-04 - acc: 0.0000e+00 - val_loss: 2.6728e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13702/13702 [==============================] - 1s - loss: 1.1739e-04 - acc: 0.0000e+00 - val_loss: 2.2743e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.1680e-04 - acc: 0.0000e+00 - val_loss: 2.1673e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.1155e-04 - acc: 0.0000e+00 - val_loss: 3.0512e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.1115e-04 - acc: 0.0000e+00 - val_loss: 2.3868e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.0944e-04 - acc: 0.0000e+00 - val_loss: 4.0689e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.1379e-04 - acc: 0.0000e+00 - val_loss: 4.3390e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.0414e-04 - acc: 0.0000e+00 - val_loss: 1.9290e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.0869e-04 - acc: 0.0000e+00 - val_loss: 1.8922e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.0707e-04 - acc: 0.0000e+00 - val_loss: 2.2854e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.0978e-04 - acc: 0.0000e+00 - val_loss: 1.9289e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.0658e-04 - acc: 0.0000e+00 - val_loss: 4.5127e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.1089e-04 - acc: 0.0000e+00 - val_loss: 2.4062e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.0182e-04 - acc: 0.0000e+00 - val_loss: 1.7791e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "13702/13702 [==============================] - 1s - loss: 9.7911e-05 - acc: 0.0000e+00 - val_loss: 2.1099e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "13702/13702 [==============================] - 1s - loss: 9.8986e-05 - acc: 0.0000e+00 - val_loss: 2.5993e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "13702/13702 [==============================] - 1s - loss: 9.6738e-05 - acc: 0.0000e+00 - val_loss: 4.7060e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.0112e-04 - acc: 0.0000e+00 - val_loss: 1.6995e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "13702/13702 [==============================] - 1s - loss: 9.1422e-05 - acc: 0.0000e+00 - val_loss: 1.8584e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "13702/13702 [==============================] - 1s - loss: 9.4577e-05 - acc: 0.0000e+00 - val_loss: 2.0896e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "13702/13702 [==============================] - 1s - loss: 9.4214e-05 - acc: 0.0000e+00 - val_loss: 1.7028e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "13702/13702 [==============================] - 1s - loss: 9.6956e-05 - acc: 0.0000e+00 - val_loss: 1.7034e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "13702/13702 [==============================] - 1s - loss: 9.6899e-05 - acc: 0.0000e+00 - val_loss: 3.3117e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "13702/13702 [==============================] - 1s - loss: 9.0311e-05 - acc: 0.0000e+00 - val_loss: 1.7297e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "13702/13702 [==============================] - 1s - loss: 8.4781e-05 - acc: 0.0000e+00 - val_loss: 2.3161e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "13702/13702 [==============================] - 1s - loss: 9.2546e-05 - acc: 0.0000e+00 - val_loss: 4.0132e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "13702/13702 [==============================] - 1s - loss: 9.0944e-05 - acc: 0.0000e+00 - val_loss: 2.1072e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "13702/13702 [==============================] - 1s - loss: 8.4480e-05 - acc: 0.0000e+00 - val_loss: 1.9303e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.0171e-04 - acc: 0.0000e+00 - val_loss: 7.2657e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.0352e-04 - acc: 0.0000e+00 - val_loss: 2.7287e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "13702/13702 [==============================] - 1s - loss: 9.9083e-05 - acc: 0.0000e+00 - val_loss: 6.3949e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.0643e-04 - acc: 0.0000e+00 - val_loss: 2.8457e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "13702/13702 [==============================] - 1s - loss: 9.4561e-05 - acc: 0.0000e+00 - val_loss: 1.4829e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "13702/13702 [==============================] - 1s - loss: 8.3505e-05 - acc: 0.0000e+00 - val_loss: 2.7795e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.0506e-04 - acc: 0.0000e+00 - val_loss: 1.5058e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "13702/13702 [==============================] - 1s - loss: 9.1471e-05 - acc: 0.0000e+00 - val_loss: 1.8744e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "13702/13702 [==============================] - 1s - loss: 8.4561e-05 - acc: 0.0000e+00 - val_loss: 1.8416e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "13702/13702 [==============================] - 1s - loss: 7.8978e-05 - acc: 0.0000e+00 - val_loss: 1.9445e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "13702/13702 [==============================] - 1s - loss: 9.8354e-05 - acc: 0.0000e+00 - val_loss: 1.4585e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "13702/13702 [==============================] - 1s - loss: 9.3938e-05 - acc: 0.0000e+00 - val_loss: 1.3755e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "13702/13702 [==============================] - 1s - loss: 9.1736e-05 - acc: 0.0000e+00 - val_loss: 1.6637e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "13702/13702 [==============================] - 1s - loss: 7.7534e-05 - acc: 0.0000e+00 - val_loss: 1.3509e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "13702/13702 [==============================] - 1s - loss: 9.3059e-05 - acc: 0.0000e+00 - val_loss: 1.4621e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "13702/13702 [==============================] - 1s - loss: 8.5632e-05 - acc: 0.0000e+00 - val_loss: 2.0207e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "13702/13702 [==============================] - 1s - loss: 8.5058e-05 - acc: 0.0000e+00 - val_loss: 1.4563e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "13702/13702 [==============================] - 1s - loss: 9.3599e-05 - acc: 0.0000e+00 - val_loss: 2.7951e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.0955e-04 - acc: 0.0000e+00 - val_loss: 2.6817e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.1209e-04 - acc: 0.0000e+00 - val_loss: 1.5426e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "13702/13702 [==============================] - 1s - loss: 9.3626e-05 - acc: 0.0000e+00 - val_loss: 3.6299e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "13702/13702 [==============================] - 1s - loss: 8.8951e-05 - acc: 0.0000e+00 - val_loss: 2.5082e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "13702/13702 [==============================] - 1s - loss: 8.6647e-05 - acc: 0.0000e+00 - val_loss: 1.3087e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "13702/13702 [==============================] - 1s - loss: 7.4261e-05 - acc: 0.0000e+00 - val_loss: 1.5975e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "13702/13702 [==============================] - 1s - loss: 7.6224e-05 - acc: 0.0000e+00 - val_loss: 1.9494e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "13702/13702 [==============================] - 1s - loss: 7.7741e-05 - acc: 0.0000e+00 - val_loss: 1.4849e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "13702/13702 [==============================] - 1s - loss: 7.2226e-05 - acc: 0.0000e+00 - val_loss: 1.2277e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "13702/13702 [==============================] - 1s - loss: 7.3065e-05 - acc: 0.0000e+00 - val_loss: 2.9331e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "13702/13702 [==============================] - 1s - loss: 7.1996e-05 - acc: 0.0000e+00 - val_loss: 1.7227e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "13702/13702 [==============================] - 1s - loss: 7.0804e-05 - acc: 0.0000e+00 - val_loss: 1.5162e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "13702/13702 [==============================] - 1s - loss: 7.6628e-05 - acc: 0.0000e+00 - val_loss: 2.8939e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "13702/13702 [==============================] - 1s - loss: 8.1165e-05 - acc: 0.0000e+00 - val_loss: 4.1937e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "13702/13702 [==============================] - 1s - loss: 8.6824e-05 - acc: 0.0000e+00 - val_loss: 4.4946e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.0001e-04 - acc: 0.0000e+00 - val_loss: 6.7111e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "13702/13702 [==============================] - 1s - loss: 9.8819e-05 - acc: 0.0000e+00 - val_loss: 1.3231e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "13702/13702 [==============================] - 1s - loss: 8.2757e-05 - acc: 0.0000e+00 - val_loss: 1.1742e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "13702/13702 [==============================] - 1s - loss: 6.6830e-05 - acc: 0.0000e+00 - val_loss: 1.1508e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "13702/13702 [==============================] - 1s - loss: 7.4761e-05 - acc: 0.0000e+00 - val_loss: 1.1612e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "13702/13702 [==============================] - 1s - loss: 7.0506e-05 - acc: 0.0000e+00 - val_loss: 1.1273e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "13702/13702 [==============================] - 1s - loss: 7.3993e-05 - acc: 0.0000e+00 - val_loss: 1.1665e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "13702/13702 [==============================] - 1s - loss: 7.2404e-05 - acc: 0.0000e+00 - val_loss: 1.8418e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "13702/13702 [==============================] - 1s - loss: 8.3052e-05 - acc: 0.0000e+00 - val_loss: 1.3797e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "13702/13702 [==============================] - 1s - loss: 7.3539e-05 - acc: 0.0000e+00 - val_loss: 1.1409e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "13702/13702 [==============================] - 1s - loss: 7.0346e-05 - acc: 0.0000e+00 - val_loss: 1.1774e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "13702/13702 [==============================] - 1s - loss: 7.2422e-05 - acc: 0.0000e+00 - val_loss: 1.1808e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "13702/13702 [==============================] - 1s - loss: 6.8385e-05 - acc: 0.0000e+00 - val_loss: 1.0849e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "13702/13702 [==============================] - 1s - loss: 7.2681e-05 - acc: 0.0000e+00 - val_loss: 1.0970e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "13702/13702 [==============================] - 1s - loss: 6.5907e-05 - acc: 0.0000e+00 - val_loss: 1.4743e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00004 MSE (0.01 RMSE)\n",
      "Test Score: 0.00032 MSE (0.02 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_29 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_30 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13702 samples, validate on 1523 samples\n",
      "Epoch 1/100\n",
      "13702/13702 [==============================] - 3s - loss: 0.0130 - acc: 0.0000e+00 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "13702/13702 [==============================] - 1s - loss: 6.3824e-04 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "13702/13702 [==============================] - 1s - loss: 2.3779e-04 - acc: 0.0000e+00 - val_loss: 5.2778e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.5669e-04 - acc: 0.0000e+00 - val_loss: 3.4203e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.4916e-04 - acc: 0.0000e+00 - val_loss: 3.9398e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.3578e-04 - acc: 0.0000e+00 - val_loss: 2.6067e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.3061e-04 - acc: 0.0000e+00 - val_loss: 2.4931e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.4447e-04 - acc: 0.0000e+00 - val_loss: 2.4685e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.3549e-04 - acc: 0.0000e+00 - val_loss: 3.0951e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.1994e-04 - acc: 0.0000e+00 - val_loss: 2.3173e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.1903e-04 - acc: 0.0000e+00 - val_loss: 3.9398e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.2634e-04 - acc: 0.0000e+00 - val_loss: 2.4660e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.1832e-04 - acc: 0.0000e+00 - val_loss: 2.2484e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.2101e-04 - acc: 0.0000e+00 - val_loss: 2.2053e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.2049e-04 - acc: 0.0000e+00 - val_loss: 2.2910e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.1224e-04 - acc: 0.0000e+00 - val_loss: 2.2444e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.1165e-04 - acc: 0.0000e+00 - val_loss: 3.2504e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.0988e-04 - acc: 0.0000e+00 - val_loss: 2.0211e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.1368e-04 - acc: 0.0000e+00 - val_loss: 2.5594e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.3644e-04 - acc: 0.0000e+00 - val_loss: 2.6951e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.1308e-04 - acc: 0.0000e+00 - val_loss: 2.6979e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.0683e-04 - acc: 0.0000e+00 - val_loss: 1.9775e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.0029e-04 - acc: 0.0000e+00 - val_loss: 2.0724e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.0851e-04 - acc: 0.0000e+00 - val_loss: 3.7251e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.0738e-04 - acc: 0.0000e+00 - val_loss: 2.5096e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.1324e-04 - acc: 0.0000e+00 - val_loss: 2.0262e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.0401e-04 - acc: 0.0000e+00 - val_loss: 3.0671e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.0098e-04 - acc: 0.0000e+00 - val_loss: 4.7762e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.1684e-04 - acc: 0.0000e+00 - val_loss: 1.8941e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13702/13702 [==============================] - 1s - loss: 1.0706e-04 - acc: 0.0000e+00 - val_loss: 3.4940e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.2781e-04 - acc: 0.0000e+00 - val_loss: 1.8850e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.0194e-04 - acc: 0.0000e+00 - val_loss: 1.9970e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.2364e-04 - acc: 0.0000e+00 - val_loss: 2.8180e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.0743e-04 - acc: 0.0000e+00 - val_loss: 1.7792e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "13702/13702 [==============================] - 1s - loss: 9.4082e-05 - acc: 0.0000e+00 - val_loss: 1.9092e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.0805e-04 - acc: 0.0000e+00 - val_loss: 1.7552e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "13702/13702 [==============================] - 1s - loss: 9.7711e-05 - acc: 0.0000e+00 - val_loss: 2.2564e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "13702/13702 [==============================] - 1s - loss: 9.8585e-05 - acc: 0.0000e+00 - val_loss: 1.8616e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.1931e-04 - acc: 0.0000e+00 - val_loss: 1.8008e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "13702/13702 [==============================] - 1s - loss: 9.9851e-05 - acc: 0.0000e+00 - val_loss: 1.7408e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.0531e-04 - acc: 0.0000e+00 - val_loss: 1.8432e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.0655e-04 - acc: 0.0000e+00 - val_loss: 3.1590e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.0102e-04 - acc: 0.0000e+00 - val_loss: 2.0471e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "13702/13702 [==============================] - 1s - loss: 9.4763e-05 - acc: 0.0000e+00 - val_loss: 1.6779e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "13702/13702 [==============================] - 1s - loss: 9.4119e-05 - acc: 0.0000e+00 - val_loss: 1.7765e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "13702/13702 [==============================] - 1s - loss: 9.6664e-05 - acc: 0.0000e+00 - val_loss: 2.2464e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "13702/13702 [==============================] - 1s - loss: 8.9921e-05 - acc: 0.0000e+00 - val_loss: 1.7101e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "13702/13702 [==============================] - 1s - loss: 8.3820e-05 - acc: 0.0000e+00 - val_loss: 2.1212e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "13702/13702 [==============================] - 1s - loss: 8.7753e-05 - acc: 0.0000e+00 - val_loss: 1.5561e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "13702/13702 [==============================] - 1s - loss: 8.1039e-05 - acc: 0.0000e+00 - val_loss: 2.8530e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "13702/13702 [==============================] - 1s - loss: 8.6943e-05 - acc: 0.0000e+00 - val_loss: 2.1737e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "13702/13702 [==============================] - 1s - loss: 9.0655e-05 - acc: 0.0000e+00 - val_loss: 1.8859e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "13702/13702 [==============================] - 1s - loss: 8.2950e-05 - acc: 0.0000e+00 - val_loss: 1.4745e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.0031e-04 - acc: 0.0000e+00 - val_loss: 4.0727e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "13702/13702 [==============================] - 1s - loss: 8.7670e-05 - acc: 0.0000e+00 - val_loss: 1.7582e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "13702/13702 [==============================] - 1s - loss: 8.5274e-05 - acc: 0.0000e+00 - val_loss: 3.6586e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.1647e-04 - acc: 0.0000e+00 - val_loss: 2.0324e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.1154e-04 - acc: 0.0000e+00 - val_loss: 1.9097e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "13702/13702 [==============================] - 1s - loss: 8.1990e-05 - acc: 0.0000e+00 - val_loss: 1.5139e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "13702/13702 [==============================] - 1s - loss: 7.9407e-05 - acc: 0.0000e+00 - val_loss: 1.4982e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "13702/13702 [==============================] - 1s - loss: 8.8360e-05 - acc: 0.0000e+00 - val_loss: 2.7859e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "13702/13702 [==============================] - 1s - loss: 9.9392e-05 - acc: 0.0000e+00 - val_loss: 1.3830e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "13702/13702 [==============================] - 1s - loss: 8.5109e-05 - acc: 0.0000e+00 - val_loss: 1.8507e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "13702/13702 [==============================] - 1s - loss: 7.9735e-05 - acc: 0.0000e+00 - val_loss: 1.3697e-04 - val_acc: 0.0000e+0000\n",
      "Epoch 65/100\n",
      "13702/13702 [==============================] - 1s - loss: 8.6296e-05 - acc: 0.0000e+00 - val_loss: 1.5770e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "13702/13702 [==============================] - 1s - loss: 8.0695e-05 - acc: 0.0000e+00 - val_loss: 1.3700e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "13702/13702 [==============================] - 1s - loss: 7.6389e-05 - acc: 0.0000e+00 - val_loss: 3.4893e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "13702/13702 [==============================] - 1s - loss: 8.2476e-05 - acc: 0.0000e+00 - val_loss: 5.0106e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "13702/13702 [==============================] - 1s - loss: 9.0194e-05 - acc: 0.0000e+00 - val_loss: 1.5320e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "13702/13702 [==============================] - 1s - loss: 7.5919e-05 - acc: 0.0000e+00 - val_loss: 1.3555e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "13702/13702 [==============================] - 1s - loss: 8.5843e-05 - acc: 0.0000e+00 - val_loss: 2.4102e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "13702/13702 [==============================] - 1s - loss: 9.3884e-05 - acc: 0.0000e+00 - val_loss: 1.9546e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "13702/13702 [==============================] - 1s - loss: 8.2290e-05 - acc: 0.0000e+00 - val_loss: 1.4807e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "13702/13702 [==============================] - 1s - loss: 7.5925e-05 - acc: 0.0000e+00 - val_loss: 1.7940e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "13702/13702 [==============================] - 1s - loss: 8.0279e-05 - acc: 0.0000e+00 - val_loss: 1.2596e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "13702/13702 [==============================] - 1s - loss: 8.1769e-05 - acc: 0.0000e+00 - val_loss: 1.2512e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "13702/13702 [==============================] - 1s - loss: 7.4212e-05 - acc: 0.0000e+00 - val_loss: 1.2629e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "13702/13702 [==============================] - 1s - loss: 7.7390e-05 - acc: 0.0000e+00 - val_loss: 3.4290e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "13702/13702 [==============================] - 1s - loss: 8.2783e-05 - acc: 0.0000e+00 - val_loss: 4.3815e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "13702/13702 [==============================] - 1s - loss: 8.0093e-05 - acc: 0.0000e+00 - val_loss: 1.2592e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "13702/13702 [==============================] - 1s - loss: 7.3900e-05 - acc: 0.0000e+00 - val_loss: 1.3849e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "13702/13702 [==============================] - 1s - loss: 7.2417e-05 - acc: 0.0000e+00 - val_loss: 1.4017e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "13702/13702 [==============================] - 1s - loss: 7.2069e-05 - acc: 0.0000e+00 - val_loss: 1.7169e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "13702/13702 [==============================] - 1s - loss: 7.2940e-05 - acc: 0.0000e+00 - val_loss: 1.1742e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "13702/13702 [==============================] - 1s - loss: 8.1765e-05 - acc: 0.0000e+00 - val_loss: 1.2945e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "13702/13702 [==============================] - 1s - loss: 6.6684e-05 - acc: 0.0000e+00 - val_loss: 1.1967e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "13702/13702 [==============================] - 1s - loss: 6.7971e-05 - acc: 0.0000e+00 - val_loss: 1.4357e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "13702/13702 [==============================] - 1s - loss: 7.7052e-05 - acc: 0.0000e+00 - val_loss: 2.5226e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "13702/13702 [==============================] - 1s - loss: 7.0868e-05 - acc: 0.0000e+00 - val_loss: 1.5820e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "13702/13702 [==============================] - 1s - loss: 7.2275e-05 - acc: 0.0000e+00 - val_loss: 1.1268e-04 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "13702/13702 [==============================] - 1s - loss: 8.9113e-05 - acc: 0.0000e+00 - val_loss: 5.6330e-04 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "13702/13702 [==============================] - 1s - loss: 8.9301e-05 - acc: 0.0000e+00 - val_loss: 2.4219e-04 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "13702/13702 [==============================] - 1s - loss: 6.8177e-05 - acc: 0.0000e+00 - val_loss: 1.1760e-04 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "13702/13702 [==============================] - 1s - loss: 7.6104e-05 - acc: 0.0000e+00 - val_loss: 1.7106e-04 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "13702/13702 [==============================] - 1s - loss: 7.0517e-05 - acc: 0.0000e+00 - val_loss: 1.3550e-04 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "13702/13702 [==============================] - 1s - loss: 6.3658e-05 - acc: 0.0000e+00 - val_loss: 1.7458e-04 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "13702/13702 [==============================] - 1s - loss: 7.0193e-05 - acc: 0.0000e+00 - val_loss: 1.0757e-04 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "13702/13702 [==============================] - 1s - loss: 6.5794e-05 - acc: 0.0000e+00 - val_loss: 1.1581e-04 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "13702/13702 [==============================] - 1s - loss: 6.3649e-05 - acc: 0.0000e+00 - val_loss: 1.9939e-04 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "13702/13702 [==============================] - 1s - loss: 7.0166e-05 - acc: 0.0000e+00 - val_loss: 1.4096e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00003 MSE (0.01 RMSE)\n",
      "Test Score: 0.00086 MSE (0.03 RMSE)\n"
     ]
    }
   ],
   "source": [
    "epochs_result = {}\n",
    "\n",
    "for epochs in epochslist:    \n",
    "    trainScore, testScore = quick_measure(stock_name, seq_len, d, shape, neurons, epochs)\n",
    "    epochs_result[epochs] = testScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzjWKJxLnnHON8v8B3ipJUWwioCcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2922df93a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lists = sorted(epochs_result.items())\n",
    "x,y = zip(*lists)\n",
    "plt.plot(x,y)\n",
    "plt.title('Finding the best hyperparameter')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Mean Square Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.3 Optimal number of neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 22, 32)            4736      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 22, 32)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 13,601\n",
      "Trainable params: 13,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13707 samples, validate on 1523 samples\n",
      "Epoch 1/90\n",
      "13707/13707 [==============================] - 2s - loss: 0.0286 - acc: 0.0000e+00 - val_loss: 0.0841 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "13707/13707 [==============================] - 1s - loss: 0.0045 - acc: 0.0000e+00 - val_loss: 9.8019e-04 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.1308e-04 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "13707/13707 [==============================] - 1s - loss: 4.5217e-04 - acc: 0.0000e+00 - val_loss: 6.0801e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "13707/13707 [==============================] - 1s - loss: 3.6125e-04 - acc: 0.0000e+00 - val_loss: 3.2174e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "13707/13707 [==============================] - 1s - loss: 3.4450e-04 - acc: 0.0000e+00 - val_loss: 3.1738e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "13707/13707 [==============================] - 1s - loss: 3.3887e-04 - acc: 0.0000e+00 - val_loss: 3.4616e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "13707/13707 [==============================] - 1s - loss: 3.3747e-04 - acc: 0.0000e+00 - val_loss: 3.0563e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "13707/13707 [==============================] - 1s - loss: 3.2240e-04 - acc: 0.0000e+00 - val_loss: 4.5232e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "13707/13707 [==============================] - 1s - loss: 3.1574e-04 - acc: 0.0000e+00 - val_loss: 3.1352e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "13707/13707 [==============================] - 1s - loss: 3.0739e-04 - acc: 0.0000e+00 - val_loss: 5.6274e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.9365e-04 - acc: 0.0000e+00 - val_loss: 2.5694e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.8381e-04 - acc: 0.0000e+00 - val_loss: 2.2885e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.7394e-04 - acc: 0.0000e+00 - val_loss: 2.4461e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.7457e-04 - acc: 0.0000e+00 - val_loss: 2.3578e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.6887e-04 - acc: 0.0000e+00 - val_loss: 2.2138e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.6127e-04 - acc: 0.0000e+00 - val_loss: 2.4881e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.7469e-04 - acc: 0.0000e+00 - val_loss: 2.6547e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.6144e-04 - acc: 0.0000e+00 - val_loss: 4.7081e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.7553e-04 - acc: 0.0000e+00 - val_loss: 2.4093e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.7055e-04 - acc: 0.0000e+00 - val_loss: 3.2517e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.3755e-04 - acc: 0.0000e+00 - val_loss: 2.0021e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.5404e-04 - acc: 0.0000e+00 - val_loss: 5.1493e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.3615e-04 - acc: 0.0000e+00 - val_loss: 2.1185e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.3941e-04 - acc: 0.0000e+00 - val_loss: 2.4835e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.4132e-04 - acc: 0.0000e+00 - val_loss: 3.2255e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.3250e-04 - acc: 0.0000e+00 - val_loss: 2.9311e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.3988e-04 - acc: 0.0000e+00 - val_loss: 3.2929e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.4467e-04 - acc: 0.0000e+00 - val_loss: 2.4528e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.2333e-04 - acc: 0.0000e+00 - val_loss: 2.7753e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.1993e-04 - acc: 0.0000e+00 - val_loss: 3.1895e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.2244e-04 - acc: 0.0000e+00 - val_loss: 1.9019e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.4162e-04 - acc: 0.0000e+00 - val_loss: 1.9278e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.2809e-04 - acc: 0.0000e+00 - val_loss: 2.6528e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.2006e-04 - acc: 0.0000e+00 - val_loss: 1.8928e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.0997e-04 - acc: 0.0000e+00 - val_loss: 1.8447e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.1408e-04 - acc: 0.0000e+00 - val_loss: 3.0332e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.0831e-04 - acc: 0.0000e+00 - val_loss: 1.7982e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.1007e-04 - acc: 0.0000e+00 - val_loss: 1.9491e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.9675e-04 - acc: 0.0000e+00 - val_loss: 1.9274e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.1145e-04 - acc: 0.0000e+00 - val_loss: 1.7986e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.0728e-04 - acc: 0.0000e+00 - val_loss: 1.9320e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.0651e-04 - acc: 0.0000e+00 - val_loss: 1.7766e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.0627e-04 - acc: 0.0000e+00 - val_loss: 1.7718e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.1044e-04 - acc: 0.0000e+00 - val_loss: 2.0235e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.8987e-04 - acc: 0.0000e+00 - val_loss: 1.7146e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.8103e-04 - acc: 0.0000e+00 - val_loss: 2.0828e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.9037e-04 - acc: 0.0000e+00 - val_loss: 2.2063e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.9263e-04 - acc: 0.0000e+00 - val_loss: 1.8588e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.8914e-04 - acc: 0.0000e+00 - val_loss: 2.5464e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.1299e-04 - acc: 0.0000e+00 - val_loss: 1.7413e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.7338e-04 - acc: 0.0000e+00 - val_loss: 1.8425e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.7103e-04 - acc: 0.0000e+00 - val_loss: 1.9687e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.7167e-04 - acc: 0.0000e+00 - val_loss: 1.9969e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.7282e-04 - acc: 0.0000e+00 - val_loss: 1.8351e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6896e-04 - acc: 0.0000e+00 - val_loss: 3.3851e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.8303e-04 - acc: 0.0000e+00 - val_loss: 2.1563e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5803e-04 - acc: 0.0000e+00 - val_loss: 1.7686e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6912e-04 - acc: 0.0000e+00 - val_loss: 1.6861e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6470e-04 - acc: 0.0000e+00 - val_loss: 1.8890e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6077e-04 - acc: 0.0000e+00 - val_loss: 1.8594e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6172e-04 - acc: 0.0000e+00 - val_loss: 1.6547e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6332e-04 - acc: 0.0000e+00 - val_loss: 1.7847e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5917e-04 - acc: 0.0000e+00 - val_loss: 2.1358e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5229e-04 - acc: 0.0000e+00 - val_loss: 1.7062e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5705e-04 - acc: 0.0000e+00 - val_loss: 1.7001e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4763e-04 - acc: 0.0000e+00 - val_loss: 1.6984e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5539e-04 - acc: 0.0000e+00 - val_loss: 2.2463e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4528e-04 - acc: 0.0000e+00 - val_loss: 1.7183e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4018e-04 - acc: 0.0000e+00 - val_loss: 2.2541e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4930e-04 - acc: 0.0000e+00 - val_loss: 2.1791e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4455e-04 - acc: 0.0000e+00 - val_loss: 1.7050e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4507e-04 - acc: 0.0000e+00 - val_loss: 1.6679e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3132e-04 - acc: 0.0000e+00 - val_loss: 2.0364e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4370e-04 - acc: 0.0000e+00 - val_loss: 1.8145e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3519e-04 - acc: 0.0000e+00 - val_loss: 3.7377e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4701e-04 - acc: 0.0000e+00 - val_loss: 4.1943e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3439e-04 - acc: 0.0000e+00 - val_loss: 2.0473e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2879e-04 - acc: 0.0000e+00 - val_loss: 1.7536e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2293e-04 - acc: 0.0000e+00 - val_loss: 1.7878e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2901e-04 - acc: 0.0000e+00 - val_loss: 3.0140e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3271e-04 - acc: 0.0000e+00 - val_loss: 3.2067e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2968e-04 - acc: 0.0000e+00 - val_loss: 2.1139e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1750e-04 - acc: 0.0000e+00 - val_loss: 1.8835e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2748e-04 - acc: 0.0000e+00 - val_loss: 1.9147e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2567e-04 - acc: 0.0000e+00 - val_loss: 2.1327e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2347e-04 - acc: 0.0000e+00 - val_loss: 1.7156e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1792e-04 - acc: 0.0000e+00 - val_loss: 1.8401e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1104e-04 - acc: 0.0000e+00 - val_loss: 1.7696e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1118e-04 - acc: 0.0000e+00 - val_loss: 2.2785e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00005 MSE (0.01 RMSE)\n",
      "Test Score: 0.00809 MSE (0.09 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 22, 32)            4736      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 22, 32)            0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 14,145\n",
      "Trainable params: 14,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13707 samples, validate on 1523 samples\n",
      "Epoch 1/90\n",
      "13707/13707 [==============================] - ETA: 0s - loss: 0.0239 - acc: 0.0000e+0 - 2s - loss: 0.0235 - acc: 0.0000e+00 - val_loss: 0.0137 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "13707/13707 [==============================] - 1s - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.6673e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "13707/13707 [==============================] - 1s - loss: 4.5537e-04 - acc: 0.0000e+00 - val_loss: 9.7508e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "13707/13707 [==============================] - 1s - loss: 4.0013e-04 - acc: 0.0000e+00 - val_loss: 5.1892e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "13707/13707 [==============================] - 1s - loss: 3.7835e-04 - acc: 0.0000e+00 - val_loss: 3.7573e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13707/13707 [==============================] - 1s - loss: 3.7209e-04 - acc: 0.0000e+00 - val_loss: 3.4938e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "13707/13707 [==============================] - 1s - loss: 3.3857e-04 - acc: 0.0000e+00 - val_loss: 2.8594e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "13707/13707 [==============================] - 1s - loss: 3.3065e-04 - acc: 0.0000e+00 - val_loss: 3.7322e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "13707/13707 [==============================] - 1s - loss: 3.1574e-04 - acc: 0.0000e+00 - val_loss: 2.4896e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "13707/13707 [==============================] - 1s - loss: 3.0677e-04 - acc: 0.0000e+00 - val_loss: 2.3476e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "13707/13707 [==============================] - 1s - loss: 3.1454e-04 - acc: 0.0000e+00 - val_loss: 2.1837e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "13707/13707 [==============================] - 1s - loss: 3.3050e-04 - acc: 0.0000e+00 - val_loss: 2.3540e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.7673e-04 - acc: 0.0000e+00 - val_loss: 4.4183e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.7449e-04 - acc: 0.0000e+00 - val_loss: 2.2809e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.6815e-04 - acc: 0.0000e+00 - val_loss: 2.3394e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.6183e-04 - acc: 0.0000e+00 - val_loss: 2.1246e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.6673e-04 - acc: 0.0000e+00 - val_loss: 2.5620e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.5763e-04 - acc: 0.0000e+00 - val_loss: 2.1607e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.4085e-04 - acc: 0.0000e+00 - val_loss: 7.3177e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.6710e-04 - acc: 0.0000e+00 - val_loss: 2.0957e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.2858e-04 - acc: 0.0000e+00 - val_loss: 5.0905e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.3903e-04 - acc: 0.0000e+00 - val_loss: 2.7810e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.3128e-04 - acc: 0.0000e+00 - val_loss: 2.5337e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.4047e-04 - acc: 0.0000e+00 - val_loss: 6.6178e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.3320e-04 - acc: 0.0000e+00 - val_loss: 5.3161e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.2623e-04 - acc: 0.0000e+00 - val_loss: 2.0268e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.1202e-04 - acc: 0.0000e+00 - val_loss: 2.0359e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.0972e-04 - acc: 0.0000e+00 - val_loss: 3.9546e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.2268e-04 - acc: 0.0000e+00 - val_loss: 2.0290e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.0346e-04 - acc: 0.0000e+00 - val_loss: 3.9124e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.0151e-04 - acc: 0.0000e+00 - val_loss: 2.2003e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.0388e-04 - acc: 0.0000e+00 - val_loss: 2.5419e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.9070e-04 - acc: 0.0000e+00 - val_loss: 2.0046e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.9934e-04 - acc: 0.0000e+00 - val_loss: 3.4510e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.0421e-04 - acc: 0.0000e+00 - val_loss: 1.8840e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.9383e-04 - acc: 0.0000e+00 - val_loss: 8.0139e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.8778e-04 - acc: 0.0000e+00 - val_loss: 2.0490e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.9604e-04 - acc: 0.0000e+00 - val_loss: 4.8461e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.8282e-04 - acc: 0.0000e+00 - val_loss: 2.4399e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.7226e-04 - acc: 0.0000e+00 - val_loss: 1.8196e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.7449e-04 - acc: 0.0000e+00 - val_loss: 2.6886e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6390e-04 - acc: 0.0000e+00 - val_loss: 4.3978e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6134e-04 - acc: 0.0000e+00 - val_loss: 2.6092e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6577e-04 - acc: 0.0000e+00 - val_loss: 1.8296e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6382e-04 - acc: 0.0000e+00 - val_loss: 3.2945e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5330e-04 - acc: 0.0000e+00 - val_loss: 1.8462e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5972e-04 - acc: 0.0000e+00 - val_loss: 6.4905e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5776e-04 - acc: 0.0000e+00 - val_loss: 2.0012e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4338e-04 - acc: 0.0000e+00 - val_loss: 2.0442e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4535e-04 - acc: 0.0000e+00 - val_loss: 5.0196e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2988e-04 - acc: 0.0000e+00 - val_loss: 1.8333e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4286e-04 - acc: 0.0000e+00 - val_loss: 4.0023e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2560e-04 - acc: 0.0000e+00 - val_loss: 2.8604e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2104e-04 - acc: 0.0000e+00 - val_loss: 3.8935e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2313e-04 - acc: 0.0000e+00 - val_loss: 1.8014e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2327e-04 - acc: 0.0000e+00 - val_loss: 3.4365e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1252e-04 - acc: 0.0000e+00 - val_loss: 3.4353e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1358e-04 - acc: 0.0000e+00 - val_loss: 3.6140e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1349e-04 - acc: 0.0000e+00 - val_loss: 3.4278e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0809e-04 - acc: 0.0000e+00 - val_loss: 3.7535e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.9576e-05 - acc: 0.0000e+00 - val_loss: 2.9398e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0462e-04 - acc: 0.0000e+00 - val_loss: 2.7304e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0765e-04 - acc: 0.0000e+00 - val_loss: 3.1029e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0486e-04 - acc: 0.0000e+00 - val_loss: 2.6433e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0384e-04 - acc: 0.0000e+00 - val_loss: 5.6881e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0465e-04 - acc: 0.0000e+00 - val_loss: 2.1451e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0251e-04 - acc: 0.0000e+00 - val_loss: 4.4722e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.5657e-05 - acc: 0.0000e+00 - val_loss: 2.9252e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0183e-04 - acc: 0.0000e+00 - val_loss: 4.3997e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.9849e-05 - acc: 0.0000e+00 - val_loss: 3.2019e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.2292e-05 - acc: 0.0000e+00 - val_loss: 2.3244e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.3430e-05 - acc: 0.0000e+00 - val_loss: 2.3518e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.3135e-05 - acc: 0.0000e+00 - val_loss: 2.5017e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.0136e-05 - acc: 0.0000e+00 - val_loss: 4.5469e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.9215e-05 - acc: 0.0000e+00 - val_loss: 2.8440e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.3321e-05 - acc: 0.0000e+00 - val_loss: 3.8150e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.9715e-05 - acc: 0.0000e+00 - val_loss: 6.2238e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.1365e-05 - acc: 0.0000e+00 - val_loss: 4.0256e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.8879e-05 - acc: 0.0000e+00 - val_loss: 7.0585e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.4942e-05 - acc: 0.0000e+00 - val_loss: 5.9327e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.9788e-05 - acc: 0.0000e+00 - val_loss: 5.4626e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.9706e-05 - acc: 0.0000e+00 - val_loss: 9.3332e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.3022e-05 - acc: 0.0000e+00 - val_loss: 8.0722e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.3190e-05 - acc: 0.0000e+00 - val_loss: 6.7787e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.1818e-05 - acc: 0.0000e+00 - val_loss: 6.8897e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.4998e-05 - acc: 0.0000e+00 - val_loss: 4.9481e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.7689e-05 - acc: 0.0000e+00 - val_loss: 4.0089e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.8570e-05 - acc: 0.0000e+00 - val_loss: 7.6558e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.4375e-05 - acc: 0.0000e+00 - val_loss: 5.0817e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00011 MSE (0.01 RMSE)\n",
      "Test Score: 0.00266 MSE (0.05 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 22, 32)            4736      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 22, 32)            0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 15,233\n",
      "Trainable params: 15,233\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13707 samples, validate on 1523 samples\n",
      "Epoch 1/90\n",
      "13707/13707 [==============================] - 2s - loss: 0.0211 - acc: 0.0000e+00 - val_loss: 0.0149 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "13707/13707 [==============================] - 1s - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 5.9589e-04 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "13707/13707 [==============================] - 1s - loss: 5.0133e-04 - acc: 0.0000e+00 - val_loss: 8.2404e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "13707/13707 [==============================] - 1s - loss: 4.0202e-04 - acc: 0.0000e+00 - val_loss: 6.6533e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "13707/13707 [==============================] - 1s - loss: 3.3818e-04 - acc: 0.0000e+00 - val_loss: 5.6144e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "13707/13707 [==============================] - 1s - loss: 3.3962e-04 - acc: 0.0000e+00 - val_loss: 3.2445e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.9927e-04 - acc: 0.0000e+00 - val_loss: 2.8042e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.8216e-04 - acc: 0.0000e+00 - val_loss: 2.5814e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.6754e-04 - acc: 0.0000e+00 - val_loss: 2.4850e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.6402e-04 - acc: 0.0000e+00 - val_loss: 2.4268e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.5773e-04 - acc: 0.0000e+00 - val_loss: 4.0016e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.4322e-04 - acc: 0.0000e+00 - val_loss: 2.3327e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.4410e-04 - acc: 0.0000e+00 - val_loss: 2.2570e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.4345e-04 - acc: 0.0000e+00 - val_loss: 2.5484e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.3237e-04 - acc: 0.0000e+00 - val_loss: 5.3237e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.2947e-04 - acc: 0.0000e+00 - val_loss: 2.6386e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.1937e-04 - acc: 0.0000e+00 - val_loss: 3.1218e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.2115e-04 - acc: 0.0000e+00 - val_loss: 2.3339e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.1661e-04 - acc: 0.0000e+00 - val_loss: 4.5529e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.0738e-04 - acc: 0.0000e+00 - val_loss: 2.5439e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13707/13707 [==============================] - 1s - loss: 2.0121e-04 - acc: 0.0000e+00 - val_loss: 3.5531e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.9814e-04 - acc: 0.0000e+00 - val_loss: 6.5135e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.9455e-04 - acc: 0.0000e+00 - val_loss: 2.9765e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.8654e-04 - acc: 0.0000e+00 - val_loss: 7.0856e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.8610e-04 - acc: 0.0000e+00 - val_loss: 7.8086e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.7281e-04 - acc: 0.0000e+00 - val_loss: 3.5580e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6975e-04 - acc: 0.0000e+00 - val_loss: 4.4894e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.8793e-04 - acc: 0.0000e+00 - val_loss: 2.3526e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6958e-04 - acc: 0.0000e+00 - val_loss: 6.5960e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5209e-04 - acc: 0.0000e+00 - val_loss: 2.7544e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6878e-04 - acc: 0.0000e+00 - val_loss: 8.1988e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5693e-04 - acc: 0.0000e+00 - val_loss: 3.3091e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4335e-04 - acc: 0.0000e+00 - val_loss: 5.0719e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4194e-04 - acc: 0.0000e+00 - val_loss: 6.1710e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4598e-04 - acc: 0.0000e+00 - val_loss: 6.7880e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4778e-04 - acc: 0.0000e+00 - val_loss: 8.6340e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4149e-04 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3593e-04 - acc: 0.0000e+00 - val_loss: 7.0729e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1836e-04 - acc: 0.0000e+00 - val_loss: 5.0911e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2053e-04 - acc: 0.0000e+00 - val_loss: 8.4274e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2624e-04 - acc: 0.0000e+00 - val_loss: 5.4251e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1889e-04 - acc: 0.0000e+00 - val_loss: 9.6545e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0966e-04 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1389e-04 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0837e-04 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0395e-04 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0222e-04 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0680e-04 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.7726e-05 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.1378e-05 - acc: 0.0000e+00 - val_loss: 7.8944e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0154e-04 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.1396e-05 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.2052e-05 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.6839e-05 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.5298e-05 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0312e-04 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.3334e-05 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.8709e-05 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.0145e-05 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.6999e-05 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.6172e-05 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.8825e-05 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.7180e-05 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.5055e-05 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.1416e-05 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.7308e-05 - acc: 0.0000e+00 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.2139e-05 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.9727e-05 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.0371e-05 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.2991e-05 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.1147e-05 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.8318e-05 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.4916e-05 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.1955e-05 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.1073e-05 - acc: 0.0000e+00 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.9245e-05 - acc: 0.0000e+00 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.4233e-05 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.8574e-05 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.2959e-05 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.6269e-05 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.7170e-05 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.6238e-05 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.8216e-05 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.1329e-05 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "13707/13707 [==============================] - 1s - loss: 5.6402e-05 - acc: 0.0000e+00 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.1755e-05 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.4283e-05 - acc: 0.0000e+00 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.5990e-05 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "13707/13707 [==============================] - 1s - loss: 5.7552e-05 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.2102e-05 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00033 MSE (0.02 RMSE)\n",
      "Test Score: 0.01148 MSE (0.11 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 22, 64)            17664     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 22, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 51,745\n",
      "Trainable params: 51,745\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13707 samples, validate on 1523 samples\n",
      "Epoch 1/90\n",
      "13707/13707 [==============================] - 2s - loss: 0.0226 - acc: 0.0000e+00 - val_loss: 0.0183 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "13707/13707 [==============================] - 1s - loss: 0.0011 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "13707/13707 [==============================] - 1s - loss: 3.6470e-04 - acc: 0.0000e+00 - val_loss: 6.2854e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.3806e-04 - acc: 0.0000e+00 - val_loss: 3.3297e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.2258e-04 - acc: 0.0000e+00 - val_loss: 3.1455e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.1450e-04 - acc: 0.0000e+00 - val_loss: 2.6590e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.1916e-04 - acc: 0.0000e+00 - val_loss: 3.8236e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.9080e-04 - acc: 0.0000e+00 - val_loss: 2.5676e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.8886e-04 - acc: 0.0000e+00 - val_loss: 3.4520e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.8814e-04 - acc: 0.0000e+00 - val_loss: 3.1629e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.9755e-04 - acc: 0.0000e+00 - val_loss: 2.4818e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.8762e-04 - acc: 0.0000e+00 - val_loss: 2.4071e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.8490e-04 - acc: 0.0000e+00 - val_loss: 2.3425e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.9992e-04 - acc: 0.0000e+00 - val_loss: 4.4923e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.7197e-04 - acc: 0.0000e+00 - val_loss: 2.6967e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.7359e-04 - acc: 0.0000e+00 - val_loss: 4.3604e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.8068e-04 - acc: 0.0000e+00 - val_loss: 2.1058e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6487e-04 - acc: 0.0000e+00 - val_loss: 2.1788e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.7661e-04 - acc: 0.0000e+00 - val_loss: 2.2932e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6782e-04 - acc: 0.0000e+00 - val_loss: 2.7017e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6598e-04 - acc: 0.0000e+00 - val_loss: 2.1216e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5660e-04 - acc: 0.0000e+00 - val_loss: 2.4616e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6272e-04 - acc: 0.0000e+00 - val_loss: 1.9881e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4802e-04 - acc: 0.0000e+00 - val_loss: 2.4627e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6218e-04 - acc: 0.0000e+00 - val_loss: 2.4333e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5858e-04 - acc: 0.0000e+00 - val_loss: 2.3508e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5488e-04 - acc: 0.0000e+00 - val_loss: 2.4143e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5595e-04 - acc: 0.0000e+00 - val_loss: 2.6521e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6891e-04 - acc: 0.0000e+00 - val_loss: 1.9908e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3846e-04 - acc: 0.0000e+00 - val_loss: 1.8755e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4574e-04 - acc: 0.0000e+00 - val_loss: 1.8321e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4663e-04 - acc: 0.0000e+00 - val_loss: 2.3112e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3985e-04 - acc: 0.0000e+00 - val_loss: 1.9247e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.7216e-04 - acc: 0.0000e+00 - val_loss: 2.8092e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4310e-04 - acc: 0.0000e+00 - val_loss: 1.9515e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13707/13707 [==============================] - 1s - loss: 1.3955e-04 - acc: 0.0000e+00 - val_loss: 2.7510e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4510e-04 - acc: 0.0000e+00 - val_loss: 2.8844e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4596e-04 - acc: 0.0000e+00 - val_loss: 2.4819e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5197e-04 - acc: 0.0000e+00 - val_loss: 2.4457e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4812e-04 - acc: 0.0000e+00 - val_loss: 2.3604e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3879e-04 - acc: 0.0000e+00 - val_loss: 1.7850e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3658e-04 - acc: 0.0000e+00 - val_loss: 2.0768e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3741e-04 - acc: 0.0000e+00 - val_loss: 2.9593e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5629e-04 - acc: 0.0000e+00 - val_loss: 2.2557e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5754e-04 - acc: 0.0000e+00 - val_loss: 1.9944e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2757e-04 - acc: 0.0000e+00 - val_loss: 2.2804e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3443e-04 - acc: 0.0000e+00 - val_loss: 1.8129e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4145e-04 - acc: 0.0000e+00 - val_loss: 1.7648e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3789e-04 - acc: 0.0000e+00 - val_loss: 3.0929e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4322e-04 - acc: 0.0000e+00 - val_loss: 5.8995e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3296e-04 - acc: 0.0000e+00 - val_loss: 1.7357e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2907e-04 - acc: 0.0000e+00 - val_loss: 1.9288e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2637e-04 - acc: 0.0000e+00 - val_loss: 2.2969e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3505e-04 - acc: 0.0000e+00 - val_loss: 1.7779e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2286e-04 - acc: 0.0000e+00 - val_loss: 1.9032e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3533e-04 - acc: 0.0000e+00 - val_loss: 3.6319e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3468e-04 - acc: 0.0000e+00 - val_loss: 3.9971e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2715e-04 - acc: 0.0000e+00 - val_loss: 3.1400e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4353e-04 - acc: 0.0000e+00 - val_loss: 3.3600e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2772e-04 - acc: 0.0000e+00 - val_loss: 2.1673e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3437e-04 - acc: 0.0000e+00 - val_loss: 3.5086e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3030e-04 - acc: 0.0000e+00 - val_loss: 1.7212e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2405e-04 - acc: 0.0000e+00 - val_loss: 1.8532e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2132e-04 - acc: 0.0000e+00 - val_loss: 1.5348e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1552e-04 - acc: 0.0000e+00 - val_loss: 1.6766e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1451e-04 - acc: 0.0000e+00 - val_loss: 1.7817e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1936e-04 - acc: 0.0000e+00 - val_loss: 1.7408e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2370e-04 - acc: 0.0000e+00 - val_loss: 1.5738e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1756e-04 - acc: 0.0000e+00 - val_loss: 1.7293e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2459e-04 - acc: 0.0000e+00 - val_loss: 3.7088e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2877e-04 - acc: 0.0000e+00 - val_loss: 3.3771e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1495e-04 - acc: 0.0000e+00 - val_loss: 3.1040e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1601e-04 - acc: 0.0000e+00 - val_loss: 1.8384e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1692e-04 - acc: 0.0000e+00 - val_loss: 1.8424e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0721e-04 - acc: 0.0000e+00 - val_loss: 1.9633e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1054e-04 - acc: 0.0000e+00 - val_loss: 2.3135e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0588e-04 - acc: 0.0000e+00 - val_loss: 1.8488e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0353e-04 - acc: 0.0000e+00 - val_loss: 2.2807e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0941e-04 - acc: 0.0000e+00 - val_loss: 1.5074e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1118e-04 - acc: 0.0000e+00 - val_loss: 1.5970e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0155e-04 - acc: 0.0000e+00 - val_loss: 1.4412e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.4178e-05 - acc: 0.0000e+00 - val_loss: 1.4362e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0368e-04 - acc: 0.0000e+00 - val_loss: 1.4380e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.4621e-05 - acc: 0.0000e+00 - val_loss: 3.2962e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.7291e-05 - acc: 0.0000e+00 - val_loss: 3.5430e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1066e-04 - acc: 0.0000e+00 - val_loss: 1.5532e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.2600e-05 - acc: 0.0000e+00 - val_loss: 1.7726e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.9959e-05 - acc: 0.0000e+00 - val_loss: 1.9204e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.4024e-05 - acc: 0.0000e+00 - val_loss: 1.4287e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.3301e-05 - acc: 0.0000e+00 - val_loss: 1.3879e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00003 MSE (0.01 RMSE)\n",
      "Test Score: 0.00177 MSE (0.04 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 22, 64)            17664     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 22, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 52,801\n",
      "Trainable params: 52,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13707 samples, validate on 1523 samples\n",
      "Epoch 1/90\n",
      "13707/13707 [==============================] - 3s - loss: 0.0187 - acc: 0.0000e+00 - val_loss: 0.0053 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.0165e-04 - acc: 0.0000e+00 - val_loss: 8.2970e-04 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "13707/13707 [==============================] - 1s - loss: 3.7721e-04 - acc: 0.0000e+00 - val_loss: 7.6723e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.8068e-04 - acc: 0.0000e+00 - val_loss: 7.3129e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.3887e-04 - acc: 0.0000e+00 - val_loss: 2.6333e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.9935e-04 - acc: 0.0000e+00 - val_loss: 2.4566e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.0403e-04 - acc: 0.0000e+00 - val_loss: 3.4284e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.8217e-04 - acc: 0.0000e+00 - val_loss: 3.3037e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.9463e-04 - acc: 0.0000e+00 - val_loss: 2.3828e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.8308e-04 - acc: 0.0000e+00 - val_loss: 3.0253e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.8285e-04 - acc: 0.0000e+00 - val_loss: 2.8349e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.8349e-04 - acc: 0.0000e+00 - val_loss: 4.1486e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6737e-04 - acc: 0.0000e+00 - val_loss: 3.7957e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.7332e-04 - acc: 0.0000e+00 - val_loss: 2.8277e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6216e-04 - acc: 0.0000e+00 - val_loss: 2.3721e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.7225e-04 - acc: 0.0000e+00 - val_loss: 2.7439e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6864e-04 - acc: 0.0000e+00 - val_loss: 2.0275e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6925e-04 - acc: 0.0000e+00 - val_loss: 4.0249e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6630e-04 - acc: 0.0000e+00 - val_loss: 2.1992e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.7049e-04 - acc: 0.0000e+00 - val_loss: 2.4559e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6008e-04 - acc: 0.0000e+00 - val_loss: 3.3924e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5873e-04 - acc: 0.0000e+00 - val_loss: 1.9231e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5198e-04 - acc: 0.0000e+00 - val_loss: 3.9207e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6206e-04 - acc: 0.0000e+00 - val_loss: 1.8952e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5761e-04 - acc: 0.0000e+00 - val_loss: 1.9089e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4740e-04 - acc: 0.0000e+00 - val_loss: 2.1694e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4532e-04 - acc: 0.0000e+00 - val_loss: 2.1952e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4907e-04 - acc: 0.0000e+00 - val_loss: 3.6601e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5727e-04 - acc: 0.0000e+00 - val_loss: 1.7864e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6226e-04 - acc: 0.0000e+00 - val_loss: 4.0328e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4268e-04 - acc: 0.0000e+00 - val_loss: 4.0546e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3835e-04 - acc: 0.0000e+00 - val_loss: 2.0555e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4690e-04 - acc: 0.0000e+00 - val_loss: 1.7280e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3294e-04 - acc: 0.0000e+00 - val_loss: 1.7233e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5111e-04 - acc: 0.0000e+00 - val_loss: 3.2609e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4745e-04 - acc: 0.0000e+00 - val_loss: 4.2219e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4084e-04 - acc: 0.0000e+00 - val_loss: 2.0300e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3696e-04 - acc: 0.0000e+00 - val_loss: 1.7031e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3157e-04 - acc: 0.0000e+00 - val_loss: 1.9916e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3233e-04 - acc: 0.0000e+00 - val_loss: 2.1978e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3340e-04 - acc: 0.0000e+00 - val_loss: 2.3406e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3796e-04 - acc: 0.0000e+00 - val_loss: 3.0887e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4475e-04 - acc: 0.0000e+00 - val_loss: 2.6176e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3613e-04 - acc: 0.0000e+00 - val_loss: 3.5597e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3672e-04 - acc: 0.0000e+00 - val_loss: 3.5454e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2905e-04 - acc: 0.0000e+00 - val_loss: 1.7676e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4060e-04 - acc: 0.0000e+00 - val_loss: 1.6176e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3328e-04 - acc: 0.0000e+00 - val_loss: 4.9908e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1766e-04 - acc: 0.0000e+00 - val_loss: 1.6788e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1982e-04 - acc: 0.0000e+00 - val_loss: 2.2569e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0611e-04 - acc: 0.0000e+00 - val_loss: 2.4419e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0941e-04 - acc: 0.0000e+00 - val_loss: 2.2179e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1105e-04 - acc: 0.0000e+00 - val_loss: 1.5933e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1352e-04 - acc: 0.0000e+00 - val_loss: 4.8780e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1338e-04 - acc: 0.0000e+00 - val_loss: 2.2228e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1819e-04 - acc: 0.0000e+00 - val_loss: 6.5505e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1412e-04 - acc: 0.0000e+00 - val_loss: 3.1636e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0838e-04 - acc: 0.0000e+00 - val_loss: 1.6188e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0664e-04 - acc: 0.0000e+00 - val_loss: 2.4612e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0956e-04 - acc: 0.0000e+00 - val_loss: 1.8218e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0582e-04 - acc: 0.0000e+00 - val_loss: 1.7021e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0480e-04 - acc: 0.0000e+00 - val_loss: 1.4567e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0443e-04 - acc: 0.0000e+00 - val_loss: 2.3643e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0482e-04 - acc: 0.0000e+00 - val_loss: 2.0244e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.5602e-05 - acc: 0.0000e+00 - val_loss: 1.7169e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.7371e-05 - acc: 0.0000e+00 - val_loss: 1.4162e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0320e-04 - acc: 0.0000e+00 - val_loss: 1.4840e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.6087e-05 - acc: 0.0000e+00 - val_loss: 3.9798e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.2435e-05 - acc: 0.0000e+00 - val_loss: 1.5709e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.5935e-05 - acc: 0.0000e+00 - val_loss: 2.3722e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1369e-04 - acc: 0.0000e+00 - val_loss: 6.1083e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.8962e-05 - acc: 0.0000e+00 - val_loss: 4.6924e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.6212e-05 - acc: 0.0000e+00 - val_loss: 2.6261e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.4726e-05 - acc: 0.0000e+00 - val_loss: 1.4454e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.2757e-05 - acc: 0.0000e+00 - val_loss: 1.4044e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.3207e-05 - acc: 0.0000e+00 - val_loss: 4.2748e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.5406e-05 - acc: 0.0000e+00 - val_loss: 1.4677e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.3313e-05 - acc: 0.0000e+00 - val_loss: 1.4022e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.7492e-05 - acc: 0.0000e+00 - val_loss: 3.0055e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.9549e-05 - acc: 0.0000e+00 - val_loss: 1.4027e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.7814e-05 - acc: 0.0000e+00 - val_loss: 1.5432e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.8402e-05 - acc: 0.0000e+00 - val_loss: 1.5542e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.4894e-05 - acc: 0.0000e+00 - val_loss: 3.0311e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.7918e-05 - acc: 0.0000e+00 - val_loss: 1.7926e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.6159e-05 - acc: 0.0000e+00 - val_loss: 1.4333e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.6418e-05 - acc: 0.0000e+00 - val_loss: 1.5161e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.5919e-05 - acc: 0.0000e+00 - val_loss: 1.7120e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.5666e-05 - acc: 0.0000e+00 - val_loss: 1.6153e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.4419e-05 - acc: 0.0000e+00 - val_loss: 1.3607e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.3003e-05 - acc: 0.0000e+00 - val_loss: 1.6121e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00004 MSE (0.01 RMSE)\n",
      "Test Score: 0.00138 MSE (0.04 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_11 (LSTM)               (None, 22, 64)            17664     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 22, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 54,913\n",
      "Trainable params: 54,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13707 samples, validate on 1523 samples\n",
      "Epoch 1/90\n",
      "13707/13707 [==============================] - 3s - loss: 0.0141 - acc: 0.0000e+00 - val_loss: 7.6493e-04 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.1870e-04 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "13707/13707 [==============================] - 1s - loss: 3.2406e-04 - acc: 0.0000e+00 - val_loss: 8.7555e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.5841e-04 - acc: 0.0000e+00 - val_loss: 4.5806e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.3539e-04 - acc: 0.0000e+00 - val_loss: 3.8046e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.1862e-04 - acc: 0.0000e+00 - val_loss: 2.8976e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.0569e-04 - acc: 0.0000e+00 - val_loss: 2.7522e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.8941e-04 - acc: 0.0000e+00 - val_loss: 2.5996e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.8259e-04 - acc: 0.0000e+00 - val_loss: 2.8500e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.7568e-04 - acc: 0.0000e+00 - val_loss: 2.4485e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.7467e-04 - acc: 0.0000e+00 - val_loss: 2.2767e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6192e-04 - acc: 0.0000e+00 - val_loss: 2.2818e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.7912e-04 - acc: 0.0000e+00 - val_loss: 3.0594e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.7072e-04 - acc: 0.0000e+00 - val_loss: 3.2454e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13707/13707 [==============================] - 1s - loss: 1.5923e-04 - acc: 0.0000e+00 - val_loss: 2.2892e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5762e-04 - acc: 0.0000e+00 - val_loss: 2.4994e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5353e-04 - acc: 0.0000e+00 - val_loss: 5.3604e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5253e-04 - acc: 0.0000e+00 - val_loss: 2.1351e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4118e-04 - acc: 0.0000e+00 - val_loss: 2.1671e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4606e-04 - acc: 0.0000e+00 - val_loss: 2.3224e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4970e-04 - acc: 0.0000e+00 - val_loss: 2.0434e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4506e-04 - acc: 0.0000e+00 - val_loss: 3.2599e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4201e-04 - acc: 0.0000e+00 - val_loss: 2.0185e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3931e-04 - acc: 0.0000e+00 - val_loss: 2.2374e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4450e-04 - acc: 0.0000e+00 - val_loss: 2.5359e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3178e-04 - acc: 0.0000e+00 - val_loss: 1.9632e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3041e-04 - acc: 0.0000e+00 - val_loss: 1.9674e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2723e-04 - acc: 0.0000e+00 - val_loss: 2.2081e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3133e-04 - acc: 0.0000e+00 - val_loss: 3.2289e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3373e-04 - acc: 0.0000e+00 - val_loss: 2.2305e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2955e-04 - acc: 0.0000e+00 - val_loss: 1.9149e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2329e-04 - acc: 0.0000e+00 - val_loss: 2.8650e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4788e-04 - acc: 0.0000e+00 - val_loss: 2.1054e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3056e-04 - acc: 0.0000e+00 - val_loss: 2.0794e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1670e-04 - acc: 0.0000e+00 - val_loss: 2.1426e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2510e-04 - acc: 0.0000e+00 - val_loss: 2.3832e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3198e-04 - acc: 0.0000e+00 - val_loss: 2.6084e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2277e-04 - acc: 0.0000e+00 - val_loss: 1.7984e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1547e-04 - acc: 0.0000e+00 - val_loss: 1.9252e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1456e-04 - acc: 0.0000e+00 - val_loss: 2.1058e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0897e-04 - acc: 0.0000e+00 - val_loss: 1.9886e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1372e-04 - acc: 0.0000e+00 - val_loss: 3.1545e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2244e-04 - acc: 0.0000e+00 - val_loss: 1.8304e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0779e-04 - acc: 0.0000e+00 - val_loss: 1.8690e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0383e-04 - acc: 0.0000e+00 - val_loss: 1.7989e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0365e-04 - acc: 0.0000e+00 - val_loss: 1.7738e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.9621e-05 - acc: 0.0000e+00 - val_loss: 2.4415e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1287e-04 - acc: 0.0000e+00 - val_loss: 1.7203e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0126e-04 - acc: 0.0000e+00 - val_loss: 1.8039e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.4142e-05 - acc: 0.0000e+00 - val_loss: 1.6777e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0252e-04 - acc: 0.0000e+00 - val_loss: 1.6583e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.6325e-05 - acc: 0.0000e+00 - val_loss: 1.9728e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0733e-04 - acc: 0.0000e+00 - val_loss: 1.8468e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.1328e-05 - acc: 0.0000e+00 - val_loss: 1.6565e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0119e-04 - acc: 0.0000e+00 - val_loss: 2.8045e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.4479e-05 - acc: 0.0000e+00 - val_loss: 1.6905e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.6434e-05 - acc: 0.0000e+00 - val_loss: 2.1274e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.5829e-05 - acc: 0.0000e+00 - val_loss: 3.5569e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.8612e-05 - acc: 0.0000e+00 - val_loss: 1.6402e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.7552e-05 - acc: 0.0000e+00 - val_loss: 3.3322e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.9838e-05 - acc: 0.0000e+00 - val_loss: 2.6305e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.7704e-05 - acc: 0.0000e+00 - val_loss: 1.7996e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.2530e-05 - acc: 0.0000e+00 - val_loss: 1.9366e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.8412e-05 - acc: 0.0000e+00 - val_loss: 2.1357e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.9956e-05 - acc: 0.0000e+00 - val_loss: 3.8152e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.1437e-05 - acc: 0.0000e+00 - val_loss: 1.6025e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.6889e-05 - acc: 0.0000e+00 - val_loss: 1.8163e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.8690e-05 - acc: 0.0000e+00 - val_loss: 1.5278e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.9613e-05 - acc: 0.0000e+00 - val_loss: 2.7162e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.5427e-05 - acc: 0.0000e+00 - val_loss: 1.8852e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.2462e-05 - acc: 0.0000e+00 - val_loss: 1.6141e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.8553e-05 - acc: 0.0000e+00 - val_loss: 1.4941e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.7627e-05 - acc: 0.0000e+00 - val_loss: 2.2867e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.4349e-05 - acc: 0.0000e+00 - val_loss: 3.2484e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.5879e-05 - acc: 0.0000e+00 - val_loss: 2.2411e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.6685e-05 - acc: 0.0000e+00 - val_loss: 3.4162e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.3943e-05 - acc: 0.0000e+00 - val_loss: 1.4585e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.2147e-05 - acc: 0.0000e+00 - val_loss: 3.3074e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.3522e-05 - acc: 0.0000e+00 - val_loss: 1.6361e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.3981e-05 - acc: 0.0000e+00 - val_loss: 2.8698e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.9285e-05 - acc: 0.0000e+00 - val_loss: 2.5161e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.6671e-05 - acc: 0.0000e+00 - val_loss: 3.2597e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.2722e-05 - acc: 0.0000e+00 - val_loss: 1.4449e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.8358e-05 - acc: 0.0000e+00 - val_loss: 1.6838e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.8868e-05 - acc: 0.0000e+00 - val_loss: 2.6274e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.7294e-05 - acc: 0.0000e+00 - val_loss: 1.5343e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.9974e-05 - acc: 0.0000e+00 - val_loss: 1.4106e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.0446e-05 - acc: 0.0000e+00 - val_loss: 1.5149e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.7856e-05 - acc: 0.0000e+00 - val_loss: 2.3106e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.3477e-05 - acc: 0.0000e+00 - val_loss: 1.4003e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00003 MSE (0.01 RMSE)\n",
      "Test Score: 0.00038 MSE (0.02 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_13 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 201,761\n",
      "Trainable params: 201,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13707 samples, validate on 1523 samples\n",
      "Epoch 1/90\n",
      "13707/13707 [==============================] - 3s - loss: 0.0164 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.0135e-04 - acc: 0.0000e+00 - val_loss: 7.9778e-04 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.2988e-04 - acc: 0.0000e+00 - val_loss: 4.0974e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5909e-04 - acc: 0.0000e+00 - val_loss: 2.7059e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6150e-04 - acc: 0.0000e+00 - val_loss: 2.8499e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4205e-04 - acc: 0.0000e+00 - val_loss: 2.7307e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3622e-04 - acc: 0.0000e+00 - val_loss: 2.6169e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3439e-04 - acc: 0.0000e+00 - val_loss: 3.6463e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3161e-04 - acc: 0.0000e+00 - val_loss: 3.2192e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2638e-04 - acc: 0.0000e+00 - val_loss: 2.4598e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3444e-04 - acc: 0.0000e+00 - val_loss: 2.5040e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5538e-04 - acc: 0.0000e+00 - val_loss: 2.6858e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2431e-04 - acc: 0.0000e+00 - val_loss: 2.9642e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2674e-04 - acc: 0.0000e+00 - val_loss: 2.2718e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2662e-04 - acc: 0.0000e+00 - val_loss: 2.3571e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1523e-04 - acc: 0.0000e+00 - val_loss: 3.5211e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1906e-04 - acc: 0.0000e+00 - val_loss: 2.3659e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1073e-04 - acc: 0.0000e+00 - val_loss: 2.4160e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3022e-04 - acc: 0.0000e+00 - val_loss: 5.2010e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1976e-04 - acc: 0.0000e+00 - val_loss: 2.2919e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2578e-04 - acc: 0.0000e+00 - val_loss: 1.9875e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1479e-04 - acc: 0.0000e+00 - val_loss: 5.4671e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2771e-04 - acc: 0.0000e+00 - val_loss: 2.2813e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1064e-04 - acc: 0.0000e+00 - val_loss: 2.1403e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1562e-04 - acc: 0.0000e+00 - val_loss: 4.6397e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1513e-04 - acc: 0.0000e+00 - val_loss: 2.0225e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1052e-04 - acc: 0.0000e+00 - val_loss: 2.1024e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2012e-04 - acc: 0.0000e+00 - val_loss: 3.0166e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13707/13707 [==============================] - 1s - loss: 1.3098e-04 - acc: 0.0000e+00 - val_loss: 2.8126e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0054e-04 - acc: 0.0000e+00 - val_loss: 1.8434e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0663e-04 - acc: 0.0000e+00 - val_loss: 1.9666e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0971e-04 - acc: 0.0000e+00 - val_loss: 4.8166e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0433e-04 - acc: 0.0000e+00 - val_loss: 1.7781e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0173e-04 - acc: 0.0000e+00 - val_loss: 1.7939e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0078e-04 - acc: 0.0000e+00 - val_loss: 3.4770e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0440e-04 - acc: 0.0000e+00 - val_loss: 1.7856e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.9727e-05 - acc: 0.0000e+00 - val_loss: 2.0045e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.8596e-05 - acc: 0.0000e+00 - val_loss: 2.6811e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.3717e-05 - acc: 0.0000e+00 - val_loss: 1.8528e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.5726e-05 - acc: 0.0000e+00 - val_loss: 1.7148e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.3957e-05 - acc: 0.0000e+00 - val_loss: 1.9260e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.9433e-05 - acc: 0.0000e+00 - val_loss: 2.8541e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1211e-04 - acc: 0.0000e+00 - val_loss: 1.7728e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.8419e-05 - acc: 0.0000e+00 - val_loss: 1.8370e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.9244e-05 - acc: 0.0000e+00 - val_loss: 1.6803e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.8887e-05 - acc: 0.0000e+00 - val_loss: 2.5497e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0554e-04 - acc: 0.0000e+00 - val_loss: 8.6904e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0222e-04 - acc: 0.0000e+00 - val_loss: 1.5651e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.9952e-05 - acc: 0.0000e+00 - val_loss: 2.0667e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.9617e-05 - acc: 0.0000e+00 - val_loss: 3.3641e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0052e-04 - acc: 0.0000e+00 - val_loss: 3.1608e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.7289e-05 - acc: 0.0000e+00 - val_loss: 2.0358e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.9652e-05 - acc: 0.0000e+00 - val_loss: 3.1544e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.7613e-05 - acc: 0.0000e+00 - val_loss: 1.7070e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.0939e-05 - acc: 0.0000e+00 - val_loss: 1.4660e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.8302e-05 - acc: 0.0000e+00 - val_loss: 1.4959e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.2394e-05 - acc: 0.0000e+00 - val_loss: 2.2587e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.5878e-05 - acc: 0.0000e+00 - val_loss: 1.4417e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.0366e-05 - acc: 0.0000e+00 - val_loss: 1.3990e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.9234e-05 - acc: 0.0000e+00 - val_loss: 5.4526e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0924e-04 - acc: 0.0000e+00 - val_loss: 1.6160e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.3049e-05 - acc: 0.0000e+00 - val_loss: 1.5958e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.7156e-05 - acc: 0.0000e+00 - val_loss: 1.4954e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.4683e-05 - acc: 0.0000e+00 - val_loss: 1.3376e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.5895e-05 - acc: 0.0000e+00 - val_loss: 1.3590e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.2361e-05 - acc: 0.0000e+00 - val_loss: 3.2972e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.3841e-05 - acc: 0.0000e+00 - val_loss: 1.5102e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.6869e-05 - acc: 0.0000e+00 - val_loss: 1.3101e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.9675e-05 - acc: 0.0000e+00 - val_loss: 2.9063e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.3225e-05 - acc: 0.0000e+00 - val_loss: 1.6304e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.9093e-05 - acc: 0.0000e+00 - val_loss: 1.5105e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.5507e-05 - acc: 0.0000e+00 - val_loss: 1.2687e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.8855e-05 - acc: 0.0000e+00 - val_loss: 1.4716e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.5875e-05 - acc: 0.0000e+00 - val_loss: 1.2970e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.9661e-05 - acc: 0.0000e+00 - val_loss: 2.9140e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.0714e-05 - acc: 0.0000e+00 - val_loss: 1.5282e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.8692e-05 - acc: 0.0000e+00 - val_loss: 3.0283e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.7298e-05 - acc: 0.0000e+00 - val_loss: 1.2766e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.7579e-05 - acc: 0.0000e+00 - val_loss: 1.2711e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.8256e-05 - acc: 0.0000e+00 - val_loss: 1.3092e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.2849e-05 - acc: 0.0000e+00 - val_loss: 1.2915e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.0962e-05 - acc: 0.0000e+00 - val_loss: 1.8090e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.0272e-05 - acc: 0.0000e+00 - val_loss: 2.5761e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.1490e-05 - acc: 0.0000e+00 - val_loss: 2.3482e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.4252e-05 - acc: 0.0000e+00 - val_loss: 1.9887e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.6815e-05 - acc: 0.0000e+00 - val_loss: 1.7044e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.1103e-05 - acc: 0.0000e+00 - val_loss: 1.1659e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.3005e-05 - acc: 0.0000e+00 - val_loss: 1.1951e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.6756e-05 - acc: 0.0000e+00 - val_loss: 1.7315e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.5129e-05 - acc: 0.0000e+00 - val_loss: 1.2389e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00003 MSE (0.01 RMSE)\n",
      "Test Score: 0.00177 MSE (0.04 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_15 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_16 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13707 samples, validate on 1523 samples\n",
      "Epoch 1/90\n",
      "13707/13707 [==============================] - 3s - loss: 0.0120 - acc: 0.0000e+00 - val_loss: 0.0062 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.4685e-04 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.3079e-04 - acc: 0.0000e+00 - val_loss: 4.8296e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4901e-04 - acc: 0.0000e+00 - val_loss: 3.1693e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4651e-04 - acc: 0.0000e+00 - val_loss: 3.4361e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4371e-04 - acc: 0.0000e+00 - val_loss: 4.0962e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3268e-04 - acc: 0.0000e+00 - val_loss: 2.8050e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2866e-04 - acc: 0.0000e+00 - val_loss: 2.2919e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2785e-04 - acc: 0.0000e+00 - val_loss: 3.1446e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2105e-04 - acc: 0.0000e+00 - val_loss: 2.3474e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1481e-04 - acc: 0.0000e+00 - val_loss: 2.2996e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2460e-04 - acc: 0.0000e+00 - val_loss: 2.5498e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1191e-04 - acc: 0.0000e+00 - val_loss: 2.2189e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0823e-04 - acc: 0.0000e+00 - val_loss: 2.1247e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2236e-04 - acc: 0.0000e+00 - val_loss: 3.5636e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1671e-04 - acc: 0.0000e+00 - val_loss: 2.0682e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1988e-04 - acc: 0.0000e+00 - val_loss: 2.1105e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1019e-04 - acc: 0.0000e+00 - val_loss: 2.2230e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2445e-04 - acc: 0.0000e+00 - val_loss: 3.1447e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3697e-04 - acc: 0.0000e+00 - val_loss: 9.0660e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4049e-04 - acc: 0.0000e+00 - val_loss: 2.6466e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0399e-04 - acc: 0.0000e+00 - val_loss: 2.2812e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1088e-04 - acc: 0.0000e+00 - val_loss: 2.5135e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.8831e-05 - acc: 0.0000e+00 - val_loss: 1.9055e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.7984e-05 - acc: 0.0000e+00 - val_loss: 2.5349e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0425e-04 - acc: 0.0000e+00 - val_loss: 3.5400e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.9999e-05 - acc: 0.0000e+00 - val_loss: 2.4460e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.4188e-05 - acc: 0.0000e+00 - val_loss: 1.8002e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0128e-04 - acc: 0.0000e+00 - val_loss: 2.4929e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.3605e-05 - acc: 0.0000e+00 - val_loss: 3.5280e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0502e-04 - acc: 0.0000e+00 - val_loss: 1.9450e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0064e-04 - acc: 0.0000e+00 - val_loss: 5.6009e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1432e-04 - acc: 0.0000e+00 - val_loss: 1.7679e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.2862e-05 - acc: 0.0000e+00 - val_loss: 1.7638e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.8320e-05 - acc: 0.0000e+00 - val_loss: 6.0299e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0669e-04 - acc: 0.0000e+00 - val_loss: 1.6939e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.4543e-05 - acc: 0.0000e+00 - val_loss: 2.0192e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0118e-04 - acc: 0.0000e+00 - val_loss: 2.3486e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.5330e-05 - acc: 0.0000e+00 - val_loss: 1.6804e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.2218e-05 - acc: 0.0000e+00 - val_loss: 1.8588e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0036e-04 - acc: 0.0000e+00 - val_loss: 2.4266e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.8635e-05 - acc: 0.0000e+00 - val_loss: 1.5695e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13707/13707 [==============================] - 1s - loss: 8.3445e-05 - acc: 0.0000e+00 - val_loss: 1.5683e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.4116e-05 - acc: 0.0000e+00 - val_loss: 1.5286e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.4973e-05 - acc: 0.0000e+00 - val_loss: 1.5757e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.8143e-05 - acc: 0.0000e+00 - val_loss: 2.6552e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.6381e-05 - acc: 0.0000e+00 - val_loss: 1.6570e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0738e-04 - acc: 0.0000e+00 - val_loss: 2.0487e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.9032e-05 - acc: 0.0000e+00 - val_loss: 1.4960e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.2504e-05 - acc: 0.0000e+00 - val_loss: 2.9658e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.5187e-05 - acc: 0.0000e+00 - val_loss: 1.9009e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.6104e-05 - acc: 0.0000e+00 - val_loss: 1.5197e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.6806e-05 - acc: 0.0000e+00 - val_loss: 1.5614e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.6898e-05 - acc: 0.0000e+00 - val_loss: 1.9437e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.6926e-05 - acc: 0.0000e+00 - val_loss: 1.8327e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0379e-04 - acc: 0.0000e+00 - val_loss: 1.4271e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.3747e-05 - acc: 0.0000e+00 - val_loss: 1.6740e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.2297e-05 - acc: 0.0000e+00 - val_loss: 2.3617e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.4170e-05 - acc: 0.0000e+00 - val_loss: 1.4652e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.2720e-05 - acc: 0.0000e+00 - val_loss: 1.3791e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.3972e-05 - acc: 0.0000e+00 - val_loss: 1.6514e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.3344e-05 - acc: 0.0000e+00 - val_loss: 3.4760e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.1770e-05 - acc: 0.0000e+00 - val_loss: 1.5910e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.7348e-05 - acc: 0.0000e+00 - val_loss: 1.3755e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.5690e-05 - acc: 0.0000e+00 - val_loss: 2.0227e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.4634e-05 - acc: 0.0000e+00 - val_loss: 3.2888e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.2604e-05 - acc: 0.0000e+00 - val_loss: 2.7122e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.6580e-05 - acc: 0.0000e+00 - val_loss: 2.4608e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.8147e-05 - acc: 0.0000e+00 - val_loss: 2.0378e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.4151e-05 - acc: 0.0000e+00 - val_loss: 1.6642e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.2906e-05 - acc: 0.0000e+00 - val_loss: 1.3460e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.1060e-05 - acc: 0.0000e+00 - val_loss: 1.6483e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.2112e-05 - acc: 0.0000e+00 - val_loss: 2.2681e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.2737e-05 - acc: 0.0000e+00 - val_loss: 1.8742e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.2589e-05 - acc: 0.0000e+00 - val_loss: 1.3082e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.4040e-05 - acc: 0.0000e+00 - val_loss: 1.2492e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.6149e-05 - acc: 0.0000e+00 - val_loss: 1.3526e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.4875e-05 - acc: 0.0000e+00 - val_loss: 2.4930e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.7066e-05 - acc: 0.0000e+00 - val_loss: 1.5552e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.4858e-05 - acc: 0.0000e+00 - val_loss: 1.5645e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.7532e-05 - acc: 0.0000e+00 - val_loss: 1.1672e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.3302e-05 - acc: 0.0000e+00 - val_loss: 1.7040e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.5768e-05 - acc: 0.0000e+00 - val_loss: 1.4459e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.3349e-05 - acc: 0.0000e+00 - val_loss: 1.2094e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.0339e-05 - acc: 0.0000e+00 - val_loss: 1.2544e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.0084e-05 - acc: 0.0000e+00 - val_loss: 1.3450e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.4950e-05 - acc: 0.0000e+00 - val_loss: 2.5771e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.4149e-05 - acc: 0.0000e+00 - val_loss: 1.1225e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.1039e-05 - acc: 0.0000e+00 - val_loss: 1.3706e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.8161e-05 - acc: 0.0000e+00 - val_loss: 1.4752e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00004 MSE (0.01 RMSE)\n",
      "Test Score: 0.00058 MSE (0.02 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_17 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 208,001\n",
      "Trainable params: 208,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13707 samples, validate on 1523 samples\n",
      "Epoch 1/90\n",
      "13707/13707 [==============================] - 3s - loss: 0.0122 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "13707/13707 [==============================] - 1s - loss: 5.3170e-04 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.4575e-04 - acc: 0.0000e+00 - val_loss: 7.3277e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6794e-04 - acc: 0.0000e+00 - val_loss: 3.8844e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4654e-04 - acc: 0.0000e+00 - val_loss: 3.0690e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3218e-04 - acc: 0.0000e+00 - val_loss: 2.6919e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2376e-04 - acc: 0.0000e+00 - val_loss: 4.8150e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2782e-04 - acc: 0.0000e+00 - val_loss: 2.5125e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1812e-04 - acc: 0.0000e+00 - val_loss: 2.2962e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1712e-04 - acc: 0.0000e+00 - val_loss: 2.5547e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1125e-04 - acc: 0.0000e+00 - val_loss: 2.1821e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0734e-04 - acc: 0.0000e+00 - val_loss: 2.6543e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0973e-04 - acc: 0.0000e+00 - val_loss: 2.5447e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0790e-04 - acc: 0.0000e+00 - val_loss: 2.3483e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1635e-04 - acc: 0.0000e+00 - val_loss: 3.1654e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1173e-04 - acc: 0.0000e+00 - val_loss: 2.5463e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0314e-04 - acc: 0.0000e+00 - val_loss: 2.2820e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.8267e-05 - acc: 0.0000e+00 - val_loss: 2.6831e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0017e-04 - acc: 0.0000e+00 - val_loss: 2.5274e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0263e-04 - acc: 0.0000e+00 - val_loss: 1.9952e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.6244e-05 - acc: 0.0000e+00 - val_loss: 3.9944e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0117e-04 - acc: 0.0000e+00 - val_loss: 3.7485e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.9505e-05 - acc: 0.0000e+00 - val_loss: 2.2896e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.9569e-05 - acc: 0.0000e+00 - val_loss: 3.4030e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0822e-04 - acc: 0.0000e+00 - val_loss: 4.0790e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0860e-04 - acc: 0.0000e+00 - val_loss: 1.9156e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0410e-04 - acc: 0.0000e+00 - val_loss: 2.0479e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0539e-04 - acc: 0.0000e+00 - val_loss: 4.8511e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0613e-04 - acc: 0.0000e+00 - val_loss: 2.3689e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.6721e-05 - acc: 0.0000e+00 - val_loss: 2.4239e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.4572e-05 - acc: 0.0000e+00 - val_loss: 2.5441e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.6483e-05 - acc: 0.0000e+00 - val_loss: 1.7625e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.7408e-05 - acc: 0.0000e+00 - val_loss: 1.8031e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0514e-04 - acc: 0.0000e+00 - val_loss: 2.8330e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0244e-04 - acc: 0.0000e+00 - val_loss: 2.0231e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.2074e-05 - acc: 0.0000e+00 - val_loss: 4.2372e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.3310e-05 - acc: 0.0000e+00 - val_loss: 2.0393e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.2361e-05 - acc: 0.0000e+00 - val_loss: 2.0808e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.5475e-05 - acc: 0.0000e+00 - val_loss: 1.6378e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.9638e-05 - acc: 0.0000e+00 - val_loss: 1.7345e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.2546e-05 - acc: 0.0000e+00 - val_loss: 5.1234e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.8866e-05 - acc: 0.0000e+00 - val_loss: 1.6806e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.7333e-05 - acc: 0.0000e+00 - val_loss: 1.5935e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.5070e-05 - acc: 0.0000e+00 - val_loss: 1.7870e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0402e-04 - acc: 0.0000e+00 - val_loss: 1.6310e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.2837e-05 - acc: 0.0000e+00 - val_loss: 2.0760e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.6093e-05 - acc: 0.0000e+00 - val_loss: 1.7476e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.1053e-05 - acc: 0.0000e+00 - val_loss: 2.3940e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.3303e-05 - acc: 0.0000e+00 - val_loss: 2.1411e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.9595e-05 - acc: 0.0000e+00 - val_loss: 1.7173e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0123e-04 - acc: 0.0000e+00 - val_loss: 1.4850e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.3607e-05 - acc: 0.0000e+00 - val_loss: 2.6273e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.4974e-05 - acc: 0.0000e+00 - val_loss: 2.7776e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.0545e-05 - acc: 0.0000e+00 - val_loss: 2.4902e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.3915e-05 - acc: 0.0000e+00 - val_loss: 1.4514e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.2979e-05 - acc: 0.0000e+00 - val_loss: 1.6482e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.4259e-05 - acc: 0.0000e+00 - val_loss: 1.7087e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13707/13707 [==============================] - 1s - loss: 7.5439e-05 - acc: 0.0000e+00 - val_loss: 1.3558e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.2382e-05 - acc: 0.0000e+00 - val_loss: 3.6089e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.7982e-05 - acc: 0.0000e+00 - val_loss: 2.9310e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.6975e-05 - acc: 0.0000e+00 - val_loss: 1.8401e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.7190e-05 - acc: 0.0000e+00 - val_loss: 1.7782e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.5438e-05 - acc: 0.0000e+00 - val_loss: 1.5962e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.1334e-05 - acc: 0.0000e+00 - val_loss: 2.3654e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.2133e-05 - acc: 0.0000e+00 - val_loss: 1.3777e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.7748e-05 - acc: 0.0000e+00 - val_loss: 1.9043e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.1454e-05 - acc: 0.0000e+00 - val_loss: 1.7700e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.0152e-05 - acc: 0.0000e+00 - val_loss: 1.4367e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.7906e-05 - acc: 0.0000e+00 - val_loss: 1.5113e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.7129e-05 - acc: 0.0000e+00 - val_loss: 1.4507e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.6346e-05 - acc: 0.0000e+00 - val_loss: 2.3820e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.8821e-05 - acc: 0.0000e+00 - val_loss: 1.4567e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.6241e-05 - acc: 0.0000e+00 - val_loss: 2.9517e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.7688e-05 - acc: 0.0000e+00 - val_loss: 1.5904e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.0465e-05 - acc: 0.0000e+00 - val_loss: 1.4471e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.8593e-05 - acc: 0.0000e+00 - val_loss: 2.0261e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.9944e-05 - acc: 0.0000e+00 - val_loss: 1.4383e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.5650e-05 - acc: 0.0000e+00 - val_loss: 1.8689e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.4978e-05 - acc: 0.0000e+00 - val_loss: 1.2999e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.5564e-05 - acc: 0.0000e+00 - val_loss: 1.1914e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.2767e-05 - acc: 0.0000e+00 - val_loss: 1.4582e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.5553e-05 - acc: 0.0000e+00 - val_loss: 1.1507e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.7178e-05 - acc: 0.0000e+00 - val_loss: 1.2124e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.6201e-05 - acc: 0.0000e+00 - val_loss: 2.4094e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.9020e-05 - acc: 0.0000e+00 - val_loss: 1.2595e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.6232e-05 - acc: 0.0000e+00 - val_loss: 1.9633e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.4495e-05 - acc: 0.0000e+00 - val_loss: 1.1766e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.8396e-05 - acc: 0.0000e+00 - val_loss: 1.3237e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.7739e-05 - acc: 0.0000e+00 - val_loss: 3.2675e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.5728e-05 - acc: 0.0000e+00 - val_loss: 1.2978e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00003 MSE (0.01 RMSE)\n",
      "Test Score: 0.00051 MSE (0.02 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_19 (LSTM)               (None, 22, 256)           267264    \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 22, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_20 (LSTM)               (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 16)                4112      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 796,705\n",
      "Trainable params: 796,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13707 samples, validate on 1523 samples\n",
      "Epoch 1/90\n",
      "13707/13707 [==============================] - 4s - loss: 0.0099 - acc: 0.0000e+00 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.3310e-04 - acc: 0.0000e+00 - val_loss: 6.3033e-04 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.3745e-04 - acc: 0.0000e+00 - val_loss: 2.9478e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0845e-04 - acc: 0.0000e+00 - val_loss: 2.6393e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.8539e-05 - acc: 0.0000e+00 - val_loss: 2.8786e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0005e-04 - acc: 0.0000e+00 - val_loss: 3.8208e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0627e-04 - acc: 0.0000e+00 - val_loss: 2.9814e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.3142e-05 - acc: 0.0000e+00 - val_loss: 2.4569e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0297e-04 - acc: 0.0000e+00 - val_loss: 8.0937e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.1450e-04 - acc: 0.0000e+00 - val_loss: 2.9584e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.7232e-05 - acc: 0.0000e+00 - val_loss: 3.6543e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0030e-04 - acc: 0.0000e+00 - val_loss: 2.7120e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.4092e-05 - acc: 0.0000e+00 - val_loss: 2.2967e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.4319e-05 - acc: 0.0000e+00 - val_loss: 2.2113e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.0924e-05 - acc: 0.0000e+00 - val_loss: 2.4672e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.2067e-05 - acc: 0.0000e+00 - val_loss: 2.5258e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.9537e-05 - acc: 0.0000e+00 - val_loss: 2.2433e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0070e-04 - acc: 0.0000e+00 - val_loss: 2.3401e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.3551e-05 - acc: 0.0000e+00 - val_loss: 2.6915e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.6260e-05 - acc: 0.0000e+00 - val_loss: 3.4556e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.6131e-05 - acc: 0.0000e+00 - val_loss: 2.3066e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.1438e-05 - acc: 0.0000e+00 - val_loss: 1.9621e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.6994e-05 - acc: 0.0000e+00 - val_loss: 2.9049e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0167e-04 - acc: 0.0000e+00 - val_loss: 3.0819e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.5200e-04 - acc: 0.0000e+00 - val_loss: 3.5665e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.1190e-05 - acc: 0.0000e+00 - val_loss: 2.7108e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.5759e-05 - acc: 0.0000e+00 - val_loss: 1.9469e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.1196e-05 - acc: 0.0000e+00 - val_loss: 2.8074e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.5423e-05 - acc: 0.0000e+00 - val_loss: 2.2285e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.8698e-05 - acc: 0.0000e+00 - val_loss: 1.8129e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.9218e-05 - acc: 0.0000e+00 - val_loss: 1.8054e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.3541e-05 - acc: 0.0000e+00 - val_loss: 2.4826e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.4460e-05 - acc: 0.0000e+00 - val_loss: 2.6781e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.1310e-05 - acc: 0.0000e+00 - val_loss: 8.5075e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.3961e-05 - acc: 0.0000e+00 - val_loss: 2.6197e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.8477e-05 - acc: 0.0000e+00 - val_loss: 1.7291e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.5672e-05 - acc: 0.0000e+00 - val_loss: 1.9632e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.5011e-05 - acc: 0.0000e+00 - val_loss: 1.6803e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.4966e-05 - acc: 0.0000e+00 - val_loss: 1.5507e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.1242e-05 - acc: 0.0000e+00 - val_loss: 4.5114e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.0893e-05 - acc: 0.0000e+00 - val_loss: 2.1917e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0144e-04 - acc: 0.0000e+00 - val_loss: 1.5423e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0315e-04 - acc: 0.0000e+00 - val_loss: 2.3157e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.5310e-05 - acc: 0.0000e+00 - val_loss: 1.8406e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.5867e-05 - acc: 0.0000e+00 - val_loss: 1.4676e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.8867e-05 - acc: 0.0000e+00 - val_loss: 1.4567e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.0101e-05 - acc: 0.0000e+00 - val_loss: 2.1274e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.0356e-05 - acc: 0.0000e+00 - val_loss: 1.5297e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.0867e-05 - acc: 0.0000e+00 - val_loss: 2.0406e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.5659e-05 - acc: 0.0000e+00 - val_loss: 2.1243e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.5254e-05 - acc: 0.0000e+00 - val_loss: 1.7563e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.4401e-05 - acc: 0.0000e+00 - val_loss: 1.9959e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.9934e-05 - acc: 0.0000e+00 - val_loss: 1.5515e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.0821e-05 - acc: 0.0000e+00 - val_loss: 1.6017e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.4790e-05 - acc: 0.0000e+00 - val_loss: 1.7770e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.8293e-05 - acc: 0.0000e+00 - val_loss: 1.5406e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.8009e-05 - acc: 0.0000e+00 - val_loss: 5.7840e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.1708e-05 - acc: 0.0000e+00 - val_loss: 1.3741e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.9262e-05 - acc: 0.0000e+00 - val_loss: 1.7759e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.5764e-05 - acc: 0.0000e+00 - val_loss: 1.8133e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.4565e-05 - acc: 0.0000e+00 - val_loss: 1.2009e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.4235e-05 - acc: 0.0000e+00 - val_loss: 1.3678e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.7988e-05 - acc: 0.0000e+00 - val_loss: 2.6540e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.1905e-05 - acc: 0.0000e+00 - val_loss: 2.0152e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.2395e-05 - acc: 0.0000e+00 - val_loss: 5.3506e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.9165e-05 - acc: 0.0000e+00 - val_loss: 1.4375e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.6399e-05 - acc: 0.0000e+00 - val_loss: 1.1962e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.0283e-05 - acc: 0.0000e+00 - val_loss: 2.7642e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.2015e-05 - acc: 0.0000e+00 - val_loss: 1.1984e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.5632e-05 - acc: 0.0000e+00 - val_loss: 2.4695e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.7413e-05 - acc: 0.0000e+00 - val_loss: 1.3103e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13707/13707 [==============================] - 2s - loss: 5.8937e-05 - acc: 0.0000e+00 - val_loss: 1.1271e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.1963e-05 - acc: 0.0000e+00 - val_loss: 1.3947e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.4133e-05 - acc: 0.0000e+00 - val_loss: 1.1294e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.8761e-05 - acc: 0.0000e+00 - val_loss: 1.1375e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.8949e-05 - acc: 0.0000e+00 - val_loss: 1.0669e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7898e-05 - acc: 0.0000e+00 - val_loss: 2.4619e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.8353e-05 - acc: 0.0000e+00 - val_loss: 1.1384e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.1247e-05 - acc: 0.0000e+00 - val_loss: 1.6741e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.0448e-05 - acc: 0.0000e+00 - val_loss: 1.0701e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.1989e-05 - acc: 0.0000e+00 - val_loss: 3.3952e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.0954e-05 - acc: 0.0000e+00 - val_loss: 1.0516e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.5193e-05 - acc: 0.0000e+00 - val_loss: 1.4999e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.5840e-05 - acc: 0.0000e+00 - val_loss: 1.0229e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.9783e-05 - acc: 0.0000e+00 - val_loss: 1.0082e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.0107e-05 - acc: 0.0000e+00 - val_loss: 1.5523e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.2912e-05 - acc: 0.0000e+00 - val_loss: 1.3979e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.1143e-05 - acc: 0.0000e+00 - val_loss: 9.8613e-05 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.9673e-05 - acc: 0.0000e+00 - val_loss: 1.0354e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.9925e-05 - acc: 0.0000e+00 - val_loss: 9.6869e-05 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00002 MSE (0.00 RMSE)\n",
      "Test Score: 0.00071 MSE (0.03 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_21 (LSTM)               (None, 22, 256)           267264    \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 22, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_22 (LSTM)               (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 800,833\n",
      "Trainable params: 800,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13707 samples, validate on 1523 samples\n",
      "Epoch 1/90\n",
      "13707/13707 [==============================] - 4s - loss: 0.0077 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "13707/13707 [==============================] - 2s - loss: 3.1762e-04 - acc: 0.0000e+00 - val_loss: 6.2745e-04 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.5307e-04 - acc: 0.0000e+00 - val_loss: 3.8348e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0878e-04 - acc: 0.0000e+00 - val_loss: 2.7381e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0411e-04 - acc: 0.0000e+00 - val_loss: 2.5320e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.5639e-05 - acc: 0.0000e+00 - val_loss: 2.8773e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0412e-04 - acc: 0.0000e+00 - val_loss: 2.4197e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.5853e-05 - acc: 0.0000e+00 - val_loss: 2.9283e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.5361e-05 - acc: 0.0000e+00 - val_loss: 3.1665e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.9827e-05 - acc: 0.0000e+00 - val_loss: 2.1170e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.2749e-05 - acc: 0.0000e+00 - val_loss: 3.4663e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.6069e-05 - acc: 0.0000e+00 - val_loss: 2.1086e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.1938e-05 - acc: 0.0000e+00 - val_loss: 2.0096e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.3655e-05 - acc: 0.0000e+00 - val_loss: 3.1467e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.7304e-05 - acc: 0.0000e+00 - val_loss: 3.9102e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.5494e-05 - acc: 0.0000e+00 - val_loss: 1.8815e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.6201e-05 - acc: 0.0000e+00 - val_loss: 2.9243e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.7635e-05 - acc: 0.0000e+00 - val_loss: 1.8097e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.1000e-05 - acc: 0.0000e+00 - val_loss: 2.0198e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.7215e-05 - acc: 0.0000e+00 - val_loss: 1.7100e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.9287e-05 - acc: 0.0000e+00 - val_loss: 3.3076e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.0768e-05 - acc: 0.0000e+00 - val_loss: 1.7367e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.8671e-05 - acc: 0.0000e+00 - val_loss: 1.7448e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.3348e-05 - acc: 0.0000e+00 - val_loss: 1.6685e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0435e-04 - acc: 0.0000e+00 - val_loss: 4.8952e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.4527e-05 - acc: 0.0000e+00 - val_loss: 1.6342e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.9623e-05 - acc: 0.0000e+00 - val_loss: 1.6144e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.9107e-05 - acc: 0.0000e+00 - val_loss: 2.1771e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.1061e-05 - acc: 0.0000e+00 - val_loss: 2.1561e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.0758e-05 - acc: 0.0000e+00 - val_loss: 1.5033e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.8513e-05 - acc: 0.0000e+00 - val_loss: 1.5234e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.1976e-05 - acc: 0.0000e+00 - val_loss: 1.9570e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.0862e-05 - acc: 0.0000e+00 - val_loss: 1.8302e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.5913e-05 - acc: 0.0000e+00 - val_loss: 2.4115e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.3368e-05 - acc: 0.0000e+00 - val_loss: 3.6891e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.6337e-05 - acc: 0.0000e+00 - val_loss: 3.9069e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.1995e-05 - acc: 0.0000e+00 - val_loss: 6.9418e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.1108e-05 - acc: 0.0000e+00 - val_loss: 1.4640e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.9820e-05 - acc: 0.0000e+00 - val_loss: 2.0474e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.5930e-05 - acc: 0.0000e+00 - val_loss: 1.4271e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.9180e-05 - acc: 0.0000e+00 - val_loss: 1.2974e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.0244e-05 - acc: 0.0000e+00 - val_loss: 2.1810e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.1317e-05 - acc: 0.0000e+00 - val_loss: 1.3586e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.0566e-05 - acc: 0.0000e+00 - val_loss: 4.3881e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.5703e-05 - acc: 0.0000e+00 - val_loss: 1.7405e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.6752e-05 - acc: 0.0000e+00 - val_loss: 1.2157e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.2369e-05 - acc: 0.0000e+00 - val_loss: 1.3106e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.1495e-05 - acc: 0.0000e+00 - val_loss: 1.3340e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.1741e-04 - acc: 0.0000e+00 - val_loss: 2.0397e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.2194e-05 - acc: 0.0000e+00 - val_loss: 1.3704e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7236e-05 - acc: 0.0000e+00 - val_loss: 1.5559e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.2989e-05 - acc: 0.0000e+00 - val_loss: 1.1665e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.4549e-05 - acc: 0.0000e+00 - val_loss: 1.6413e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.5304e-05 - acc: 0.0000e+00 - val_loss: 2.7490e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.6171e-05 - acc: 0.0000e+00 - val_loss: 1.9201e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.8330e-05 - acc: 0.0000e+00 - val_loss: 4.1592e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.9335e-05 - acc: 0.0000e+00 - val_loss: 1.1460e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7448e-05 - acc: 0.0000e+00 - val_loss: 1.2008e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.9417e-05 - acc: 0.0000e+00 - val_loss: 1.0950e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.1140e-05 - acc: 0.0000e+00 - val_loss: 1.0766e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.1937e-05 - acc: 0.0000e+00 - val_loss: 2.3076e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.8266e-05 - acc: 0.0000e+00 - val_loss: 1.0760e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.5861e-05 - acc: 0.0000e+00 - val_loss: 1.4369e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.4926e-05 - acc: 0.0000e+00 - val_loss: 3.2232e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.3248e-05 - acc: 0.0000e+00 - val_loss: 1.8481e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.7679e-05 - acc: 0.0000e+00 - val_loss: 1.2871e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7880e-05 - acc: 0.0000e+00 - val_loss: 2.4993e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.6346e-05 - acc: 0.0000e+00 - val_loss: 1.0069e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.1183e-05 - acc: 0.0000e+00 - val_loss: 1.0771e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7082e-05 - acc: 0.0000e+00 - val_loss: 2.9158e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.0512e-05 - acc: 0.0000e+00 - val_loss: 1.2987e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.9147e-05 - acc: 0.0000e+00 - val_loss: 2.5739e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.1296e-05 - acc: 0.0000e+00 - val_loss: 9.9959e-05 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.9777e-05 - acc: 0.0000e+00 - val_loss: 9.6162e-05 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.1116e-05 - acc: 0.0000e+00 - val_loss: 1.1731e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.0422e-05 - acc: 0.0000e+00 - val_loss: 1.4577e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.1013e-05 - acc: 0.0000e+00 - val_loss: 1.0623e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.9559e-05 - acc: 0.0000e+00 - val_loss: 1.3815e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.6423e-05 - acc: 0.0000e+00 - val_loss: 1.4018e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.2166e-05 - acc: 0.0000e+00 - val_loss: 1.5155e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.8065e-05 - acc: 0.0000e+00 - val_loss: 1.1399e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.9102e-05 - acc: 0.0000e+00 - val_loss: 8.9431e-05 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.1838e-05 - acc: 0.0000e+00 - val_loss: 1.7270e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.4163e-05 - acc: 0.0000e+00 - val_loss: 1.6806e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7365e-05 - acc: 0.0000e+00 - val_loss: 1.2908e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13707/13707 [==============================] - 2s - loss: 4.6763e-05 - acc: 0.0000e+00 - val_loss: 1.0595e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.0788e-05 - acc: 0.0000e+00 - val_loss: 1.5208e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.0592e-05 - acc: 0.0000e+00 - val_loss: 1.0276e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.5310e-05 - acc: 0.0000e+00 - val_loss: 1.6509e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.6720e-05 - acc: 0.0000e+00 - val_loss: 1.3959e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00003 MSE (0.01 RMSE)\n",
      "Test Score: 0.00021 MSE (0.01 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_23 (LSTM)               (None, 22, 256)           267264    \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 22, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_24 (LSTM)               (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 809,089\n",
      "Trainable params: 809,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13707 samples, validate on 1523 samples\n",
      "Epoch 1/90\n",
      "13707/13707 [==============================] - 4s - loss: 0.0096 - acc: 0.0000e+00 - val_loss: 0.0096 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.0181e-04 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.6371e-04 - acc: 0.0000e+00 - val_loss: 4.1609e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.2213e-04 - acc: 0.0000e+00 - val_loss: 3.2139e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.1409e-04 - acc: 0.0000e+00 - val_loss: 4.1379e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0606e-04 - acc: 0.0000e+00 - val_loss: 2.4285e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.8232e-05 - acc: 0.0000e+00 - val_loss: 2.3283e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0070e-04 - acc: 0.0000e+00 - val_loss: 2.2279e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.0621e-05 - acc: 0.0000e+00 - val_loss: 2.2914e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.8094e-05 - acc: 0.0000e+00 - val_loss: 2.1350e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.7727e-05 - acc: 0.0000e+00 - val_loss: 2.0742e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.6307e-05 - acc: 0.0000e+00 - val_loss: 2.3852e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.4454e-05 - acc: 0.0000e+00 - val_loss: 1.9922e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.7632e-05 - acc: 0.0000e+00 - val_loss: 1.9435e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.8439e-05 - acc: 0.0000e+00 - val_loss: 1.9311e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.6799e-05 - acc: 0.0000e+00 - val_loss: 2.7103e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.0145e-05 - acc: 0.0000e+00 - val_loss: 1.8856e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0098e-04 - acc: 0.0000e+00 - val_loss: 2.2187e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.4428e-05 - acc: 0.0000e+00 - val_loss: 2.2218e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.1758e-05 - acc: 0.0000e+00 - val_loss: 1.9211e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.2834e-05 - acc: 0.0000e+00 - val_loss: 2.1215e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.7957e-05 - acc: 0.0000e+00 - val_loss: 2.0983e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.5747e-05 - acc: 0.0000e+00 - val_loss: 1.7711e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.9023e-05 - acc: 0.0000e+00 - val_loss: 2.0176e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.1649e-05 - acc: 0.0000e+00 - val_loss: 1.8603e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.3357e-05 - acc: 0.0000e+00 - val_loss: 3.3086e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.5898e-05 - acc: 0.0000e+00 - val_loss: 1.9545e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.7264e-05 - acc: 0.0000e+00 - val_loss: 1.6782e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.6493e-05 - acc: 0.0000e+00 - val_loss: 4.3663e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.6357e-05 - acc: 0.0000e+00 - val_loss: 1.6497e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.0731e-05 - acc: 0.0000e+00 - val_loss: 1.5683e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.3049e-05 - acc: 0.0000e+00 - val_loss: 1.5698e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.0850e-05 - acc: 0.0000e+00 - val_loss: 1.8113e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.4386e-05 - acc: 0.0000e+00 - val_loss: 1.6883e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.3276e-05 - acc: 0.0000e+00 - val_loss: 2.7601e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.1896e-05 - acc: 0.0000e+00 - val_loss: 1.6007e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.1360e-05 - acc: 0.0000e+00 - val_loss: 1.7175e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.3682e-05 - acc: 0.0000e+00 - val_loss: 1.6422e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.7071e-05 - acc: 0.0000e+00 - val_loss: 1.7621e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7570e-05 - acc: 0.0000e+00 - val_loss: 1.5119e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.1288e-05 - acc: 0.0000e+00 - val_loss: 2.1572e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.3713e-05 - acc: 0.0000e+00 - val_loss: 1.6333e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.9881e-05 - acc: 0.0000e+00 - val_loss: 1.7215e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.2633e-05 - acc: 0.0000e+00 - val_loss: 1.3589e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.4513e-05 - acc: 0.0000e+00 - val_loss: 1.7724e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.2045e-05 - acc: 0.0000e+00 - val_loss: 1.9163e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.5259e-05 - acc: 0.0000e+00 - val_loss: 2.2824e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.8696e-05 - acc: 0.0000e+00 - val_loss: 1.4655e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.6153e-05 - acc: 0.0000e+00 - val_loss: 1.3362e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.9115e-05 - acc: 0.0000e+00 - val_loss: 1.6425e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.0320e-05 - acc: 0.0000e+00 - val_loss: 1.2688e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.4085e-05 - acc: 0.0000e+00 - val_loss: 1.9757e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.0367e-05 - acc: 0.0000e+00 - val_loss: 1.6377e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.9877e-05 - acc: 0.0000e+00 - val_loss: 1.2305e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.0607e-05 - acc: 0.0000e+00 - val_loss: 3.8728e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.2545e-05 - acc: 0.0000e+00 - val_loss: 3.0147e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.0281e-05 - acc: 0.0000e+00 - val_loss: 1.4459e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.4326e-05 - acc: 0.0000e+00 - val_loss: 1.2723e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.0050e-05 - acc: 0.0000e+00 - val_loss: 1.2949e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.5365e-05 - acc: 0.0000e+00 - val_loss: 1.2775e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.4587e-05 - acc: 0.0000e+00 - val_loss: 1.1553e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.6952e-05 - acc: 0.0000e+00 - val_loss: 3.5440e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7505e-05 - acc: 0.0000e+00 - val_loss: 1.2739e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.1206e-05 - acc: 0.0000e+00 - val_loss: 1.3347e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.9365e-05 - acc: 0.0000e+00 - val_loss: 2.1700e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.9185e-05 - acc: 0.0000e+00 - val_loss: 3.3951e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.8418e-05 - acc: 0.0000e+00 - val_loss: 2.6330e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.6553e-05 - acc: 0.0000e+00 - val_loss: 1.4572e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.9944e-05 - acc: 0.0000e+00 - val_loss: 3.8270e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.6265e-05 - acc: 0.0000e+00 - val_loss: 1.9433e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.9580e-05 - acc: 0.0000e+00 - val_loss: 1.0720e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.1305e-05 - acc: 0.0000e+00 - val_loss: 1.8352e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.3313e-05 - acc: 0.0000e+00 - val_loss: 1.0967e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.5718e-05 - acc: 0.0000e+00 - val_loss: 1.1168e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.7179e-05 - acc: 0.0000e+00 - val_loss: 1.6778e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.9833e-05 - acc: 0.0000e+00 - val_loss: 1.8654e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.6820e-05 - acc: 0.0000e+00 - val_loss: 1.1794e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.3134e-05 - acc: 0.0000e+00 - val_loss: 1.5263e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.0241e-05 - acc: 0.0000e+00 - val_loss: 1.0799e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.7767e-05 - acc: 0.0000e+00 - val_loss: 1.0010e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.0136e-05 - acc: 0.0000e+00 - val_loss: 1.0205e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.8949e-05 - acc: 0.0000e+00 - val_loss: 1.3785e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.9370e-05 - acc: 0.0000e+00 - val_loss: 9.9040e-05 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.7166e-05 - acc: 0.0000e+00 - val_loss: 1.1173e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.8248e-05 - acc: 0.0000e+00 - val_loss: 1.7276e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.4496e-05 - acc: 0.0000e+00 - val_loss: 1.9274e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.9201e-05 - acc: 0.0000e+00 - val_loss: 2.4660e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.6730e-05 - acc: 0.0000e+00 - val_loss: 9.9719e-05 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.6232e-05 - acc: 0.0000e+00 - val_loss: 2.0847e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.2217e-05 - acc: 0.0000e+00 - val_loss: 9.5365e-05 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00002 MSE (0.00 RMSE)\n",
      "Test Score: 0.00030 MSE (0.02 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_25 (LSTM)               (None, 22, 512)           1058816   \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 22, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_26 (LSTM)               (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 16)                8208      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 3,166,241\n",
      "Trainable params: 3,166,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13707 samples, validate on 1523 samples\n",
      "Epoch 1/90\n",
      "13707/13707 [==============================] - 7s - loss: 0.0074 - acc: 0.0000e+00 - val_loss: 0.0043 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13707/13707 [==============================] - 5s - loss: 1.7744e-04 - acc: 0.0000e+00 - val_loss: 3.4495e-04 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "13707/13707 [==============================] - 5s - loss: 9.2383e-05 - acc: 0.0000e+00 - val_loss: 3.1878e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "13707/13707 [==============================] - 5s - loss: 8.8010e-05 - acc: 0.0000e+00 - val_loss: 5.9432e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "13707/13707 [==============================] - 5s - loss: 8.6156e-05 - acc: 0.0000e+00 - val_loss: 2.6485e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "13707/13707 [==============================] - 5s - loss: 9.8003e-05 - acc: 0.0000e+00 - val_loss: 3.1075e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "13707/13707 [==============================] - 5s - loss: 9.6360e-05 - acc: 0.0000e+00 - val_loss: 3.4285e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "13707/13707 [==============================] - 5s - loss: 8.0516e-05 - acc: 0.0000e+00 - val_loss: 3.9601e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "13707/13707 [==============================] - 5s - loss: 1.0337e-04 - acc: 0.0000e+00 - val_loss: 3.1765e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "13707/13707 [==============================] - 5s - loss: 1.0934e-04 - acc: 0.0000e+00 - val_loss: 3.2519e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.8272e-05 - acc: 0.0000e+00 - val_loss: 4.7571e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.4994e-05 - acc: 0.0000e+00 - val_loss: 2.9675e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "13707/13707 [==============================] - 5s - loss: 8.2102e-05 - acc: 0.0000e+00 - val_loss: 2.8599e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "13707/13707 [==============================] - 5s - loss: 1.0325e-04 - acc: 0.0000e+00 - val_loss: 2.4849e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "13707/13707 [==============================] - 5s - loss: 8.5081e-05 - acc: 0.0000e+00 - val_loss: 2.3204e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.4864e-05 - acc: 0.0000e+00 - val_loss: 2.2429e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.8728e-05 - acc: 0.0000e+00 - val_loss: 2.4237e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.3073e-05 - acc: 0.0000e+00 - val_loss: 2.3263e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.4732e-05 - acc: 0.0000e+00 - val_loss: 9.5417e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "13707/13707 [==============================] - 5s - loss: 8.2801e-05 - acc: 0.0000e+00 - val_loss: 2.3274e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "13707/13707 [==============================] - 5s - loss: 9.1270e-05 - acc: 0.0000e+00 - val_loss: 3.0606e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.6542e-05 - acc: 0.0000e+00 - val_loss: 2.1356e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.3672e-05 - acc: 0.0000e+00 - val_loss: 2.0471e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "13707/13707 [==============================] - 5s - loss: 9.2687e-05 - acc: 0.0000e+00 - val_loss: 2.1525e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.1923e-05 - acc: 0.0000e+00 - val_loss: 2.6906e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.5529e-05 - acc: 0.0000e+00 - val_loss: 2.2161e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.6567e-05 - acc: 0.0000e+00 - val_loss: 3.0321e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.3865e-05 - acc: 0.0000e+00 - val_loss: 2.1432e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.8791e-05 - acc: 0.0000e+00 - val_loss: 3.4520e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.7491e-05 - acc: 0.0000e+00 - val_loss: 2.4891e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.4428e-05 - acc: 0.0000e+00 - val_loss: 2.2451e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.6747e-05 - acc: 0.0000e+00 - val_loss: 2.7320e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "13707/13707 [==============================] - 5s - loss: 8.5721e-05 - acc: 0.0000e+00 - val_loss: 2.4247e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.5621e-05 - acc: 0.0000e+00 - val_loss: 1.9781e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.1395e-05 - acc: 0.0000e+00 - val_loss: 5.5046e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.9735e-05 - acc: 0.0000e+00 - val_loss: 1.7398e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "13707/13707 [==============================] - 5s - loss: 8.6767e-05 - acc: 0.0000e+00 - val_loss: 8.1312e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.8467e-05 - acc: 0.0000e+00 - val_loss: 1.9842e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.2052e-05 - acc: 0.0000e+00 - val_loss: 2.2533e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.1900e-05 - acc: 0.0000e+00 - val_loss: 1.7377e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.4266e-05 - acc: 0.0000e+00 - val_loss: 4.0736e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.4379e-05 - acc: 0.0000e+00 - val_loss: 2.7438e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.3307e-05 - acc: 0.0000e+00 - val_loss: 1.4855e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.0383e-05 - acc: 0.0000e+00 - val_loss: 1.6908e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.2109e-05 - acc: 0.0000e+00 - val_loss: 1.4925e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.8929e-05 - acc: 0.0000e+00 - val_loss: 2.0280e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.6286e-05 - acc: 0.0000e+00 - val_loss: 3.6762e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.9321e-05 - acc: 0.0000e+00 - val_loss: 4.1044e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.7442e-05 - acc: 0.0000e+00 - val_loss: 2.6415e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.1384e-05 - acc: 0.0000e+00 - val_loss: 1.2662e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.3324e-05 - acc: 0.0000e+00 - val_loss: 1.7271e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.5706e-05 - acc: 0.0000e+00 - val_loss: 3.7834e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.7666e-05 - acc: 0.0000e+00 - val_loss: 1.3999e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.3377e-05 - acc: 0.0000e+00 - val_loss: 1.2388e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "13707/13707 [==============================] - 5s - loss: 8.0172e-05 - acc: 0.0000e+00 - val_loss: 2.4319e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.6979e-05 - acc: 0.0000e+00 - val_loss: 1.2924e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.7535e-05 - acc: 0.0000e+00 - val_loss: 4.3677e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.4995e-05 - acc: 0.0000e+00 - val_loss: 2.8436e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13707/13707 [==============================] - 5s - loss: 5.0257e-05 - acc: 0.0000e+00 - val_loss: 1.1430e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.0646e-05 - acc: 0.0000e+00 - val_loss: 1.9424e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.6332e-05 - acc: 0.0000e+00 - val_loss: 7.3764e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.5294e-05 - acc: 0.0000e+00 - val_loss: 1.1102e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.0142e-05 - acc: 0.0000e+00 - val_loss: 4.0685e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.0925e-05 - acc: 0.0000e+00 - val_loss: 1.3003e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.4738e-05 - acc: 0.0000e+00 - val_loss: 1.0553e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.0880e-05 - acc: 0.0000e+00 - val_loss: 1.5358e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "13707/13707 [==============================] - 5s - loss: 3.8448e-05 - acc: 0.0000e+00 - val_loss: 2.8436e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.0430e-05 - acc: 0.0000e+00 - val_loss: 1.8442e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.0367e-05 - acc: 0.0000e+00 - val_loss: 2.5187e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.2968e-05 - acc: 0.0000e+00 - val_loss: 3.0867e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.6618e-05 - acc: 0.0000e+00 - val_loss: 1.6065e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.2401e-05 - acc: 0.0000e+00 - val_loss: 1.6702e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.0544e-05 - acc: 0.0000e+00 - val_loss: 9.5525e-05 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "13707/13707 [==============================] - 5s - loss: 3.9828e-05 - acc: 0.0000e+00 - val_loss: 1.8311e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.1247e-05 - acc: 0.0000e+00 - val_loss: 3.4708e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.0362e-05 - acc: 0.0000e+00 - val_loss: 1.1589e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.2499e-05 - acc: 0.0000e+00 - val_loss: 1.3025e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.2591e-05 - acc: 0.0000e+00 - val_loss: 1.2744e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "13707/13707 [==============================] - 5s - loss: 3.5940e-05 - acc: 0.0000e+00 - val_loss: 9.2073e-05 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "13707/13707 [==============================] - 5s - loss: 3.7204e-05 - acc: 0.0000e+00 - val_loss: 1.3093e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "13707/13707 [==============================] - 5s - loss: 3.6906e-05 - acc: 0.0000e+00 - val_loss: 9.7412e-05 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.2656e-05 - acc: 0.0000e+00 - val_loss: 2.3259e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.9680e-05 - acc: 0.0000e+00 - val_loss: 1.3716e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.5916e-05 - acc: 0.0000e+00 - val_loss: 9.1353e-05 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.7735e-05 - acc: 0.0000e+00 - val_loss: 9.1079e-05 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.5627e-05 - acc: 0.0000e+00 - val_loss: 1.7377e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.1069e-05 - acc: 0.0000e+00 - val_loss: 2.5054e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.1901e-05 - acc: 0.0000e+00 - val_loss: 3.0488e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.3568e-05 - acc: 0.0000e+00 - val_loss: 1.4197e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "13707/13707 [==============================] - 5s - loss: 3.6352e-05 - acc: 0.0000e+00 - val_loss: 8.7662e-05 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00002 MSE (0.00 RMSE)\n",
      "Test Score: 0.00056 MSE (0.02 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_27 (LSTM)               (None, 22, 512)           1058816   \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 22, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_28 (LSTM)               (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 32)                16416     \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 3,174,465\n",
      "Trainable params: 3,174,465\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13707 samples, validate on 1523 samples\n",
      "Epoch 1/90\n",
      "13707/13707 [==============================] - 7s - loss: 0.0114 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.7627e-04 - acc: 0.0000e+00 - val_loss: 8.7711e-04 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "13707/13707 [==============================] - 5s - loss: 1.6591e-04 - acc: 0.0000e+00 - val_loss: 4.3464e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "13707/13707 [==============================] - 5s - loss: 1.1055e-04 - acc: 0.0000e+00 - val_loss: 3.1364e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "13707/13707 [==============================] - 5s - loss: 8.6402e-05 - acc: 0.0000e+00 - val_loss: 2.6699e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "13707/13707 [==============================] - 5s - loss: 8.0669e-05 - acc: 0.0000e+00 - val_loss: 2.3708e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.7800e-05 - acc: 0.0000e+00 - val_loss: 2.6208e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "13707/13707 [==============================] - 5s - loss: 9.0497e-05 - acc: 0.0000e+00 - val_loss: 2.3972e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.1067e-05 - acc: 0.0000e+00 - val_loss: 2.4296e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.9885e-05 - acc: 0.0000e+00 - val_loss: 2.5970e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.1293e-05 - acc: 0.0000e+00 - val_loss: 2.2061e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.0748e-05 - acc: 0.0000e+00 - val_loss: 2.1607e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.5438e-05 - acc: 0.0000e+00 - val_loss: 3.1982e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.7950e-05 - acc: 0.0000e+00 - val_loss: 2.6940e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.7328e-05 - acc: 0.0000e+00 - val_loss: 2.0519e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.3397e-05 - acc: 0.0000e+00 - val_loss: 2.2156e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.0194e-05 - acc: 0.0000e+00 - val_loss: 2.1489e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.1922e-05 - acc: 0.0000e+00 - val_loss: 2.2043e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.7475e-05 - acc: 0.0000e+00 - val_loss: 1.9719e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.9206e-05 - acc: 0.0000e+00 - val_loss: 3.4417e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.3915e-05 - acc: 0.0000e+00 - val_loss: 2.8902e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.9033e-05 - acc: 0.0000e+00 - val_loss: 2.5501e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.8111e-05 - acc: 0.0000e+00 - val_loss: 6.4109e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.6134e-05 - acc: 0.0000e+00 - val_loss: 2.0495e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.7076e-05 - acc: 0.0000e+00 - val_loss: 1.9230e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.9483e-05 - acc: 0.0000e+00 - val_loss: 2.2378e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.6974e-05 - acc: 0.0000e+00 - val_loss: 3.5238e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.4746e-05 - acc: 0.0000e+00 - val_loss: 1.6960e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.7180e-05 - acc: 0.0000e+00 - val_loss: 2.9533e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.3362e-05 - acc: 0.0000e+00 - val_loss: 1.7395e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.9658e-05 - acc: 0.0000e+00 - val_loss: 2.7860e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.8084e-05 - acc: 0.0000e+00 - val_loss: 2.2948e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.0821e-05 - acc: 0.0000e+00 - val_loss: 1.6719e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.8743e-05 - acc: 0.0000e+00 - val_loss: 3.2100e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.7563e-05 - acc: 0.0000e+00 - val_loss: 1.5917e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.9278e-05 - acc: 0.0000e+00 - val_loss: 1.8111e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.4663e-05 - acc: 0.0000e+00 - val_loss: 1.6178e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.3156e-05 - acc: 0.0000e+00 - val_loss: 1.6793e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.2560e-05 - acc: 0.0000e+00 - val_loss: 1.7672e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.2714e-05 - acc: 0.0000e+00 - val_loss: 1.9043e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.7904e-05 - acc: 0.0000e+00 - val_loss: 1.8789e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.2191e-05 - acc: 0.0000e+00 - val_loss: 1.9801e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.2251e-05 - acc: 0.0000e+00 - val_loss: 2.5759e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.1228e-05 - acc: 0.0000e+00 - val_loss: 2.9425e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.4749e-05 - acc: 0.0000e+00 - val_loss: 3.1890e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.8371e-05 - acc: 0.0000e+00 - val_loss: 1.5237e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.6497e-05 - acc: 0.0000e+00 - val_loss: 3.3804e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.4504e-05 - acc: 0.0000e+00 - val_loss: 1.3825e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.0490e-05 - acc: 0.0000e+00 - val_loss: 1.4198e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.4790e-05 - acc: 0.0000e+00 - val_loss: 2.0868e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.3868e-05 - acc: 0.0000e+00 - val_loss: 1.4702e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.2877e-05 - acc: 0.0000e+00 - val_loss: 1.2672e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.3234e-05 - acc: 0.0000e+00 - val_loss: 1.7786e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.1293e-05 - acc: 0.0000e+00 - val_loss: 2.4828e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.8906e-05 - acc: 0.0000e+00 - val_loss: 3.9230e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.3556e-05 - acc: 0.0000e+00 - val_loss: 5.8902e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.4967e-05 - acc: 0.0000e+00 - val_loss: 2.3537e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.3928e-05 - acc: 0.0000e+00 - val_loss: 1.9513e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.1963e-05 - acc: 0.0000e+00 - val_loss: 1.3201e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.0514e-05 - acc: 0.0000e+00 - val_loss: 2.3785e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.1522e-05 - acc: 0.0000e+00 - val_loss: 1.3313e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.1900e-05 - acc: 0.0000e+00 - val_loss: 1.2340e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.1488e-05 - acc: 0.0000e+00 - val_loss: 1.8833e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.8815e-05 - acc: 0.0000e+00 - val_loss: 2.8125e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.1729e-05 - acc: 0.0000e+00 - val_loss: 1.1163e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.0148e-05 - acc: 0.0000e+00 - val_loss: 1.4508e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.5945e-05 - acc: 0.0000e+00 - val_loss: 1.2213e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.7222e-05 - acc: 0.0000e+00 - val_loss: 1.7338e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.6965e-05 - acc: 0.0000e+00 - val_loss: 1.3902e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "13707/13707 [==============================] - 5s - loss: 3.8000e-05 - acc: 0.0000e+00 - val_loss: 2.2710e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.4208e-05 - acc: 0.0000e+00 - val_loss: 1.1956e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.4768e-05 - acc: 0.0000e+00 - val_loss: 2.4201e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13707/13707 [==============================] - 5s - loss: 4.6059e-05 - acc: 0.0000e+00 - val_loss: 2.6171e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.2302e-05 - acc: 0.0000e+00 - val_loss: 1.0281e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.0051e-05 - acc: 0.0000e+00 - val_loss: 1.1258e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.0282e-05 - acc: 0.0000e+00 - val_loss: 1.8706e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.0816e-05 - acc: 0.0000e+00 - val_loss: 1.0030e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.3881e-05 - acc: 0.0000e+00 - val_loss: 3.4460e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.6086e-05 - acc: 0.0000e+00 - val_loss: 1.7175e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.4014e-05 - acc: 0.0000e+00 - val_loss: 9.8474e-05 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.2938e-05 - acc: 0.0000e+00 - val_loss: 3.6452e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.2751e-05 - acc: 0.0000e+00 - val_loss: 1.5063e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.0101e-05 - acc: 0.0000e+00 - val_loss: 1.1372e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "13707/13707 [==============================] - 5s - loss: 3.7873e-05 - acc: 0.0000e+00 - val_loss: 1.1552e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "13707/13707 [==============================] - 5s - loss: 3.9376e-05 - acc: 0.0000e+00 - val_loss: 9.7031e-05 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.4795e-05 - acc: 0.0000e+00 - val_loss: 1.2941e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.8544e-05 - acc: 0.0000e+00 - val_loss: 1.1371e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "13707/13707 [==============================] - 5s - loss: 3.9842e-05 - acc: 0.0000e+00 - val_loss: 1.2123e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "13707/13707 [==============================] - 5s - loss: 3.9124e-05 - acc: 0.0000e+00 - val_loss: 9.4820e-05 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "13707/13707 [==============================] - 5s - loss: 3.7951e-05 - acc: 0.0000e+00 - val_loss: 2.2827e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00006 MSE (0.01 RMSE)\n",
      "Test Score: 0.00021 MSE (0.01 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_29 (LSTM)               (None, 22, 512)           1058816   \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 22, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_30 (LSTM)               (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 3,190,913\n",
      "Trainable params: 3,190,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13707 samples, validate on 1523 samples\n",
      "Epoch 1/90\n",
      "13707/13707 [==============================] - 7s - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.7127e-04 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "13707/13707 [==============================] - 5s - loss: 1.5277e-04 - acc: 0.0000e+00 - val_loss: 5.1752e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "13707/13707 [==============================] - 5s - loss: 1.1383e-04 - acc: 0.0000e+00 - val_loss: 3.1569e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "13707/13707 [==============================] - 5s - loss: 8.3033e-05 - acc: 0.0000e+00 - val_loss: 2.9547e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "13707/13707 [==============================] - 5s - loss: 8.4735e-05 - acc: 0.0000e+00 - val_loss: 3.0643e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.5323e-05 - acc: 0.0000e+00 - val_loss: 2.4925e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "13707/13707 [==============================] - 5s - loss: 8.1686e-05 - acc: 0.0000e+00 - val_loss: 2.1852e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.3006e-05 - acc: 0.0000e+00 - val_loss: 2.3519e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.8317e-05 - acc: 0.0000e+00 - val_loss: 2.2700e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.5661e-05 - acc: 0.0000e+00 - val_loss: 2.1559e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.8524e-05 - acc: 0.0000e+00 - val_loss: 2.3825e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.5461e-05 - acc: 0.0000e+00 - val_loss: 3.3604e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.9308e-05 - acc: 0.0000e+00 - val_loss: 2.8185e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.7471e-05 - acc: 0.0000e+00 - val_loss: 2.4124e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.6734e-05 - acc: 0.0000e+00 - val_loss: 1.9131e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.0376e-05 - acc: 0.0000e+00 - val_loss: 1.9164e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.7234e-05 - acc: 0.0000e+00 - val_loss: 1.8514e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.0717e-05 - acc: 0.0000e+00 - val_loss: 3.0114e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.2376e-05 - acc: 0.0000e+00 - val_loss: 2.2846e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.7468e-05 - acc: 0.0000e+00 - val_loss: 1.7822e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.3096e-05 - acc: 0.0000e+00 - val_loss: 2.3393e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.8082e-05 - acc: 0.0000e+00 - val_loss: 3.0920e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "13707/13707 [==============================] - 5s - loss: 8.2944e-05 - acc: 0.0000e+00 - val_loss: 2.0705e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "13707/13707 [==============================] - 5s - loss: 8.1935e-05 - acc: 0.0000e+00 - val_loss: 1.7846e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.6712e-05 - acc: 0.0000e+00 - val_loss: 2.2576e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.5286e-05 - acc: 0.0000e+00 - val_loss: 2.2648e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.5477e-05 - acc: 0.0000e+00 - val_loss: 2.1367e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.6091e-05 - acc: 0.0000e+00 - val_loss: 1.9820e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.1355e-05 - acc: 0.0000e+00 - val_loss: 3.4680e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.4002e-05 - acc: 0.0000e+00 - val_loss: 1.8448e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.4998e-05 - acc: 0.0000e+00 - val_loss: 2.5581e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.3935e-05 - acc: 0.0000e+00 - val_loss: 1.5469e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.4605e-05 - acc: 0.0000e+00 - val_loss: 4.2348e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.3398e-05 - acc: 0.0000e+00 - val_loss: 2.7493e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.8229e-05 - acc: 0.0000e+00 - val_loss: 1.8093e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.2976e-05 - acc: 0.0000e+00 - val_loss: 2.8494e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.0289e-05 - acc: 0.0000e+00 - val_loss: 2.7506e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.9997e-05 - acc: 0.0000e+00 - val_loss: 1.4458e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.7490e-05 - acc: 0.0000e+00 - val_loss: 1.6178e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.5040e-05 - acc: 0.0000e+00 - val_loss: 1.7008e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.9983e-05 - acc: 0.0000e+00 - val_loss: 2.1438e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.7204e-05 - acc: 0.0000e+00 - val_loss: 1.9721e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.6172e-05 - acc: 0.0000e+00 - val_loss: 1.4535e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.8046e-05 - acc: 0.0000e+00 - val_loss: 2.2610e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.0639e-05 - acc: 0.0000e+00 - val_loss: 1.6809e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.6883e-05 - acc: 0.0000e+00 - val_loss: 1.3198e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.2987e-05 - acc: 0.0000e+00 - val_loss: 4.9383e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "13707/13707 [==============================] - 5s - loss: 1.0399e-04 - acc: 0.0000e+00 - val_loss: 4.8208e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.2235e-05 - acc: 0.0000e+00 - val_loss: 1.3547e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.5444e-05 - acc: 0.0000e+00 - val_loss: 1.3129e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.1589e-05 - acc: 0.0000e+00 - val_loss: 2.2130e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.9925e-05 - acc: 0.0000e+00 - val_loss: 1.5910e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.6165e-05 - acc: 0.0000e+00 - val_loss: 3.0870e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.1203e-05 - acc: 0.0000e+00 - val_loss: 1.2229e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.3808e-05 - acc: 0.0000e+00 - val_loss: 1.6088e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.2079e-05 - acc: 0.0000e+00 - val_loss: 1.4262e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.1734e-05 - acc: 0.0000e+00 - val_loss: 2.2540e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.9984e-05 - acc: 0.0000e+00 - val_loss: 2.5313e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.4694e-05 - acc: 0.0000e+00 - val_loss: 1.3746e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.2644e-05 - acc: 0.0000e+00 - val_loss: 1.1615e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.8698e-05 - acc: 0.0000e+00 - val_loss: 1.7441e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.2934e-05 - acc: 0.0000e+00 - val_loss: 1.8039e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.5987e-05 - acc: 0.0000e+00 - val_loss: 1.4653e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.4255e-05 - acc: 0.0000e+00 - val_loss: 1.3370e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.0193e-05 - acc: 0.0000e+00 - val_loss: 1.5693e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.2163e-05 - acc: 0.0000e+00 - val_loss: 1.9438e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.8123e-05 - acc: 0.0000e+00 - val_loss: 3.8878e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.3870e-05 - acc: 0.0000e+00 - val_loss: 1.2966e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.7672e-05 - acc: 0.0000e+00 - val_loss: 1.1231e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.1490e-05 - acc: 0.0000e+00 - val_loss: 1.1473e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.6135e-05 - acc: 0.0000e+00 - val_loss: 1.8271e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.2570e-05 - acc: 0.0000e+00 - val_loss: 1.4970e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "13707/13707 [==============================] - 5s - loss: 3.6103e-05 - acc: 0.0000e+00 - val_loss: 1.0239e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "13707/13707 [==============================] - 5s - loss: 3.6905e-05 - acc: 0.0000e+00 - val_loss: 1.0734e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "13707/13707 [==============================] - 5s - loss: 3.5542e-05 - acc: 0.0000e+00 - val_loss: 1.1453e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.0579e-05 - acc: 0.0000e+00 - val_loss: 2.1340e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.4344e-05 - acc: 0.0000e+00 - val_loss: 2.5877e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "13707/13707 [==============================] - 5s - loss: 3.8096e-05 - acc: 0.0000e+00 - val_loss: 1.3082e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.1058e-05 - acc: 0.0000e+00 - val_loss: 1.3139e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "13707/13707 [==============================] - 5s - loss: 3.9520e-05 - acc: 0.0000e+00 - val_loss: 1.5584e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.0933e-05 - acc: 0.0000e+00 - val_loss: 1.1102e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "13707/13707 [==============================] - 5s - loss: 3.4266e-05 - acc: 0.0000e+00 - val_loss: 1.2612e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "13707/13707 [==============================] - 5s - loss: 3.6913e-05 - acc: 0.0000e+00 - val_loss: 1.1481e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.1322e-05 - acc: 0.0000e+00 - val_loss: 3.3684e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.6055e-05 - acc: 0.0000e+00 - val_loss: 3.4491e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13707/13707 [==============================] - 5s - loss: 4.5288e-05 - acc: 0.0000e+00 - val_loss: 1.2911e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "13707/13707 [==============================] - 5s - loss: 3.6853e-05 - acc: 0.0000e+00 - val_loss: 1.0088e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "13707/13707 [==============================] - 5s - loss: 3.5433e-05 - acc: 0.0000e+00 - val_loss: 1.4986e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.2263e-05 - acc: 0.0000e+00 - val_loss: 4.1180e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00009 MSE (0.01 RMSE)\n",
      "Test Score: 0.00176 MSE (0.04 RMSE)\n"
     ]
    }
   ],
   "source": [
    "stock_name = '^GSPC'\n",
    "seq_len = 22\n",
    "shape = [4, seq_len, 1] # feature, window, output\n",
    "epochs = 90\n",
    "dropout = 0.3\n",
    "neuronlist1 = [32, 64, 128, 256, 512]\n",
    "neuronlist2 = [16, 32, 64]\n",
    "neurons_result = {}\n",
    "\n",
    "for neuron_lstm in neuronlist1:\n",
    "    neurons = [neuron_lstm, neuron_lstm]\n",
    "    for activation in neuronlist2:\n",
    "        neurons.append(activation)\n",
    "        neurons.append(1)\n",
    "        trainScore, testScore = quick_measure(stock_name, seq_len, d, shape, neurons, epochs)\n",
    "        neurons_result[str(neurons)] = testScore\n",
    "        neurons = neurons[:2]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAFgCAYAAACR2P/oAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d8a2e21d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lists = sorted(neurons_result.items())\n",
    "x,y = zip(*lists)\n",
    "\n",
    "plt.title('Finding the best hyperparameter')\n",
    "plt.xlabel('neurons')\n",
    "plt.ylabel('Mean Square Error')\n",
    "\n",
    "plt.bar(range(len(lists)), y, align='center')\n",
    "plt.xticks(range(len(lists)), x)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "12.4 Optimial Dropout value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stock_name = '^GSPC'\n",
    "seq_len = 22\n",
    "shape = [4, seq_len, 1] # feature, window, output\n",
    "neurons = [256, 256, 32, 1]\n",
    "epochs = 90\n",
    "decaylist = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model3(layers, neurons, d, decay):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(neurons[0], input_shape=(layers[1], layers[0]), return_sequences=True))\n",
    "    model.add(Dropout(d))\n",
    "        \n",
    "    model.add(LSTM(neurons[1], input_shape=(layers[1], layers[0]), return_sequences=False))\n",
    "    model.add(Dropout(d))\n",
    "        \n",
    "    model.add(Dense(neurons[2],kernel_initializer=\"uniform\",activation='relu'))        \n",
    "    model.add(Dense(neurons[3],kernel_initializer=\"uniform\",activation='linear'))\n",
    "    # model = load_model('my_LSTM_stock_model1000.h5')\n",
    "    adam = keras.optimizers.Adam(decay=decay)\n",
    "    model.compile(loss='mse',optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def quick_measure(stock_name, seq_len, d, shape, neurons, epochs, decay):\n",
    "    df = get_stock_data(stock_name)\n",
    "    X_train, y_train, X_test, y_test = load_data(df, seq_len)\n",
    "    model = build_model3(shape, neurons, d, decay)\n",
    "    model.fit(X_train, y_train, batch_size=512, epochs=epochs, validation_split=0.1, verbose=1)\n",
    "    # model.save('LSTM_Stock_prediction-20170429.h5')\n",
    "    trainScore, testScore = model_score(model, X_train, y_train, X_test, y_test)\n",
    "    return trainScore, testScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 22, 256)           267264    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 22, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 800,833\n",
      "Trainable params: 800,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13707 samples, validate on 1523 samples\n",
      "Epoch 1/90\n",
      "13707/13707 [==============================] - 3s - loss: 0.0096 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.9971e-04 - acc: 0.0000e+00 - val_loss: 9.5124e-04 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.6762e-04 - acc: 0.0000e+00 - val_loss: 4.3061e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.1391e-04 - acc: 0.0000e+00 - val_loss: 2.6363e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0464e-04 - acc: 0.0000e+00 - val_loss: 2.5376e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.9976e-05 - acc: 0.0000e+00 - val_loss: 2.8067e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0076e-04 - acc: 0.0000e+00 - val_loss: 2.9161e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.6570e-05 - acc: 0.0000e+00 - val_loss: 3.6734e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.7021e-05 - acc: 0.0000e+00 - val_loss: 2.8608e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0084e-04 - acc: 0.0000e+00 - val_loss: 3.0161e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.8751e-05 - acc: 0.0000e+00 - val_loss: 2.4426e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.3156e-05 - acc: 0.0000e+00 - val_loss: 2.6313e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.7150e-05 - acc: 0.0000e+00 - val_loss: 3.9968e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.2144e-05 - acc: 0.0000e+00 - val_loss: 3.5981e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.5790e-05 - acc: 0.0000e+00 - val_loss: 2.5699e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.8017e-05 - acc: 0.0000e+00 - val_loss: 2.1423e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.2350e-05 - acc: 0.0000e+00 - val_loss: 2.0836e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.7951e-05 - acc: 0.0000e+00 - val_loss: 2.1108e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.7052e-05 - acc: 0.0000e+00 - val_loss: 2.8844e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.9517e-05 - acc: 0.0000e+00 - val_loss: 2.0290e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.0339e-05 - acc: 0.0000e+00 - val_loss: 2.0525e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.4393e-05 - acc: 0.0000e+00 - val_loss: 2.2504e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.2508e-05 - acc: 0.0000e+00 - val_loss: 2.3181e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.5132e-05 - acc: 0.0000e+00 - val_loss: 3.1292e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.1110e-04 - acc: 0.0000e+00 - val_loss: 2.2283e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.0209e-05 - acc: 0.0000e+00 - val_loss: 1.8992e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.0738e-05 - acc: 0.0000e+00 - val_loss: 3.0352e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.5860e-05 - acc: 0.0000e+00 - val_loss: 2.3464e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.5625e-05 - acc: 0.0000e+00 - val_loss: 2.0594e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.9275e-05 - acc: 0.0000e+00 - val_loss: 9.0123e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0443e-04 - acc: 0.0000e+00 - val_loss: 3.4180e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.0641e-05 - acc: 0.0000e+00 - val_loss: 1.8530e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.7339e-05 - acc: 0.0000e+00 - val_loss: 4.3907e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.0989e-05 - acc: 0.0000e+00 - val_loss: 2.6665e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.5049e-05 - acc: 0.0000e+00 - val_loss: 1.7362e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.4915e-05 - acc: 0.0000e+00 - val_loss: 1.7969e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.0159e-05 - acc: 0.0000e+00 - val_loss: 2.0300e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.6273e-05 - acc: 0.0000e+00 - val_loss: 1.6514e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.0429e-05 - acc: 0.0000e+00 - val_loss: 2.6663e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.2235e-05 - acc: 0.0000e+00 - val_loss: 2.5903e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.3720e-05 - acc: 0.0000e+00 - val_loss: 4.4130e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.8739e-05 - acc: 0.0000e+00 - val_loss: 1.9534e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.5256e-05 - acc: 0.0000e+00 - val_loss: 3.6655e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.4729e-05 - acc: 0.0000e+00 - val_loss: 1.6224e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.9523e-05 - acc: 0.0000e+00 - val_loss: 2.8440e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.1683e-05 - acc: 0.0000e+00 - val_loss: 1.7170e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.3411e-05 - acc: 0.0000e+00 - val_loss: 8.2892e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.8178e-05 - acc: 0.0000e+00 - val_loss: 1.4692e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13707/13707 [==============================] - 2s - loss: 7.5814e-05 - acc: 0.0000e+00 - val_loss: 2.4876e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.9445e-05 - acc: 0.0000e+00 - val_loss: 3.8789e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.1836e-05 - acc: 0.0000e+00 - val_loss: 1.5367e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.3926e-05 - acc: 0.0000e+00 - val_loss: 2.7854e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.6929e-05 - acc: 0.0000e+00 - val_loss: 1.4532e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.3945e-05 - acc: 0.0000e+00 - val_loss: 1.7865e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.7463e-05 - acc: 0.0000e+00 - val_loss: 2.3209e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.5200e-05 - acc: 0.0000e+00 - val_loss: 3.1266e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.3360e-05 - acc: 0.0000e+00 - val_loss: 1.2950e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.9177e-05 - acc: 0.0000e+00 - val_loss: 1.2804e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.8972e-05 - acc: 0.0000e+00 - val_loss: 1.2780e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.9174e-05 - acc: 0.0000e+00 - val_loss: 2.8267e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.4969e-05 - acc: 0.0000e+00 - val_loss: 1.4337e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.8504e-05 - acc: 0.0000e+00 - val_loss: 2.0099e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.6628e-05 - acc: 0.0000e+00 - val_loss: 1.3458e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.1996e-05 - acc: 0.0000e+00 - val_loss: 1.9122e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.5423e-05 - acc: 0.0000e+00 - val_loss: 1.1486e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.3502e-05 - acc: 0.0000e+00 - val_loss: 3.2193e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.5105e-05 - acc: 0.0000e+00 - val_loss: 1.1420e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.3614e-05 - acc: 0.0000e+00 - val_loss: 2.5536e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.8344e-05 - acc: 0.0000e+00 - val_loss: 1.1503e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.5422e-05 - acc: 0.0000e+00 - val_loss: 1.9232e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.2262e-05 - acc: 0.0000e+00 - val_loss: 1.3578e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.2106e-05 - acc: 0.0000e+00 - val_loss: 1.1637e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.3491e-05 - acc: 0.0000e+00 - val_loss: 1.8309e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.1413e-05 - acc: 0.0000e+00 - val_loss: 2.8359e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.3508e-05 - acc: 0.0000e+00 - val_loss: 3.0983e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.6258e-05 - acc: 0.0000e+00 - val_loss: 1.4627e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.3676e-05 - acc: 0.0000e+00 - val_loss: 1.1554e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.3407e-05 - acc: 0.0000e+00 - val_loss: 1.2454e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.8132e-05 - acc: 0.0000e+00 - val_loss: 1.5967e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.5144e-05 - acc: 0.0000e+00 - val_loss: 1.0517e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.0416e-05 - acc: 0.0000e+00 - val_loss: 1.1141e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.3340e-05 - acc: 0.0000e+00 - val_loss: 1.1488e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.9484e-05 - acc: 0.0000e+00 - val_loss: 1.2796e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.2427e-05 - acc: 0.0000e+00 - val_loss: 2.0774e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.2691e-05 - acc: 0.0000e+00 - val_loss: 1.1299e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.1747e-05 - acc: 0.0000e+00 - val_loss: 1.1372e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.1500e-05 - acc: 0.0000e+00 - val_loss: 1.9972e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7676e-05 - acc: 0.0000e+00 - val_loss: 1.4518e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.9801e-05 - acc: 0.0000e+00 - val_loss: 9.8381e-05 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.7741e-05 - acc: 0.0000e+00 - val_loss: 1.4633e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00004 MSE (0.01 RMSE)\n",
      "Test Score: 0.00088 MSE (0.03 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 22, 256)           267264    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 22, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 800,833\n",
      "Trainable params: 800,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13707 samples, validate on 1523 samples\n",
      "Epoch 1/90\n",
      "13707/13707 [==============================] - 3s - loss: 0.0092 - acc: 0.0000e+00 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.8256e-04 - acc: 0.0000e+00 - val_loss: 8.1101e-04 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.5366e-04 - acc: 0.0000e+00 - val_loss: 3.1798e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0891e-04 - acc: 0.0000e+00 - val_loss: 3.2575e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0238e-04 - acc: 0.0000e+00 - val_loss: 2.6703e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0079e-04 - acc: 0.0000e+00 - val_loss: 2.5591e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13707/13707 [==============================] - 2s - loss: 1.0138e-04 - acc: 0.0000e+00 - val_loss: 3.7100e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.2695e-05 - acc: 0.0000e+00 - val_loss: 2.4905e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.6153e-05 - acc: 0.0000e+00 - val_loss: 3.3920e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0700e-04 - acc: 0.0000e+00 - val_loss: 7.5708e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0424e-04 - acc: 0.0000e+00 - val_loss: 2.3749e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.9004e-05 - acc: 0.0000e+00 - val_loss: 2.8443e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.0934e-05 - acc: 0.0000e+00 - val_loss: 2.3463e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.1447e-05 - acc: 0.0000e+00 - val_loss: 2.9908e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.6838e-05 - acc: 0.0000e+00 - val_loss: 3.3958e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.9393e-05 - acc: 0.0000e+00 - val_loss: 4.2044e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.3394e-05 - acc: 0.0000e+00 - val_loss: 2.1540e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.8999e-05 - acc: 0.0000e+00 - val_loss: 2.2738e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.4233e-05 - acc: 0.0000e+00 - val_loss: 2.1392e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.9782e-05 - acc: 0.0000e+00 - val_loss: 2.6271e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.2909e-04 - acc: 0.0000e+00 - val_loss: 3.8421e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.3530e-04 - acc: 0.0000e+00 - val_loss: 2.1571e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0369e-04 - acc: 0.0000e+00 - val_loss: 2.1362e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.9407e-05 - acc: 0.0000e+00 - val_loss: 2.0226e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.4786e-05 - acc: 0.0000e+00 - val_loss: 1.9642e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.2819e-05 - acc: 0.0000e+00 - val_loss: 1.9500e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.1180e-05 - acc: 0.0000e+00 - val_loss: 2.1563e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.5232e-05 - acc: 0.0000e+00 - val_loss: 1.8377e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.7185e-05 - acc: 0.0000e+00 - val_loss: 1.8985e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.8856e-05 - acc: 0.0000e+00 - val_loss: 1.8619e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.9781e-05 - acc: 0.0000e+00 - val_loss: 1.9165e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.6818e-05 - acc: 0.0000e+00 - val_loss: 2.6004e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.8596e-05 - acc: 0.0000e+00 - val_loss: 2.5281e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.2468e-05 - acc: 0.0000e+00 - val_loss: 1.9832e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.6474e-05 - acc: 0.0000e+00 - val_loss: 1.9304e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.0112e-05 - acc: 0.0000e+00 - val_loss: 1.7216e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.7645e-05 - acc: 0.0000e+00 - val_loss: 3.2050e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.0457e-05 - acc: 0.0000e+00 - val_loss: 1.5872e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.7043e-05 - acc: 0.0000e+00 - val_loss: 1.6433e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.7664e-05 - acc: 0.0000e+00 - val_loss: 5.2738e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.8293e-05 - acc: 0.0000e+00 - val_loss: 1.5302e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.7537e-05 - acc: 0.0000e+00 - val_loss: 1.5549e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.8742e-05 - acc: 0.0000e+00 - val_loss: 3.7045e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.5129e-05 - acc: 0.0000e+00 - val_loss: 1.6734e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.2015e-05 - acc: 0.0000e+00 - val_loss: 7.0733e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.2252e-05 - acc: 0.0000e+00 - val_loss: 1.6818e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.2819e-05 - acc: 0.0000e+00 - val_loss: 1.5123e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.4610e-05 - acc: 0.0000e+00 - val_loss: 5.2177e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.8201e-05 - acc: 0.0000e+00 - val_loss: 3.2360e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.1845e-05 - acc: 0.0000e+00 - val_loss: 2.2444e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.4865e-05 - acc: 0.0000e+00 - val_loss: 1.3318e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.1591e-05 - acc: 0.0000e+00 - val_loss: 1.3488e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.4766e-05 - acc: 0.0000e+00 - val_loss: 1.4807e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.5340e-05 - acc: 0.0000e+00 - val_loss: 2.5732e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.7238e-05 - acc: 0.0000e+00 - val_loss: 1.2861e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.9696e-05 - acc: 0.0000e+00 - val_loss: 2.1080e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7829e-05 - acc: 0.0000e+00 - val_loss: 1.3764e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.8134e-05 - acc: 0.0000e+00 - val_loss: 2.0366e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7774e-05 - acc: 0.0000e+00 - val_loss: 2.2978e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7844e-05 - acc: 0.0000e+00 - val_loss: 4.8241e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.3095e-05 - acc: 0.0000e+00 - val_loss: 1.2141e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.9283e-05 - acc: 0.0000e+00 - val_loss: 1.2102e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13707/13707 [==============================] - 2s - loss: 5.5197e-05 - acc: 0.0000e+00 - val_loss: 1.2746e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.8607e-05 - acc: 0.0000e+00 - val_loss: 2.8203e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.3751e-05 - acc: 0.0000e+00 - val_loss: 3.4747e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.1687e-05 - acc: 0.0000e+00 - val_loss: 1.3186e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.9851e-05 - acc: 0.0000e+00 - val_loss: 4.4105e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.7404e-05 - acc: 0.0000e+00 - val_loss: 1.2459e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.3114e-05 - acc: 0.0000e+00 - val_loss: 1.1743e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7109e-05 - acc: 0.0000e+00 - val_loss: 1.3400e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.4494e-05 - acc: 0.0000e+00 - val_loss: 2.0250e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.3127e-05 - acc: 0.0000e+00 - val_loss: 1.0745e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.5758e-05 - acc: 0.0000e+00 - val_loss: 3.0722e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.5787e-05 - acc: 0.0000e+00 - val_loss: 1.2154e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.4556e-05 - acc: 0.0000e+00 - val_loss: 1.4568e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.5562e-05 - acc: 0.0000e+00 - val_loss: 1.8210e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.1790e-05 - acc: 0.0000e+00 - val_loss: 2.6829e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.9319e-05 - acc: 0.0000e+00 - val_loss: 1.0577e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.8775e-05 - acc: 0.0000e+00 - val_loss: 3.1429e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.9501e-05 - acc: 0.0000e+00 - val_loss: 1.0374e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.2837e-05 - acc: 0.0000e+00 - val_loss: 1.5408e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.3207e-05 - acc: 0.0000e+00 - val_loss: 1.5805e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.1290e-05 - acc: 0.0000e+00 - val_loss: 1.0482e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.3858e-05 - acc: 0.0000e+00 - val_loss: 9.8314e-05 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.0447e-05 - acc: 0.0000e+00 - val_loss: 1.0762e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.4781e-05 - acc: 0.0000e+00 - val_loss: 1.5731e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.3267e-05 - acc: 0.0000e+00 - val_loss: 1.9247e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.3239e-05 - acc: 0.0000e+00 - val_loss: 2.7097e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.5439e-05 - acc: 0.0000e+00 - val_loss: 9.6829e-05 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.6516e-05 - acc: 0.0000e+00 - val_loss: 1.6365e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00004 MSE (0.01 RMSE)\n",
      "Test Score: 0.00095 MSE (0.03 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 22, 256)           267264    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 22, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 800,833\n",
      "Trainable params: 800,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13707 samples, validate on 1523 samples\n",
      "Epoch 1/90\n",
      "13707/13707 [==============================] - 3s - loss: 0.0097 - acc: 0.0000e+00 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.5976e-04 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.5601e-04 - acc: 0.0000e+00 - val_loss: 3.5681e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.9559e-05 - acc: 0.0000e+00 - val_loss: 3.2381e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.7453e-05 - acc: 0.0000e+00 - val_loss: 2.5481e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0121e-04 - acc: 0.0000e+00 - val_loss: 3.7260e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.7361e-05 - acc: 0.0000e+00 - val_loss: 4.5066e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.2133e-05 - acc: 0.0000e+00 - val_loss: 2.3356e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.7933e-05 - acc: 0.0000e+00 - val_loss: 2.3442e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.1118e-05 - acc: 0.0000e+00 - val_loss: 5.7929e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0513e-04 - acc: 0.0000e+00 - val_loss: 2.4238e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.7893e-05 - acc: 0.0000e+00 - val_loss: 2.4874e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.7314e-05 - acc: 0.0000e+00 - val_loss: 2.2907e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.1185e-05 - acc: 0.0000e+00 - val_loss: 2.1640e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.1484e-05 - acc: 0.0000e+00 - val_loss: 2.1719e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.8991e-05 - acc: 0.0000e+00 - val_loss: 2.2344e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.0081e-05 - acc: 0.0000e+00 - val_loss: 2.0081e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.3571e-05 - acc: 0.0000e+00 - val_loss: 3.6580e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.8246e-05 - acc: 0.0000e+00 - val_loss: 2.0586e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.2363e-05 - acc: 0.0000e+00 - val_loss: 2.9250e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13707/13707 [==============================] - 2s - loss: 8.5093e-05 - acc: 0.0000e+00 - val_loss: 3.8989e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.2774e-05 - acc: 0.0000e+00 - val_loss: 1.8704e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.3514e-05 - acc: 0.0000e+00 - val_loss: 1.8411e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0534e-04 - acc: 0.0000e+00 - val_loss: 2.6722e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.9454e-05 - acc: 0.0000e+00 - val_loss: 3.2659e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.8341e-05 - acc: 0.0000e+00 - val_loss: 2.2177e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.5278e-05 - acc: 0.0000e+00 - val_loss: 1.7510e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.6144e-05 - acc: 0.0000e+00 - val_loss: 1.7151e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.9426e-05 - acc: 0.0000e+00 - val_loss: 1.6836e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.2120e-05 - acc: 0.0000e+00 - val_loss: 1.7483e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.5030e-05 - acc: 0.0000e+00 - val_loss: 3.5809e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.2385e-05 - acc: 0.0000e+00 - val_loss: 3.0169e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.2172e-05 - acc: 0.0000e+00 - val_loss: 2.0659e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.3238e-05 - acc: 0.0000e+00 - val_loss: 2.8440e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.6088e-05 - acc: 0.0000e+00 - val_loss: 1.6746e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.7843e-05 - acc: 0.0000e+00 - val_loss: 4.4515e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.3480e-05 - acc: 0.0000e+00 - val_loss: 5.6932e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.7942e-05 - acc: 0.0000e+00 - val_loss: 5.2976e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.7092e-05 - acc: 0.0000e+00 - val_loss: 1.9992e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.8165e-05 - acc: 0.0000e+00 - val_loss: 1.5246e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.9833e-05 - acc: 0.0000e+00 - val_loss: 1.4138e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7650e-05 - acc: 0.0000e+00 - val_loss: 2.3129e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.8872e-05 - acc: 0.0000e+00 - val_loss: 3.5372e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.7170e-05 - acc: 0.0000e+00 - val_loss: 1.3485e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.7536e-05 - acc: 0.0000e+00 - val_loss: 2.4172e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.5894e-05 - acc: 0.0000e+00 - val_loss: 1.4608e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.1841e-05 - acc: 0.0000e+00 - val_loss: 1.4294e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.5795e-05 - acc: 0.0000e+00 - val_loss: 1.6423e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.6395e-05 - acc: 0.0000e+00 - val_loss: 1.3865e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.8289e-05 - acc: 0.0000e+00 - val_loss: 1.4282e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.1434e-05 - acc: 0.0000e+00 - val_loss: 1.5099e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.2944e-05 - acc: 0.0000e+00 - val_loss: 2.9978e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.8214e-05 - acc: 0.0000e+00 - val_loss: 2.4891e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.1692e-05 - acc: 0.0000e+00 - val_loss: 3.7856e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.0267e-05 - acc: 0.0000e+00 - val_loss: 1.4824e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.1339e-05 - acc: 0.0000e+00 - val_loss: 2.9513e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.9967e-05 - acc: 0.0000e+00 - val_loss: 1.2111e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.4982e-05 - acc: 0.0000e+00 - val_loss: 2.1350e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.0860e-05 - acc: 0.0000e+00 - val_loss: 2.5726e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.7601e-05 - acc: 0.0000e+00 - val_loss: 2.5236e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.3873e-05 - acc: 0.0000e+00 - val_loss: 3.9370e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.1761e-05 - acc: 0.0000e+00 - val_loss: 1.5690e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7843e-05 - acc: 0.0000e+00 - val_loss: 1.5733e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.5916e-05 - acc: 0.0000e+00 - val_loss: 1.9058e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.4232e-05 - acc: 0.0000e+00 - val_loss: 1.1558e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.4099e-05 - acc: 0.0000e+00 - val_loss: 2.2458e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.4222e-05 - acc: 0.0000e+00 - val_loss: 1.0843e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.3210e-05 - acc: 0.0000e+00 - val_loss: 1.1723e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.2572e-05 - acc: 0.0000e+00 - val_loss: 1.1887e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.0937e-05 - acc: 0.0000e+00 - val_loss: 1.7984e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.6628e-05 - acc: 0.0000e+00 - val_loss: 2.8472e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7076e-05 - acc: 0.0000e+00 - val_loss: 1.6231e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.3566e-05 - acc: 0.0000e+00 - val_loss: 1.2079e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.1161e-05 - acc: 0.0000e+00 - val_loss: 1.1606e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.9113e-05 - acc: 0.0000e+00 - val_loss: 1.0836e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.4187e-05 - acc: 0.0000e+00 - val_loss: 1.5054e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13707/13707 [==============================] - 2s - loss: 5.5157e-05 - acc: 0.0000e+00 - val_loss: 2.2662e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.5886e-05 - acc: 0.0000e+00 - val_loss: 1.4599e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.0130e-05 - acc: 0.0000e+00 - val_loss: 2.3498e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.4722e-05 - acc: 0.0000e+00 - val_loss: 9.9896e-05 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.2930e-05 - acc: 0.0000e+00 - val_loss: 1.5012e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.5249e-05 - acc: 0.0000e+00 - val_loss: 9.8496e-05 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.6249e-05 - acc: 0.0000e+00 - val_loss: 2.2127e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7796e-05 - acc: 0.0000e+00 - val_loss: 9.3830e-05 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.0995e-05 - acc: 0.0000e+00 - val_loss: 9.2843e-05 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.1287e-05 - acc: 0.0000e+00 - val_loss: 1.7049e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.4977e-05 - acc: 0.0000e+00 - val_loss: 1.9727e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.5237e-05 - acc: 0.0000e+00 - val_loss: 1.3746e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.2766e-05 - acc: 0.0000e+00 - val_loss: 1.5647e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.4726e-05 - acc: 0.0000e+00 - val_loss: 1.1920e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00003 MSE (0.01 RMSE)\n",
      "Test Score: 0.00097 MSE (0.03 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 22, 256)           267264    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 22, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 800,833\n",
      "Trainable params: 800,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13707 samples, validate on 1523 samples\n",
      "Epoch 1/90\n",
      "13707/13707 [==============================] - 3s - loss: 0.0091 - acc: 0.0000e+00 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.8532e-04 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.6998e-04 - acc: 0.0000e+00 - val_loss: 4.9511e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.1424e-04 - acc: 0.0000e+00 - val_loss: 2.8540e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.9456e-05 - acc: 0.0000e+00 - val_loss: 2.6090e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0292e-04 - acc: 0.0000e+00 - val_loss: 3.0406e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0338e-04 - acc: 0.0000e+00 - val_loss: 2.4874e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.9164e-05 - acc: 0.0000e+00 - val_loss: 2.9635e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0066e-04 - acc: 0.0000e+00 - val_loss: 3.4010e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.4582e-05 - acc: 0.0000e+00 - val_loss: 4.1419e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.2722e-04 - acc: 0.0000e+00 - val_loss: 4.2293e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.2633e-05 - acc: 0.0000e+00 - val_loss: 2.5341e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.6161e-05 - acc: 0.0000e+00 - val_loss: 4.2062e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0293e-04 - acc: 0.0000e+00 - val_loss: 5.8345e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.1634e-04 - acc: 0.0000e+00 - val_loss: 4.6921e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.1195e-04 - acc: 0.0000e+00 - val_loss: 6.1893e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.4967e-05 - acc: 0.0000e+00 - val_loss: 2.8900e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.2649e-05 - acc: 0.0000e+00 - val_loss: 2.9028e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.4130e-05 - acc: 0.0000e+00 - val_loss: 2.5066e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.6026e-05 - acc: 0.0000e+00 - val_loss: 2.3262e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.6568e-05 - acc: 0.0000e+00 - val_loss: 2.2771e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.0991e-05 - acc: 0.0000e+00 - val_loss: 2.7560e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.7311e-05 - acc: 0.0000e+00 - val_loss: 2.9914e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.3989e-05 - acc: 0.0000e+00 - val_loss: 3.5915e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.9285e-05 - acc: 0.0000e+00 - val_loss: 2.3122e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.0527e-05 - acc: 0.0000e+00 - val_loss: 5.8041e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.0016e-05 - acc: 0.0000e+00 - val_loss: 2.8846e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.8078e-05 - acc: 0.0000e+00 - val_loss: 2.2269e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.7552e-05 - acc: 0.0000e+00 - val_loss: 2.3466e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.4169e-05 - acc: 0.0000e+00 - val_loss: 1.7789e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.6272e-05 - acc: 0.0000e+00 - val_loss: 1.7682e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.0435e-05 - acc: 0.0000e+00 - val_loss: 3.0644e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.1662e-05 - acc: 0.0000e+00 - val_loss: 1.8858e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.5242e-05 - acc: 0.0000e+00 - val_loss: 2.3677e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13707/13707 [==============================] - 2s - loss: 7.1747e-05 - acc: 0.0000e+00 - val_loss: 3.3410e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.7700e-05 - acc: 0.0000e+00 - val_loss: 1.6883e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.0560e-05 - acc: 0.0000e+00 - val_loss: 2.5049e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.6507e-05 - acc: 0.0000e+00 - val_loss: 1.7083e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.3928e-05 - acc: 0.0000e+00 - val_loss: 1.9526e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.2799e-05 - acc: 0.0000e+00 - val_loss: 1.5929e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.6002e-05 - acc: 0.0000e+00 - val_loss: 2.3309e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.2619e-05 - acc: 0.0000e+00 - val_loss: 1.6878e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.4697e-05 - acc: 0.0000e+00 - val_loss: 1.5612e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.2225e-05 - acc: 0.0000e+00 - val_loss: 2.7884e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.2596e-05 - acc: 0.0000e+00 - val_loss: 2.1872e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.6545e-05 - acc: 0.0000e+00 - val_loss: 1.5794e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.7569e-05 - acc: 0.0000e+00 - val_loss: 2.7109e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.4149e-05 - acc: 0.0000e+00 - val_loss: 4.4632e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.2331e-05 - acc: 0.0000e+00 - val_loss: 1.6670e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.1636e-05 - acc: 0.0000e+00 - val_loss: 1.4676e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.3903e-05 - acc: 0.0000e+00 - val_loss: 1.4026e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.8715e-05 - acc: 0.0000e+00 - val_loss: 1.5099e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.0270e-05 - acc: 0.0000e+00 - val_loss: 2.2118e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.2111e-05 - acc: 0.0000e+00 - val_loss: 1.4187e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.3227e-05 - acc: 0.0000e+00 - val_loss: 3.8391e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.7735e-05 - acc: 0.0000e+00 - val_loss: 1.3241e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.5664e-05 - acc: 0.0000e+00 - val_loss: 1.6851e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.2702e-05 - acc: 0.0000e+00 - val_loss: 2.4201e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.6366e-05 - acc: 0.0000e+00 - val_loss: 1.4831e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.2369e-05 - acc: 0.0000e+00 - val_loss: 1.5932e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.9695e-05 - acc: 0.0000e+00 - val_loss: 2.2023e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.6680e-05 - acc: 0.0000e+00 - val_loss: 1.2753e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.9521e-05 - acc: 0.0000e+00 - val_loss: 1.6724e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.8762e-05 - acc: 0.0000e+00 - val_loss: 1.9981e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7404e-05 - acc: 0.0000e+00 - val_loss: 1.4628e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.6573e-05 - acc: 0.0000e+00 - val_loss: 3.0014e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.9136e-05 - acc: 0.0000e+00 - val_loss: 2.3782e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.2397e-05 - acc: 0.0000e+00 - val_loss: 1.2704e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.1617e-05 - acc: 0.0000e+00 - val_loss: 1.8304e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.5910e-05 - acc: 0.0000e+00 - val_loss: 2.1911e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.9849e-05 - acc: 0.0000e+00 - val_loss: 1.6517e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.2186e-05 - acc: 0.0000e+00 - val_loss: 1.8863e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.3872e-05 - acc: 0.0000e+00 - val_loss: 1.5176e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.6974e-05 - acc: 0.0000e+00 - val_loss: 1.6810e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.3728e-05 - acc: 0.0000e+00 - val_loss: 2.7726e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7215e-05 - acc: 0.0000e+00 - val_loss: 1.4450e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.9694e-05 - acc: 0.0000e+00 - val_loss: 1.2426e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.3620e-05 - acc: 0.0000e+00 - val_loss: 3.0339e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7609e-05 - acc: 0.0000e+00 - val_loss: 1.1114e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.3223e-05 - acc: 0.0000e+00 - val_loss: 1.1059e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.1391e-05 - acc: 0.0000e+00 - val_loss: 1.1594e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.3599e-05 - acc: 0.0000e+00 - val_loss: 1.7111e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.8745e-05 - acc: 0.0000e+00 - val_loss: 1.4980e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.0925e-05 - acc: 0.0000e+00 - val_loss: 1.4057e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.3174e-05 - acc: 0.0000e+00 - val_loss: 2.9563e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.5521e-05 - acc: 0.0000e+00 - val_loss: 5.5482e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7498e-05 - acc: 0.0000e+00 - val_loss: 1.9768e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.2078e-05 - acc: 0.0000e+00 - val_loss: 1.7648e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.4145e-05 - acc: 0.0000e+00 - val_loss: 3.3260e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.7965e-05 - acc: 0.0000e+00 - val_loss: 3.1280e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00008 MSE (0.01 RMSE)\n",
      "Test Score: 0.00030 MSE (0.02 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 22, 256)           267264    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 22, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 800,833\n",
      "Trainable params: 800,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13707 samples, validate on 1523 samples\n",
      "Epoch 1/90\n",
      "13707/13707 [==============================] - 4s - loss: 0.0087 - acc: 0.0000e+00 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.1415e-04 - acc: 0.0000e+00 - val_loss: 8.5366e-04 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.7658e-04 - acc: 0.0000e+00 - val_loss: 5.3417e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.2861e-04 - acc: 0.0000e+00 - val_loss: 3.5525e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0391e-04 - acc: 0.0000e+00 - val_loss: 3.0271e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0041e-04 - acc: 0.0000e+00 - val_loss: 2.7384e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.3974e-05 - acc: 0.0000e+00 - val_loss: 2.4615e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.5372e-05 - acc: 0.0000e+00 - val_loss: 2.3657e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.8727e-05 - acc: 0.0000e+00 - val_loss: 3.3748e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.5907e-05 - acc: 0.0000e+00 - val_loss: 2.3807e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.7858e-05 - acc: 0.0000e+00 - val_loss: 2.2823e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.7871e-05 - acc: 0.0000e+00 - val_loss: 3.2805e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.0657e-05 - acc: 0.0000e+00 - val_loss: 3.3099e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.7472e-05 - acc: 0.0000e+00 - val_loss: 2.9169e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.5762e-05 - acc: 0.0000e+00 - val_loss: 3.3101e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.7161e-05 - acc: 0.0000e+00 - val_loss: 2.1167e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.7215e-05 - acc: 0.0000e+00 - val_loss: 2.8468e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.2827e-05 - acc: 0.0000e+00 - val_loss: 2.7495e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.5620e-05 - acc: 0.0000e+00 - val_loss: 2.1016e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.0710e-05 - acc: 0.0000e+00 - val_loss: 2.5708e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.1681e-05 - acc: 0.0000e+00 - val_loss: 2.0021e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.8288e-05 - acc: 0.0000e+00 - val_loss: 1.9209e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.9537e-05 - acc: 0.0000e+00 - val_loss: 3.0872e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.9923e-05 - acc: 0.0000e+00 - val_loss: 2.3336e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.3560e-05 - acc: 0.0000e+00 - val_loss: 2.6411e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.2391e-05 - acc: 0.0000e+00 - val_loss: 2.3014e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.7698e-05 - acc: 0.0000e+00 - val_loss: 2.1964e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.6282e-05 - acc: 0.0000e+00 - val_loss: 2.1218e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.8257e-05 - acc: 0.0000e+00 - val_loss: 1.8014e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.2382e-05 - acc: 0.0000e+00 - val_loss: 3.9226e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.9628e-05 - acc: 0.0000e+00 - val_loss: 3.1521e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.7852e-05 - acc: 0.0000e+00 - val_loss: 2.3198e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.0526e-05 - acc: 0.0000e+00 - val_loss: 2.0472e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.1945e-05 - acc: 0.0000e+00 - val_loss: 1.8126e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.7392e-05 - acc: 0.0000e+00 - val_loss: 1.7177e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.1631e-05 - acc: 0.0000e+00 - val_loss: 1.9752e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.2611e-05 - acc: 0.0000e+00 - val_loss: 1.6302e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.2362e-05 - acc: 0.0000e+00 - val_loss: 1.7300e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.6814e-05 - acc: 0.0000e+00 - val_loss: 1.8961e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.3978e-05 - acc: 0.0000e+00 - val_loss: 1.5906e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.1541e-05 - acc: 0.0000e+00 - val_loss: 1.9694e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.2780e-05 - acc: 0.0000e+00 - val_loss: 1.7969e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.5592e-05 - acc: 0.0000e+00 - val_loss: 6.0260e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.0666e-05 - acc: 0.0000e+00 - val_loss: 1.9681e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.8038e-05 - acc: 0.0000e+00 - val_loss: 1.4971e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7789e-05 - acc: 0.0000e+00 - val_loss: 1.5044e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.7911e-05 - acc: 0.0000e+00 - val_loss: 1.4408e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7189e-05 - acc: 0.0000e+00 - val_loss: 1.4096e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.6243e-05 - acc: 0.0000e+00 - val_loss: 2.3207e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.3207e-05 - acc: 0.0000e+00 - val_loss: 8.3994e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.4364e-05 - acc: 0.0000e+00 - val_loss: 1.5283e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.1243e-05 - acc: 0.0000e+00 - val_loss: 1.6080e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.8987e-05 - acc: 0.0000e+00 - val_loss: 1.6275e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.2855e-05 - acc: 0.0000e+00 - val_loss: 1.5124e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.6353e-05 - acc: 0.0000e+00 - val_loss: 1.9070e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7199e-05 - acc: 0.0000e+00 - val_loss: 1.2694e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13707/13707 [==============================] - 2s - loss: 5.7924e-05 - acc: 0.0000e+00 - val_loss: 1.3883e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.0982e-05 - acc: 0.0000e+00 - val_loss: 1.2470e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.4123e-05 - acc: 0.0000e+00 - val_loss: 3.0393e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.0255e-05 - acc: 0.0000e+00 - val_loss: 1.2217e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.0869e-05 - acc: 0.0000e+00 - val_loss: 2.9455e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.3115e-05 - acc: 0.0000e+00 - val_loss: 4.5479e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.8738e-05 - acc: 0.0000e+00 - val_loss: 1.2865e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.6346e-05 - acc: 0.0000e+00 - val_loss: 1.4040e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.3547e-05 - acc: 0.0000e+00 - val_loss: 1.1660e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.3800e-05 - acc: 0.0000e+00 - val_loss: 1.1561e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.0362e-05 - acc: 0.0000e+00 - val_loss: 1.1884e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.7079e-05 - acc: 0.0000e+00 - val_loss: 1.6631e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7320e-05 - acc: 0.0000e+00 - val_loss: 1.3394e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.6134e-05 - acc: 0.0000e+00 - val_loss: 1.8153e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.5765e-05 - acc: 0.0000e+00 - val_loss: 1.5365e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.5729e-05 - acc: 0.0000e+00 - val_loss: 1.3475e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.4938e-05 - acc: 0.0000e+00 - val_loss: 1.2848e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.0702e-05 - acc: 0.0000e+00 - val_loss: 1.0860e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.0337e-05 - acc: 0.0000e+00 - val_loss: 2.0006e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.5754e-05 - acc: 0.0000e+00 - val_loss: 2.3008e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.0447e-05 - acc: 0.0000e+00 - val_loss: 2.2710e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7854e-05 - acc: 0.0000e+00 - val_loss: 1.4160e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.0394e-05 - acc: 0.0000e+00 - val_loss: 1.0915e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.5546e-05 - acc: 0.0000e+00 - val_loss: 1.1012e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.2781e-05 - acc: 0.0000e+00 - val_loss: 1.1446e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.2289e-05 - acc: 0.0000e+00 - val_loss: 1.1915e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.4952e-05 - acc: 0.0000e+00 - val_loss: 1.0331e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.9219e-05 - acc: 0.0000e+00 - val_loss: 1.0030e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7699e-05 - acc: 0.0000e+00 - val_loss: 1.7250e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.3962e-05 - acc: 0.0000e+00 - val_loss: 1.2920e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.4692e-05 - acc: 0.0000e+00 - val_loss: 1.6210e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7002e-05 - acc: 0.0000e+00 - val_loss: 2.4652e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.4852e-05 - acc: 0.0000e+00 - val_loss: 3.4827e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.5465e-05 - acc: 0.0000e+00 - val_loss: 1.0574e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00003 MSE (0.01 RMSE)\n",
      "Test Score: 0.00029 MSE (0.02 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_11 (LSTM)               (None, 22, 256)           267264    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 22, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 800,833\n",
      "Trainable params: 800,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13707 samples, validate on 1523 samples\n",
      "Epoch 1/90\n",
      "13707/13707 [==============================] - 4s - loss: 0.0081 - acc: 0.0000e+00 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.1456e-04 - acc: 0.0000e+00 - val_loss: 9.1136e-04 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.6981e-04 - acc: 0.0000e+00 - val_loss: 4.7816e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.1657e-04 - acc: 0.0000e+00 - val_loss: 2.8799e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0487e-04 - acc: 0.0000e+00 - val_loss: 2.5939e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.9454e-05 - acc: 0.0000e+00 - val_loss: 4.3090e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0192e-04 - acc: 0.0000e+00 - val_loss: 4.8383e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.5814e-05 - acc: 0.0000e+00 - val_loss: 2.5570e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.1985e-05 - acc: 0.0000e+00 - val_loss: 2.2465e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.2667e-05 - acc: 0.0000e+00 - val_loss: 2.6702e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.2538e-05 - acc: 0.0000e+00 - val_loss: 2.2054e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.1159e-04 - acc: 0.0000e+00 - val_loss: 2.9043e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.5862e-05 - acc: 0.0000e+00 - val_loss: 2.8272e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.2476e-05 - acc: 0.0000e+00 - val_loss: 2.8687e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13707/13707 [==============================] - 2s - loss: 8.4456e-05 - acc: 0.0000e+00 - val_loss: 2.3465e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.1257e-04 - acc: 0.0000e+00 - val_loss: 4.1878e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0567e-04 - acc: 0.0000e+00 - val_loss: 4.0021e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.5394e-05 - acc: 0.0000e+00 - val_loss: 4.3484e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.7117e-05 - acc: 0.0000e+00 - val_loss: 2.1213e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.6638e-05 - acc: 0.0000e+00 - val_loss: 2.6007e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.8425e-05 - acc: 0.0000e+00 - val_loss: 1.9956e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.4926e-05 - acc: 0.0000e+00 - val_loss: 2.2068e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.1132e-05 - acc: 0.0000e+00 - val_loss: 2.9505e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.8343e-05 - acc: 0.0000e+00 - val_loss: 2.0772e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.7583e-05 - acc: 0.0000e+00 - val_loss: 4.8171e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.7447e-05 - acc: 0.0000e+00 - val_loss: 2.8604e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.8953e-05 - acc: 0.0000e+00 - val_loss: 2.1970e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.8818e-05 - acc: 0.0000e+00 - val_loss: 1.7411e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.0202e-05 - acc: 0.0000e+00 - val_loss: 6.0350e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.4326e-05 - acc: 0.0000e+00 - val_loss: 1.6751e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.1446e-05 - acc: 0.0000e+00 - val_loss: 3.1462e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.8804e-05 - acc: 0.0000e+00 - val_loss: 3.3739e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.8404e-05 - acc: 0.0000e+00 - val_loss: 1.7078e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.5200e-05 - acc: 0.0000e+00 - val_loss: 3.7082e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.2731e-05 - acc: 0.0000e+00 - val_loss: 3.4256e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0465e-04 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.1360e-04 - acc: 0.0000e+00 - val_loss: 1.6271e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.7762e-05 - acc: 0.0000e+00 - val_loss: 1.6823e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.5478e-05 - acc: 0.0000e+00 - val_loss: 1.8252e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.7808e-05 - acc: 0.0000e+00 - val_loss: 1.5045e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.9716e-05 - acc: 0.0000e+00 - val_loss: 1.9515e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.8550e-05 - acc: 0.0000e+00 - val_loss: 2.7059e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.0214e-05 - acc: 0.0000e+00 - val_loss: 2.8426e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.6153e-05 - acc: 0.0000e+00 - val_loss: 1.7619e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.8850e-05 - acc: 0.0000e+00 - val_loss: 4.0076e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.7529e-05 - acc: 0.0000e+00 - val_loss: 5.0161e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.6740e-05 - acc: 0.0000e+00 - val_loss: 1.3485e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.1925e-05 - acc: 0.0000e+00 - val_loss: 2.7203e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.1200e-05 - acc: 0.0000e+00 - val_loss: 1.8761e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.5567e-05 - acc: 0.0000e+00 - val_loss: 1.2969e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.5582e-05 - acc: 0.0000e+00 - val_loss: 2.7729e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.0537e-05 - acc: 0.0000e+00 - val_loss: 2.0104e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.1842e-05 - acc: 0.0000e+00 - val_loss: 1.2778e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7110e-05 - acc: 0.0000e+00 - val_loss: 1.2425e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.5141e-05 - acc: 0.0000e+00 - val_loss: 1.8105e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.0328e-05 - acc: 0.0000e+00 - val_loss: 1.2462e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.9654e-05 - acc: 0.0000e+00 - val_loss: 1.4138e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.6570e-05 - acc: 0.0000e+00 - val_loss: 1.6054e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.3264e-05 - acc: 0.0000e+00 - val_loss: 1.3114e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.1937e-05 - acc: 0.0000e+00 - val_loss: 2.3115e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.2919e-05 - acc: 0.0000e+00 - val_loss: 1.7624e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7878e-05 - acc: 0.0000e+00 - val_loss: 3.5888e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.5688e-05 - acc: 0.0000e+00 - val_loss: 1.6203e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.2449e-05 - acc: 0.0000e+00 - val_loss: 3.7035e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.5682e-05 - acc: 0.0000e+00 - val_loss: 1.1483e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.3647e-05 - acc: 0.0000e+00 - val_loss: 1.1096e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.5659e-05 - acc: 0.0000e+00 - val_loss: 1.5686e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.4935e-05 - acc: 0.0000e+00 - val_loss: 2.2927e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.8289e-05 - acc: 0.0000e+00 - val_loss: 1.0923e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.9637e-05 - acc: 0.0000e+00 - val_loss: 1.1859e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.0517e-05 - acc: 0.0000e+00 - val_loss: 1.3392e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13707/13707 [==============================] - 2s - loss: 5.4285e-05 - acc: 0.0000e+00 - val_loss: 1.0557e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.2575e-05 - acc: 0.0000e+00 - val_loss: 1.2703e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7853e-05 - acc: 0.0000e+00 - val_loss: 3.2244e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.9638e-05 - acc: 0.0000e+00 - val_loss: 1.1982e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.3540e-05 - acc: 0.0000e+00 - val_loss: 1.8460e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.0959e-05 - acc: 0.0000e+00 - val_loss: 1.7797e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.2776e-05 - acc: 0.0000e+00 - val_loss: 1.2487e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.8955e-05 - acc: 0.0000e+00 - val_loss: 1.0958e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.1398e-05 - acc: 0.0000e+00 - val_loss: 1.1631e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.4026e-05 - acc: 0.0000e+00 - val_loss: 1.0017e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.0783e-05 - acc: 0.0000e+00 - val_loss: 1.2083e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7798e-05 - acc: 0.0000e+00 - val_loss: 1.0307e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.4225e-05 - acc: 0.0000e+00 - val_loss: 1.4815e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.8116e-05 - acc: 0.0000e+00 - val_loss: 1.5598e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.6932e-05 - acc: 0.0000e+00 - val_loss: 9.7140e-05 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.8846e-05 - acc: 0.0000e+00 - val_loss: 1.2312e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7294e-05 - acc: 0.0000e+00 - val_loss: 1.7070e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.1661e-05 - acc: 0.0000e+00 - val_loss: 9.4458e-05 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.8177e-05 - acc: 0.0000e+00 - val_loss: 4.7858e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00011 MSE (0.01 RMSE)\n",
      "Test Score: 0.00211 MSE (0.05 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_13 (LSTM)               (None, 22, 256)           267264    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 22, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 800,833\n",
      "Trainable params: 800,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13707 samples, validate on 1523 samples\n",
      "Epoch 1/90\n",
      "13707/13707 [==============================] - 4s - loss: 0.0093 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.7515e-04 - acc: 0.0000e+00 - val_loss: 8.2352e-04 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.6541e-04 - acc: 0.0000e+00 - val_loss: 4.0907e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.1601e-04 - acc: 0.0000e+00 - val_loss: 3.2187e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0069e-04 - acc: 0.0000e+00 - val_loss: 2.4934e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0645e-04 - acc: 0.0000e+00 - val_loss: 2.5003e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.5946e-05 - acc: 0.0000e+00 - val_loss: 2.5442e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0227e-04 - acc: 0.0000e+00 - val_loss: 2.4198e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.8026e-05 - acc: 0.0000e+00 - val_loss: 3.3051e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.6876e-05 - acc: 0.0000e+00 - val_loss: 2.4651e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.4705e-05 - acc: 0.0000e+00 - val_loss: 2.2779e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0161e-04 - acc: 0.0000e+00 - val_loss: 3.3065e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.7635e-05 - acc: 0.0000e+00 - val_loss: 4.0036e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.4760e-05 - acc: 0.0000e+00 - val_loss: 2.2009e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.2340e-05 - acc: 0.0000e+00 - val_loss: 2.7301e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.5117e-05 - acc: 0.0000e+00 - val_loss: 2.0635e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.9751e-05 - acc: 0.0000e+00 - val_loss: 6.3821e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.5920e-05 - acc: 0.0000e+00 - val_loss: 4.7921e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.3066e-05 - acc: 0.0000e+00 - val_loss: 2.0321e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.4798e-05 - acc: 0.0000e+00 - val_loss: 2.7559e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.5492e-05 - acc: 0.0000e+00 - val_loss: 8.6333e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.1398e-04 - acc: 0.0000e+00 - val_loss: 2.9354e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.1906e-05 - acc: 0.0000e+00 - val_loss: 1.9962e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.8245e-05 - acc: 0.0000e+00 - val_loss: 3.2042e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.0496e-05 - acc: 0.0000e+00 - val_loss: 2.1369e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.0660e-05 - acc: 0.0000e+00 - val_loss: 2.9584e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.8560e-05 - acc: 0.0000e+00 - val_loss: 1.7980e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.3497e-05 - acc: 0.0000e+00 - val_loss: 1.8602e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.5271e-05 - acc: 0.0000e+00 - val_loss: 2.6449e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13707/13707 [==============================] - 2s - loss: 7.4977e-05 - acc: 0.0000e+00 - val_loss: 2.3587e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.9825e-05 - acc: 0.0000e+00 - val_loss: 1.9400e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.9258e-05 - acc: 0.0000e+00 - val_loss: 1.8559e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.1830e-04 - acc: 0.0000e+00 - val_loss: 8.1235e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.8482e-05 - acc: 0.0000e+00 - val_loss: 4.1811e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.9037e-05 - acc: 0.0000e+00 - val_loss: 1.6783e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.4977e-05 - acc: 0.0000e+00 - val_loss: 2.3832e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.8094e-05 - acc: 0.0000e+00 - val_loss: 1.9111e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.4825e-05 - acc: 0.0000e+00 - val_loss: 1.6608e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.0265e-05 - acc: 0.0000e+00 - val_loss: 2.6185e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.4451e-05 - acc: 0.0000e+00 - val_loss: 2.0298e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.3787e-05 - acc: 0.0000e+00 - val_loss: 2.8096e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.0826e-05 - acc: 0.0000e+00 - val_loss: 2.5993e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.5082e-05 - acc: 0.0000e+00 - val_loss: 1.4204e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.8851e-05 - acc: 0.0000e+00 - val_loss: 7.4873e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.3983e-05 - acc: 0.0000e+00 - val_loss: 1.4385e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.9962e-05 - acc: 0.0000e+00 - val_loss: 1.5631e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.1622e-05 - acc: 0.0000e+00 - val_loss: 2.1488e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.1233e-05 - acc: 0.0000e+00 - val_loss: 1.3621e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.8331e-05 - acc: 0.0000e+00 - val_loss: 1.4222e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.8201e-05 - acc: 0.0000e+00 - val_loss: 1.3309e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7586e-05 - acc: 0.0000e+00 - val_loss: 2.7515e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.6920e-05 - acc: 0.0000e+00 - val_loss: 2.2811e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.6260e-05 - acc: 0.0000e+00 - val_loss: 3.0618e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0120e-04 - acc: 0.0000e+00 - val_loss: 9.1850e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.0978e-05 - acc: 0.0000e+00 - val_loss: 1.6072e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.7193e-05 - acc: 0.0000e+00 - val_loss: 3.9246e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.9220e-05 - acc: 0.0000e+00 - val_loss: 1.3339e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.8442e-05 - acc: 0.0000e+00 - val_loss: 2.5280e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7762e-05 - acc: 0.0000e+00 - val_loss: 1.3152e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.5408e-05 - acc: 0.0000e+00 - val_loss: 1.1862e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.6107e-05 - acc: 0.0000e+00 - val_loss: 1.1992e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.9475e-05 - acc: 0.0000e+00 - val_loss: 2.1318e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7631e-05 - acc: 0.0000e+00 - val_loss: 1.8231e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.8172e-05 - acc: 0.0000e+00 - val_loss: 2.8389e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.1572e-05 - acc: 0.0000e+00 - val_loss: 1.5506e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.9479e-05 - acc: 0.0000e+00 - val_loss: 1.7870e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.5788e-05 - acc: 0.0000e+00 - val_loss: 1.2632e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.3682e-05 - acc: 0.0000e+00 - val_loss: 2.5659e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.3929e-05 - acc: 0.0000e+00 - val_loss: 1.1205e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.2063e-05 - acc: 0.0000e+00 - val_loss: 1.9502e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.2159e-05 - acc: 0.0000e+00 - val_loss: 1.8218e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.5813e-05 - acc: 0.0000e+00 - val_loss: 1.2302e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.5690e-05 - acc: 0.0000e+00 - val_loss: 1.5116e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.4633e-05 - acc: 0.0000e+00 - val_loss: 1.5988e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.2510e-05 - acc: 0.0000e+00 - val_loss: 1.0547e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.4062e-05 - acc: 0.0000e+00 - val_loss: 1.8698e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.9101e-05 - acc: 0.0000e+00 - val_loss: 1.2296e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.0199e-05 - acc: 0.0000e+00 - val_loss: 1.5159e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.3049e-05 - acc: 0.0000e+00 - val_loss: 2.9009e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.0348e-05 - acc: 0.0000e+00 - val_loss: 1.2344e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.4580e-05 - acc: 0.0000e+00 - val_loss: 1.1588e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.1517e-05 - acc: 0.0000e+00 - val_loss: 1.1490e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.1208e-05 - acc: 0.0000e+00 - val_loss: 1.0284e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.1767e-05 - acc: 0.0000e+00 - val_loss: 1.5611e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.5362e-05 - acc: 0.0000e+00 - val_loss: 1.6928e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13707/13707 [==============================] - 2s - loss: 4.9125e-05 - acc: 0.0000e+00 - val_loss: 9.9087e-05 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.2275e-05 - acc: 0.0000e+00 - val_loss: 1.2411e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7377e-05 - acc: 0.0000e+00 - val_loss: 9.6935e-05 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.8645e-05 - acc: 0.0000e+00 - val_loss: 1.1367e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.0339e-05 - acc: 0.0000e+00 - val_loss: 9.9187e-05 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00002 MSE (0.00 RMSE)\n",
      "Test Score: 0.00032 MSE (0.02 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_15 (LSTM)               (None, 22, 256)           267264    \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 22, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_16 (LSTM)               (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 800,833\n",
      "Trainable params: 800,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13707 samples, validate on 1523 samples\n",
      "Epoch 1/90\n",
      "13707/13707 [==============================] - 4s - loss: 0.0076 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "13707/13707 [==============================] - 2s - loss: 3.2717e-04 - acc: 0.0000e+00 - val_loss: 8.9787e-04 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.4513e-04 - acc: 0.0000e+00 - val_loss: 5.5817e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.1342e-04 - acc: 0.0000e+00 - val_loss: 3.4523e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0501e-04 - acc: 0.0000e+00 - val_loss: 3.9843e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.6898e-05 - acc: 0.0000e+00 - val_loss: 2.5642e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.3458e-05 - acc: 0.0000e+00 - val_loss: 2.4315e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.0240e-05 - acc: 0.0000e+00 - val_loss: 4.7265e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.5090e-05 - acc: 0.0000e+00 - val_loss: 3.5475e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0822e-04 - acc: 0.0000e+00 - val_loss: 2.3318e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.0899e-05 - acc: 0.0000e+00 - val_loss: 2.4313e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0028e-04 - acc: 0.0000e+00 - val_loss: 2.1142e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.1086e-05 - acc: 0.0000e+00 - val_loss: 2.0280e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0344e-04 - acc: 0.0000e+00 - val_loss: 2.2314e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.2418e-05 - acc: 0.0000e+00 - val_loss: 2.5189e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.5755e-05 - acc: 0.0000e+00 - val_loss: 3.5955e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.9953e-05 - acc: 0.0000e+00 - val_loss: 4.9581e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.5974e-05 - acc: 0.0000e+00 - val_loss: 3.5981e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.5367e-05 - acc: 0.0000e+00 - val_loss: 2.0966e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.8532e-05 - acc: 0.0000e+00 - val_loss: 2.3643e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.5087e-05 - acc: 0.0000e+00 - val_loss: 3.2514e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.4265e-05 - acc: 0.0000e+00 - val_loss: 2.1215e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.9454e-05 - acc: 0.0000e+00 - val_loss: 2.1580e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.1333e-05 - acc: 0.0000e+00 - val_loss: 1.7174e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.1101e-05 - acc: 0.0000e+00 - val_loss: 1.7274e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.9612e-05 - acc: 0.0000e+00 - val_loss: 2.2224e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.0585e-05 - acc: 0.0000e+00 - val_loss: 1.8395e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.6924e-05 - acc: 0.0000e+00 - val_loss: 8.0402e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.1501e-04 - acc: 0.0000e+00 - val_loss: 2.9249e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.2671e-05 - acc: 0.0000e+00 - val_loss: 1.8500e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.1856e-05 - acc: 0.0000e+00 - val_loss: 3.2243e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.1534e-05 - acc: 0.0000e+00 - val_loss: 2.7769e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.7259e-05 - acc: 0.0000e+00 - val_loss: 1.4778e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.2046e-05 - acc: 0.0000e+00 - val_loss: 1.4549e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.3403e-05 - acc: 0.0000e+00 - val_loss: 4.8680e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.9212e-05 - acc: 0.0000e+00 - val_loss: 4.9474e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.8460e-05 - acc: 0.0000e+00 - val_loss: 2.6525e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.0001e-05 - acc: 0.0000e+00 - val_loss: 1.9230e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.0438e-05 - acc: 0.0000e+00 - val_loss: 1.5627e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.0314e-05 - acc: 0.0000e+00 - val_loss: 1.3995e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.2567e-05 - acc: 0.0000e+00 - val_loss: 2.4090e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.4849e-05 - acc: 0.0000e+00 - val_loss: 1.7694e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.4610e-05 - acc: 0.0000e+00 - val_loss: 1.3227e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13707/13707 [==============================] - 2s - loss: 6.1227e-05 - acc: 0.0000e+00 - val_loss: 2.7145e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.9630e-05 - acc: 0.0000e+00 - val_loss: 1.7365e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.8065e-05 - acc: 0.0000e+00 - val_loss: 2.1107e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.7750e-05 - acc: 0.0000e+00 - val_loss: 2.8291e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.2271e-05 - acc: 0.0000e+00 - val_loss: 1.2929e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.6445e-05 - acc: 0.0000e+00 - val_loss: 1.2971e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7389e-05 - acc: 0.0000e+00 - val_loss: 1.2242e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.3459e-05 - acc: 0.0000e+00 - val_loss: 2.8307e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.2708e-05 - acc: 0.0000e+00 - val_loss: 1.5218e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7934e-05 - acc: 0.0000e+00 - val_loss: 1.4182e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7302e-05 - acc: 0.0000e+00 - val_loss: 1.2976e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7250e-05 - acc: 0.0000e+00 - val_loss: 1.1317e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.9887e-05 - acc: 0.0000e+00 - val_loss: 1.2312e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.8978e-05 - acc: 0.0000e+00 - val_loss: 1.1618e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.1500e-05 - acc: 0.0000e+00 - val_loss: 1.7923e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.6178e-05 - acc: 0.0000e+00 - val_loss: 2.0498e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.0339e-05 - acc: 0.0000e+00 - val_loss: 1.1042e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.7241e-05 - acc: 0.0000e+00 - val_loss: 8.1237e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.2458e-05 - acc: 0.0000e+00 - val_loss: 1.1058e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.8908e-05 - acc: 0.0000e+00 - val_loss: 1.2557e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.0555e-05 - acc: 0.0000e+00 - val_loss: 1.1513e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7249e-05 - acc: 0.0000e+00 - val_loss: 1.5325e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.8317e-05 - acc: 0.0000e+00 - val_loss: 1.1313e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.1441e-05 - acc: 0.0000e+00 - val_loss: 1.5691e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.2008e-05 - acc: 0.0000e+00 - val_loss: 1.0336e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.2628e-05 - acc: 0.0000e+00 - val_loss: 1.1780e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.2414e-05 - acc: 0.0000e+00 - val_loss: 1.4055e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.4445e-05 - acc: 0.0000e+00 - val_loss: 1.0306e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.3058e-05 - acc: 0.0000e+00 - val_loss: 9.8311e-05 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.0017e-05 - acc: 0.0000e+00 - val_loss: 1.1125e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.2722e-05 - acc: 0.0000e+00 - val_loss: 3.0669e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.6908e-05 - acc: 0.0000e+00 - val_loss: 1.3713e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.0460e-05 - acc: 0.0000e+00 - val_loss: 3.2793e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.3584e-05 - acc: 0.0000e+00 - val_loss: 1.4244e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.3897e-05 - acc: 0.0000e+00 - val_loss: 9.8004e-05 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.9604e-05 - acc: 0.0000e+00 - val_loss: 1.1243e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.0011e-05 - acc: 0.0000e+00 - val_loss: 1.0219e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.0205e-05 - acc: 0.0000e+00 - val_loss: 1.3462e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.8980e-05 - acc: 0.0000e+00 - val_loss: 9.2461e-05 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.6185e-05 - acc: 0.0000e+00 - val_loss: 3.4012e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.0219e-05 - acc: 0.0000e+00 - val_loss: 9.1465e-05 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.3921e-05 - acc: 0.0000e+00 - val_loss: 1.1665e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.3642e-05 - acc: 0.0000e+00 - val_loss: 1.3723e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.9346e-05 - acc: 0.0000e+00 - val_loss: 2.1832e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.0757e-05 - acc: 0.0000e+00 - val_loss: 1.3931e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.5030e-05 - acc: 0.0000e+00 - val_loss: 9.8243e-05 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.0222e-05 - acc: 0.0000e+00 - val_loss: 1.8193e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00004 MSE (0.01 RMSE)\n",
      "Test Score: 0.00013 MSE (0.01 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_17 (LSTM)               (None, 22, 256)           267264    \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 22, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 800,833\n",
      "Trainable params: 800,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13707 samples, validate on 1523 samples\n",
      "Epoch 1/90\n",
      "13707/13707 [==============================] - 4s - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13707/13707 [==============================] - 2s - loss: 5.8312e-04 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.8926e-04 - acc: 0.0000e+00 - val_loss: 5.6433e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.1808e-04 - acc: 0.0000e+00 - val_loss: 2.7698e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0705e-04 - acc: 0.0000e+00 - val_loss: 2.5206e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.6845e-05 - acc: 0.0000e+00 - val_loss: 2.4755e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0041e-04 - acc: 0.0000e+00 - val_loss: 2.5016e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.7657e-05 - acc: 0.0000e+00 - val_loss: 4.1486e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.2825e-05 - acc: 0.0000e+00 - val_loss: 2.3159e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.7693e-05 - acc: 0.0000e+00 - val_loss: 2.3847e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.4679e-05 - acc: 0.0000e+00 - val_loss: 2.7945e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.4956e-05 - acc: 0.0000e+00 - val_loss: 3.1660e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.1303e-05 - acc: 0.0000e+00 - val_loss: 5.1561e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.2295e-05 - acc: 0.0000e+00 - val_loss: 4.1299e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.3451e-04 - acc: 0.0000e+00 - val_loss: 3.1633e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.9631e-05 - acc: 0.0000e+00 - val_loss: 2.2248e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.3511e-05 - acc: 0.0000e+00 - val_loss: 2.4374e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.5802e-05 - acc: 0.0000e+00 - val_loss: 3.5801e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0346e-04 - acc: 0.0000e+00 - val_loss: 2.2560e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.2278e-05 - acc: 0.0000e+00 - val_loss: 2.9046e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.1633e-05 - acc: 0.0000e+00 - val_loss: 2.0915e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.2953e-05 - acc: 0.0000e+00 - val_loss: 2.8383e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.1482e-05 - acc: 0.0000e+00 - val_loss: 6.6336e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.7366e-05 - acc: 0.0000e+00 - val_loss: 2.3401e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.7709e-05 - acc: 0.0000e+00 - val_loss: 2.5302e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.3664e-05 - acc: 0.0000e+00 - val_loss: 2.5937e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.0625e-05 - acc: 0.0000e+00 - val_loss: 4.4362e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.0699e-05 - acc: 0.0000e+00 - val_loss: 2.2642e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.4106e-05 - acc: 0.0000e+00 - val_loss: 2.2546e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.5401e-05 - acc: 0.0000e+00 - val_loss: 3.1055e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.6800e-05 - acc: 0.0000e+00 - val_loss: 6.1959e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.9614e-05 - acc: 0.0000e+00 - val_loss: 3.9146e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.0143e-05 - acc: 0.0000e+00 - val_loss: 2.1636e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.6263e-05 - acc: 0.0000e+00 - val_loss: 5.1619e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.7853e-05 - acc: 0.0000e+00 - val_loss: 4.3875e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.7922e-05 - acc: 0.0000e+00 - val_loss: 2.4758e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.7068e-05 - acc: 0.0000e+00 - val_loss: 1.8367e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.3752e-05 - acc: 0.0000e+00 - val_loss: 1.8079e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.7059e-05 - acc: 0.0000e+00 - val_loss: 4.3200e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.6665e-05 - acc: 0.0000e+00 - val_loss: 1.7782e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.6745e-05 - acc: 0.0000e+00 - val_loss: 1.5887e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.2421e-05 - acc: 0.0000e+00 - val_loss: 1.7648e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.8174e-05 - acc: 0.0000e+00 - val_loss: 2.0918e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.3483e-05 - acc: 0.0000e+00 - val_loss: 1.9126e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.7435e-05 - acc: 0.0000e+00 - val_loss: 2.6337e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.9202e-05 - acc: 0.0000e+00 - val_loss: 1.4640e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.2992e-05 - acc: 0.0000e+00 - val_loss: 2.2186e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.7055e-05 - acc: 0.0000e+00 - val_loss: 3.2362e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.1856e-05 - acc: 0.0000e+00 - val_loss: 1.4123e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7745e-05 - acc: 0.0000e+00 - val_loss: 1.4462e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.8545e-05 - acc: 0.0000e+00 - val_loss: 2.5114e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.8693e-05 - acc: 0.0000e+00 - val_loss: 1.3884e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7400e-05 - acc: 0.0000e+00 - val_loss: 1.5266e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.2247e-05 - acc: 0.0000e+00 - val_loss: 1.9716e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.6050e-05 - acc: 0.0000e+00 - val_loss: 1.4846e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.3975e-05 - acc: 0.0000e+00 - val_loss: 1.3953e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.2294e-05 - acc: 0.0000e+00 - val_loss: 1.8993e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.2554e-05 - acc: 0.0000e+00 - val_loss: 1.9759e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13707/13707 [==============================] - 2s - loss: 6.1030e-05 - acc: 0.0000e+00 - val_loss: 1.7050e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7863e-05 - acc: 0.0000e+00 - val_loss: 1.4728e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.3282e-05 - acc: 0.0000e+00 - val_loss: 1.7243e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.9349e-05 - acc: 0.0000e+00 - val_loss: 3.6039e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.9651e-05 - acc: 0.0000e+00 - val_loss: 2.0825e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.0597e-05 - acc: 0.0000e+00 - val_loss: 1.2898e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.2718e-05 - acc: 0.0000e+00 - val_loss: 1.4828e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.4042e-05 - acc: 0.0000e+00 - val_loss: 1.6156e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.9808e-05 - acc: 0.0000e+00 - val_loss: 1.1854e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.2371e-05 - acc: 0.0000e+00 - val_loss: 1.2356e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.1309e-05 - acc: 0.0000e+00 - val_loss: 2.1796e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.2981e-05 - acc: 0.0000e+00 - val_loss: 1.5164e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.5796e-05 - acc: 0.0000e+00 - val_loss: 1.2352e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.2093e-05 - acc: 0.0000e+00 - val_loss: 1.1951e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7571e-05 - acc: 0.0000e+00 - val_loss: 1.1632e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.9525e-05 - acc: 0.0000e+00 - val_loss: 1.3923e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.8469e-05 - acc: 0.0000e+00 - val_loss: 1.6658e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.5210e-05 - acc: 0.0000e+00 - val_loss: 1.1139e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.9432e-05 - acc: 0.0000e+00 - val_loss: 1.2699e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7080e-05 - acc: 0.0000e+00 - val_loss: 2.0950e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.6731e-05 - acc: 0.0000e+00 - val_loss: 1.1186e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.0827e-05 - acc: 0.0000e+00 - val_loss: 1.0592e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.6505e-05 - acc: 0.0000e+00 - val_loss: 1.0586e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.3542e-05 - acc: 0.0000e+00 - val_loss: 1.6861e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.8891e-05 - acc: 0.0000e+00 - val_loss: 1.1325e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.4436e-05 - acc: 0.0000e+00 - val_loss: 2.1753e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.3935e-05 - acc: 0.0000e+00 - val_loss: 1.0524e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.2022e-05 - acc: 0.0000e+00 - val_loss: 1.0605e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.6267e-05 - acc: 0.0000e+00 - val_loss: 1.6398e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.9368e-05 - acc: 0.0000e+00 - val_loss: 2.4312e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.3914e-05 - acc: 0.0000e+00 - val_loss: 2.2220e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.4653e-05 - acc: 0.0000e+00 - val_loss: 1.0274e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00002 MSE (0.00 RMSE)\n",
      "Test Score: 0.00043 MSE (0.02 RMSE)\n"
     ]
    }
   ],
   "source": [
    "decay_result = {}\n",
    "\n",
    "for decay in decaylist:    \n",
    "    trainScore, testScore = quick_measure(stock_name, seq_len, d, shape, neurons, epochs, decay)\n",
    "    decay_result[decay] = testScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ8AAAEWCAYAAAC5XZqEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24c8e1fa438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lists = sorted(decay_result.items())\n",
    "x,y = zip(*lists)\n",
    "plt.plot(x,y)\n",
    "plt.title('Finding the best hyperparameter')\n",
    "plt.xlabel('Decay')\n",
    "plt.ylabel('Mean Square Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stock_name = '^GSPC'\n",
    "neurons = [256, 256, 32, 1]\n",
    "epochs = 90\n",
    "d = 0.3 #dropout\n",
    "decay = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_25 (LSTM)               (None, 5, 256)            267264    \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 5, 256)            0         \n",
      "_________________________________________________________________\n",
      "lstm_26 (LSTM)               (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 800,833\n",
      "Trainable params: 800,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13720 samples, validate on 1525 samples\n",
      "Epoch 1/90\n",
      "13720/13720 [==============================] - 2s - loss: 0.0133 - acc: 0.0000e+00 - val_loss: 0.0103 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "13720/13720 [==============================] - 0s - loss: 4.5234e-04 - acc: 0.0000e+00 - val_loss: 4.6956e-04 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "13720/13720 [==============================] - 0s - loss: 1.1776e-04 - acc: 0.0000e+00 - val_loss: 1.8881e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "13720/13720 [==============================] - 0s - loss: 8.8200e-05 - acc: 0.0000e+00 - val_loss: 1.6826e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "13720/13720 [==============================] - 0s - loss: 8.8609e-05 - acc: 0.0000e+00 - val_loss: 1.5600e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "13720/13720 [==============================] - 0s - loss: 8.7436e-05 - acc: 0.0000e+00 - val_loss: 1.5207e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "13720/13720 [==============================] - 0s - loss: 8.0968e-05 - acc: 0.0000e+00 - val_loss: 1.4416e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "13720/13720 [==============================] - 0s - loss: 7.7619e-05 - acc: 0.0000e+00 - val_loss: 2.2057e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "13720/13720 [==============================] - 0s - loss: 8.2018e-05 - acc: 0.0000e+00 - val_loss: 1.7573e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "13720/13720 [==============================] - 0s - loss: 7.9364e-05 - acc: 0.0000e+00 - val_loss: 1.3402e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "13720/13720 [==============================] - 0s - loss: 7.8890e-05 - acc: 0.0000e+00 - val_loss: 1.3533e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "13720/13720 [==============================] - 0s - loss: 7.7469e-05 - acc: 0.0000e+00 - val_loss: 1.3374e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "13720/13720 [==============================] - 0s - loss: 7.6790e-05 - acc: 0.0000e+00 - val_loss: 1.2136e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "13720/13720 [==============================] - 0s - loss: 6.9505e-05 - acc: 0.0000e+00 - val_loss: 1.2381e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "13720/13720 [==============================] - 0s - loss: 6.8085e-05 - acc: 0.0000e+00 - val_loss: 2.3641e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "13720/13720 [==============================] - 0s - loss: 7.0684e-05 - acc: 0.0000e+00 - val_loss: 1.4684e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "13720/13720 [==============================] - 0s - loss: 7.3419e-05 - acc: 0.0000e+00 - val_loss: 2.4074e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "13720/13720 [==============================] - 0s - loss: 7.4066e-05 - acc: 0.0000e+00 - val_loss: 1.8321e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "13720/13720 [==============================] - 0s - loss: 7.3780e-05 - acc: 0.0000e+00 - val_loss: 2.9133e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "13720/13720 [==============================] - 0s - loss: 7.3692e-05 - acc: 0.0000e+00 - val_loss: 1.3108e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "13720/13720 [==============================] - 0s - loss: 6.2801e-05 - acc: 0.0000e+00 - val_loss: 1.6111e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "13720/13720 [==============================] - 0s - loss: 6.3919e-05 - acc: 0.0000e+00 - val_loss: 1.2159e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "13720/13720 [==============================] - 0s - loss: 6.3783e-05 - acc: 0.0000e+00 - val_loss: 1.6679e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "13720/13720 [==============================] - 0s - loss: 7.1172e-05 - acc: 0.0000e+00 - val_loss: 1.1625e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "13720/13720 [==============================] - 0s - loss: 7.4113e-05 - acc: 0.0000e+00 - val_loss: 1.5632e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "13720/13720 [==============================] - 0s - loss: 6.5915e-05 - acc: 0.0000e+00 - val_loss: 1.2152e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "13720/13720 [==============================] - 0s - loss: 6.8672e-05 - acc: 0.0000e+00 - val_loss: 1.1255e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "13720/13720 [==============================] - 0s - loss: 6.7778e-05 - acc: 0.0000e+00 - val_loss: 1.1642e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "13720/13720 [==============================] - 0s - loss: 5.7351e-05 - acc: 0.0000e+00 - val_loss: 1.1310e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "13720/13720 [==============================] - 0s - loss: 6.1493e-05 - acc: 0.0000e+00 - val_loss: 1.5189e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "13720/13720 [==============================] - 0s - loss: 6.4303e-05 - acc: 0.0000e+00 - val_loss: 1.7046e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "13720/13720 [==============================] - 0s - loss: 6.0373e-05 - acc: 0.0000e+00 - val_loss: 1.1528e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "13720/13720 [==============================] - 0s - loss: 5.8232e-05 - acc: 0.0000e+00 - val_loss: 1.1623e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "13720/13720 [==============================] - 0s - loss: 5.9619e-05 - acc: 0.0000e+00 - val_loss: 1.7583e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "13720/13720 [==============================] - 0s - loss: 6.1861e-05 - acc: 0.0000e+00 - val_loss: 1.1739e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "13720/13720 [==============================] - 0s - loss: 5.7078e-05 - acc: 0.0000e+00 - val_loss: 1.1213e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "13720/13720 [==============================] - 0s - loss: 6.0332e-05 - acc: 0.0000e+00 - val_loss: 1.1146e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "13720/13720 [==============================] - 0s - loss: 5.5830e-05 - acc: 0.0000e+00 - val_loss: 1.0987e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "13720/13720 [==============================] - 0s - loss: 5.7216e-05 - acc: 0.0000e+00 - val_loss: 2.1912e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "13720/13720 [==============================] - 0s - loss: 7.1926e-05 - acc: 0.0000e+00 - val_loss: 1.5963e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "13720/13720 [==============================] - 0s - loss: 5.9467e-05 - acc: 0.0000e+00 - val_loss: 1.3340e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "13720/13720 [==============================] - 0s - loss: 5.6599e-05 - acc: 0.0000e+00 - val_loss: 1.1135e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "13720/13720 [==============================] - 0s - loss: 5.7562e-05 - acc: 0.0000e+00 - val_loss: 1.0762e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "13720/13720 [==============================] - 0s - loss: 5.7619e-05 - acc: 0.0000e+00 - val_loss: 1.1478e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "13720/13720 [==============================] - 0s - loss: 6.3169e-05 - acc: 0.0000e+00 - val_loss: 1.7997e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "13720/13720 [==============================] - 0s - loss: 5.9973e-05 - acc: 0.0000e+00 - val_loss: 1.0907e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "13720/13720 [==============================] - 0s - loss: 5.8368e-05 - acc: 0.0000e+00 - val_loss: 1.7206e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "13720/13720 [==============================] - 0s - loss: 6.2737e-05 - acc: 0.0000e+00 - val_loss: 2.8130e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13720/13720 [==============================] - 0s - loss: 6.4705e-05 - acc: 0.0000e+00 - val_loss: 1.1223e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "13720/13720 [==============================] - 0s - loss: 6.5480e-05 - acc: 0.0000e+00 - val_loss: 1.3953e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "13720/13720 [==============================] - 0s - loss: 5.8361e-05 - acc: 0.0000e+00 - val_loss: 1.6859e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "13720/13720 [==============================] - 0s - loss: 5.7276e-05 - acc: 0.0000e+00 - val_loss: 1.1123e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "13720/13720 [==============================] - 0s - loss: 5.8302e-05 - acc: 0.0000e+00 - val_loss: 1.8325e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "13720/13720 [==============================] - 0s - loss: 5.7336e-05 - acc: 0.0000e+00 - val_loss: 1.1708e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "13720/13720 [==============================] - 0s - loss: 5.0876e-05 - acc: 0.0000e+00 - val_loss: 1.2762e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "13720/13720 [==============================] - 0s - loss: 5.6945e-05 - acc: 0.0000e+00 - val_loss: 1.4402e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "13720/13720 [==============================] - 0s - loss: 5.2740e-05 - acc: 0.0000e+00 - val_loss: 1.0656e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "13720/13720 [==============================] - 0s - loss: 6.1548e-05 - acc: 0.0000e+00 - val_loss: 1.1240e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "13720/13720 [==============================] - 0s - loss: 5.6434e-05 - acc: 0.0000e+00 - val_loss: 1.1401e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "13720/13720 [==============================] - 0s - loss: 5.7637e-05 - acc: 0.0000e+00 - val_loss: 1.1748e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "13720/13720 [==============================] - 0s - loss: 5.4797e-05 - acc: 0.0000e+00 - val_loss: 1.7225e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "13720/13720 [==============================] - 0s - loss: 5.3971e-05 - acc: 0.0000e+00 - val_loss: 1.2344e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "13720/13720 [==============================] - 0s - loss: 5.6766e-05 - acc: 0.0000e+00 - val_loss: 1.0672e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "13720/13720 [==============================] - 0s - loss: 5.4179e-05 - acc: 0.0000e+00 - val_loss: 1.4878e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "13720/13720 [==============================] - 0s - loss: 6.7816e-05 - acc: 0.0000e+00 - val_loss: 1.0719e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "13720/13720 [==============================] - 0s - loss: 1.0279e-04 - acc: 0.0000e+00 - val_loss: 6.2480e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "13720/13720 [==============================] - 0s - loss: 5.6266e-05 - acc: 0.0000e+00 - val_loss: 1.0778e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "13720/13720 [==============================] - 0s - loss: 5.5271e-05 - acc: 0.0000e+00 - val_loss: 2.0993e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "13720/13720 [==============================] - 0s - loss: 5.2928e-05 - acc: 0.0000e+00 - val_loss: 1.3544e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "13720/13720 [==============================] - 0s - loss: 5.2683e-05 - acc: 0.0000e+00 - val_loss: 1.1878e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "13720/13720 [==============================] - 0s - loss: 5.1847e-05 - acc: 0.0000e+00 - val_loss: 1.0900e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "13720/13720 [==============================] - 0s - loss: 5.4010e-05 - acc: 0.0000e+00 - val_loss: 1.0280e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "13720/13720 [==============================] - 0s - loss: 5.9173e-05 - acc: 0.0000e+00 - val_loss: 1.8027e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "13720/13720 [==============================] - 0s - loss: 6.5960e-05 - acc: 0.0000e+00 - val_loss: 3.8704e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "13720/13720 [==============================] - 0s - loss: 5.5644e-05 - acc: 0.0000e+00 - val_loss: 1.3060e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "13720/13720 [==============================] - 0s - loss: 5.2575e-05 - acc: 0.0000e+00 - val_loss: 1.2742e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "13720/13720 [==============================] - 0s - loss: 6.0766e-05 - acc: 0.0000e+00 - val_loss: 4.3813e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "13720/13720 [==============================] - 0s - loss: 6.4911e-05 - acc: 0.0000e+00 - val_loss: 2.3520e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "13720/13720 [==============================] - 0s - loss: 5.3154e-05 - acc: 0.0000e+00 - val_loss: 1.0505e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "13720/13720 [==============================] - 0s - loss: 5.1624e-05 - acc: 0.0000e+00 - val_loss: 1.4355e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "13720/13720 [==============================] - 0s - loss: 5.9910e-05 - acc: 0.0000e+00 - val_loss: 2.5391e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "13720/13720 [==============================] - 0s - loss: 5.5827e-05 - acc: 0.0000e+00 - val_loss: 1.3791e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "13720/13720 [==============================] - 0s - loss: 6.9153e-05 - acc: 0.0000e+00 - val_loss: 1.0508e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "13720/13720 [==============================] - 0s - loss: 5.1211e-05 - acc: 0.0000e+00 - val_loss: 2.3528e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "13720/13720 [==============================] - 0s - loss: 5.4781e-05 - acc: 0.0000e+00 - val_loss: 1.4873e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "13720/13720 [==============================] - 0s - loss: 6.0005e-05 - acc: 0.0000e+00 - val_loss: 1.0435e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "13720/13720 [==============================] - 0s - loss: 6.2114e-05 - acc: 0.0000e+00 - val_loss: 1.9797e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "13720/13720 [==============================] - 0s - loss: 6.3108e-05 - acc: 0.0000e+00 - val_loss: 1.3437e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "13720/13720 [==============================] - 0s - loss: 5.6412e-05 - acc: 0.0000e+00 - val_loss: 1.0824e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "13720/13720 [==============================] - 0s - loss: 5.2609e-05 - acc: 0.0000e+00 - val_loss: 1.0846e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00003 MSE (0.01 RMSE)\n",
      "Test Score: 0.00130 MSE (0.04 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_27 (LSTM)               (None, 10, 256)           267264    \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 10, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_28 (LSTM)               (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 800,833\n",
      "Trainable params: 800,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13716 samples, validate on 1525 samples\n",
      "Epoch 1/90\n",
      "13716/13716 [==============================] - 3s - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0092 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "13716/13716 [==============================] - 1s - loss: 4.8950e-04 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "13716/13716 [==============================] - 1s - loss: 1.5238e-04 - acc: 0.0000e+00 - val_loss: 3.6207e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "13716/13716 [==============================] - 1s - loss: 1.1975e-04 - acc: 0.0000e+00 - val_loss: 3.1507e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "13716/13716 [==============================] - 1s - loss: 1.0238e-04 - acc: 0.0000e+00 - val_loss: 2.6590e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "13716/13716 [==============================] - 1s - loss: 9.1154e-05 - acc: 0.0000e+00 - val_loss: 2.4434e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13716/13716 [==============================] - 1s - loss: 9.1310e-05 - acc: 0.0000e+00 - val_loss: 2.2097e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "13716/13716 [==============================] - 1s - loss: 9.1000e-05 - acc: 0.0000e+00 - val_loss: 2.0048e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "13716/13716 [==============================] - 1s - loss: 8.6275e-05 - acc: 0.0000e+00 - val_loss: 1.8437e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "13716/13716 [==============================] - 1s - loss: 8.0305e-05 - acc: 0.0000e+00 - val_loss: 1.8771e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "13716/13716 [==============================] - 1s - loss: 7.9185e-05 - acc: 0.0000e+00 - val_loss: 2.4136e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "13716/13716 [==============================] - 1s - loss: 8.5153e-05 - acc: 0.0000e+00 - val_loss: 4.1757e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "13716/13716 [==============================] - 1s - loss: 8.9859e-05 - acc: 0.0000e+00 - val_loss: 1.8177e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "13716/13716 [==============================] - 1s - loss: 8.1111e-05 - acc: 0.0000e+00 - val_loss: 2.0934e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "13716/13716 [==============================] - 1s - loss: 7.2279e-05 - acc: 0.0000e+00 - val_loss: 1.7053e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "13716/13716 [==============================] - 1s - loss: 8.6417e-05 - acc: 0.0000e+00 - val_loss: 1.7801e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "13716/13716 [==============================] - 1s - loss: 7.6860e-05 - acc: 0.0000e+00 - val_loss: 1.7378e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "13716/13716 [==============================] - 1s - loss: 7.4620e-05 - acc: 0.0000e+00 - val_loss: 1.9132e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "13716/13716 [==============================] - 1s - loss: 8.2247e-05 - acc: 0.0000e+00 - val_loss: 2.5798e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "13716/13716 [==============================] - 1s - loss: 6.9130e-05 - acc: 0.0000e+00 - val_loss: 2.7919e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "13716/13716 [==============================] - 1s - loss: 7.2663e-05 - acc: 0.0000e+00 - val_loss: 3.4480e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "13716/13716 [==============================] - 1s - loss: 7.4488e-05 - acc: 0.0000e+00 - val_loss: 1.9755e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "13716/13716 [==============================] - 1s - loss: 8.2341e-05 - acc: 0.0000e+00 - val_loss: 1.5849e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "13716/13716 [==============================] - 1s - loss: 6.7933e-05 - acc: 0.0000e+00 - val_loss: 1.6126e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "13716/13716 [==============================] - 1s - loss: 8.5643e-05 - acc: 0.0000e+00 - val_loss: 6.9061e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "13716/13716 [==============================] - 1s - loss: 8.1087e-05 - acc: 0.0000e+00 - val_loss: 3.0849e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "13716/13716 [==============================] - 1s - loss: 8.4726e-05 - acc: 0.0000e+00 - val_loss: 2.7541e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "13716/13716 [==============================] - 1s - loss: 7.6517e-05 - acc: 0.0000e+00 - val_loss: 1.5668e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "13716/13716 [==============================] - 1s - loss: 6.5824e-05 - acc: 0.0000e+00 - val_loss: 3.7286e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "13716/13716 [==============================] - 1s - loss: 6.5436e-05 - acc: 0.0000e+00 - val_loss: 1.5524e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "13716/13716 [==============================] - 1s - loss: 6.4167e-05 - acc: 0.0000e+00 - val_loss: 1.5355e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "13716/13716 [==============================] - 1s - loss: 6.6983e-05 - acc: 0.0000e+00 - val_loss: 1.6298e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "13716/13716 [==============================] - 1s - loss: 7.7354e-05 - acc: 0.0000e+00 - val_loss: 3.4613e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "13716/13716 [==============================] - 1s - loss: 7.3498e-05 - acc: 0.0000e+00 - val_loss: 2.7981e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "13716/13716 [==============================] - 1s - loss: 7.8956e-05 - acc: 0.0000e+00 - val_loss: 3.9050e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "13716/13716 [==============================] - 1s - loss: 7.8364e-05 - acc: 0.0000e+00 - val_loss: 2.1238e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "13716/13716 [==============================] - 1s - loss: 6.4129e-05 - acc: 0.0000e+00 - val_loss: 1.5958e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "13716/13716 [==============================] - 1s - loss: 7.0023e-05 - acc: 0.0000e+00 - val_loss: 1.5196e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "13716/13716 [==============================] - 1s - loss: 6.7777e-05 - acc: 0.0000e+00 - val_loss: 1.4858e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "13716/13716 [==============================] - 1s - loss: 6.3671e-05 - acc: 0.0000e+00 - val_loss: 1.5244e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "13716/13716 [==============================] - 1s - loss: 6.4519e-05 - acc: 0.0000e+00 - val_loss: 1.8142e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "13716/13716 [==============================] - 1s - loss: 6.9225e-05 - acc: 0.0000e+00 - val_loss: 1.4554e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "13716/13716 [==============================] - 1s - loss: 6.3244e-05 - acc: 0.0000e+00 - val_loss: 1.4585e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "13716/13716 [==============================] - 1s - loss: 7.0419e-05 - acc: 0.0000e+00 - val_loss: 1.5498e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "13716/13716 [==============================] - 1s - loss: 6.1104e-05 - acc: 0.0000e+00 - val_loss: 1.4720e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "13716/13716 [==============================] - 1s - loss: 6.1782e-05 - acc: 0.0000e+00 - val_loss: 1.4111e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "13716/13716 [==============================] - 1s - loss: 5.7044e-05 - acc: 0.0000e+00 - val_loss: 1.5670e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "13716/13716 [==============================] - 1s - loss: 6.3134e-05 - acc: 0.0000e+00 - val_loss: 1.5894e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "13716/13716 [==============================] - 1s - loss: 6.8544e-05 - acc: 0.0000e+00 - val_loss: 2.4010e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "13716/13716 [==============================] - 1s - loss: 7.0865e-05 - acc: 0.0000e+00 - val_loss: 2.5393e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "13716/13716 [==============================] - 1s - loss: 6.3668e-05 - acc: 0.0000e+00 - val_loss: 2.1104e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "13716/13716 [==============================] - 1s - loss: 7.2044e-05 - acc: 0.0000e+00 - val_loss: 1.5172e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "13716/13716 [==============================] - 1s - loss: 6.2602e-05 - acc: 0.0000e+00 - val_loss: 1.3998e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "13716/13716 [==============================] - 1s - loss: 6.0878e-05 - acc: 0.0000e+00 - val_loss: 1.5440e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "13716/13716 [==============================] - 1s - loss: 6.7459e-05 - acc: 0.0000e+00 - val_loss: 1.6724e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "13716/13716 [==============================] - 1s - loss: 6.7707e-05 - acc: 0.0000e+00 - val_loss: 3.4987e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "13716/13716 [==============================] - 1s - loss: 7.7660e-05 - acc: 0.0000e+00 - val_loss: 1.9860e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "13716/13716 [==============================] - 1s - loss: 6.5911e-05 - acc: 0.0000e+00 - val_loss: 1.4681e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "13716/13716 [==============================] - 1s - loss: 6.7512e-05 - acc: 0.0000e+00 - val_loss: 1.5411e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "13716/13716 [==============================] - 1s - loss: 5.9704e-05 - acc: 0.0000e+00 - val_loss: 3.8516e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "13716/13716 [==============================] - 1s - loss: 8.2843e-05 - acc: 0.0000e+00 - val_loss: 2.3372e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "13716/13716 [==============================] - 1s - loss: 6.7703e-05 - acc: 0.0000e+00 - val_loss: 1.5339e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13716/13716 [==============================] - 1s - loss: 5.9701e-05 - acc: 0.0000e+00 - val_loss: 1.3881e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "13716/13716 [==============================] - 1s - loss: 5.5470e-05 - acc: 0.0000e+00 - val_loss: 1.3168e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "13716/13716 [==============================] - 1s - loss: 5.7555e-05 - acc: 0.0000e+00 - val_loss: 1.5070e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "13716/13716 [==============================] - 1s - loss: 5.7928e-05 - acc: 0.0000e+00 - val_loss: 1.5600e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "13716/13716 [==============================] - 1s - loss: 5.7025e-05 - acc: 0.0000e+00 - val_loss: 1.3148e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "13716/13716 [==============================] - 1s - loss: 5.8403e-05 - acc: 0.0000e+00 - val_loss: 1.7163e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "13716/13716 [==============================] - 1s - loss: 6.5568e-05 - acc: 0.0000e+00 - val_loss: 1.7475e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "13716/13716 [==============================] - 1s - loss: 6.1019e-05 - acc: 0.0000e+00 - val_loss: 1.3092e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "13716/13716 [==============================] - 1s - loss: 5.6455e-05 - acc: 0.0000e+00 - val_loss: 1.2790e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "13716/13716 [==============================] - 1s - loss: 5.1032e-05 - acc: 0.0000e+00 - val_loss: 1.4502e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "13716/13716 [==============================] - 1s - loss: 5.8737e-05 - acc: 0.0000e+00 - val_loss: 1.3741e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "13716/13716 [==============================] - 1s - loss: 5.2087e-05 - acc: 0.0000e+00 - val_loss: 1.2638e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "13716/13716 [==============================] - 1s - loss: 5.7192e-05 - acc: 0.0000e+00 - val_loss: 1.8692e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "13716/13716 [==============================] - 1s - loss: 5.6630e-05 - acc: 0.0000e+00 - val_loss: 1.2412e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "13716/13716 [==============================] - 1s - loss: 6.0956e-05 - acc: 0.0000e+00 - val_loss: 4.0790e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "13716/13716 [==============================] - 1s - loss: 8.4674e-05 - acc: 0.0000e+00 - val_loss: 1.4107e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "13716/13716 [==============================] - 1s - loss: 8.2127e-05 - acc: 0.0000e+00 - val_loss: 3.9263e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "13716/13716 [==============================] - 1s - loss: 8.0728e-05 - acc: 0.0000e+00 - val_loss: 2.2567e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "13716/13716 [==============================] - 1s - loss: 6.3958e-05 - acc: 0.0000e+00 - val_loss: 2.5978e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "13716/13716 [==============================] - 1s - loss: 5.6306e-05 - acc: 0.0000e+00 - val_loss: 2.7395e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "13716/13716 [==============================] - 1s - loss: 5.9988e-05 - acc: 0.0000e+00 - val_loss: 1.3948e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "13716/13716 [==============================] - 1s - loss: 5.5533e-05 - acc: 0.0000e+00 - val_loss: 1.9101e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "13716/13716 [==============================] - 1s - loss: 5.2934e-05 - acc: 0.0000e+00 - val_loss: 1.1903e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "13716/13716 [==============================] - 1s - loss: 5.6167e-05 - acc: 0.0000e+00 - val_loss: 2.2782e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "13716/13716 [==============================] - 1s - loss: 5.9626e-05 - acc: 0.0000e+00 - val_loss: 1.2067e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "13716/13716 [==============================] - 1s - loss: 5.4497e-05 - acc: 0.0000e+00 - val_loss: 2.1044e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "13716/13716 [==============================] - 1s - loss: 5.2280e-05 - acc: 0.0000e+00 - val_loss: 4.2498e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "13716/13716 [==============================] - 1s - loss: 6.0871e-05 - acc: 0.0000e+00 - val_loss: 1.3605e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00003 MSE (0.01 RMSE)\n",
      "Test Score: 0.00070 MSE (0.03 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_29 (LSTM)               (None, 22, 256)           267264    \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 22, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_30 (LSTM)               (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 800,833\n",
      "Trainable params: 800,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13707 samples, validate on 1523 samples\n",
      "Epoch 1/90\n",
      "13707/13707 [==============================] - 4s - loss: 0.0096 - acc: 0.0000e+00 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.0338e-04 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.6358e-04 - acc: 0.0000e+00 - val_loss: 5.4031e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.1044e-04 - acc: 0.0000e+00 - val_loss: 2.8978e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0631e-04 - acc: 0.0000e+00 - val_loss: 2.5664e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0732e-04 - acc: 0.0000e+00 - val_loss: 2.5422e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0700e-04 - acc: 0.0000e+00 - val_loss: 2.6845e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.7306e-05 - acc: 0.0000e+00 - val_loss: 2.9447e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.2567e-05 - acc: 0.0000e+00 - val_loss: 3.6906e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0459e-04 - acc: 0.0000e+00 - val_loss: 3.5827e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.7564e-05 - acc: 0.0000e+00 - val_loss: 2.3008e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.3375e-05 - acc: 0.0000e+00 - val_loss: 2.5130e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.0238e-05 - acc: 0.0000e+00 - val_loss: 3.1320e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.0097e-05 - acc: 0.0000e+00 - val_loss: 3.6435e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.9631e-05 - acc: 0.0000e+00 - val_loss: 3.0493e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.4834e-05 - acc: 0.0000e+00 - val_loss: 2.1693e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.0851e-05 - acc: 0.0000e+00 - val_loss: 2.6372e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.3579e-05 - acc: 0.0000e+00 - val_loss: 2.1661e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.8078e-05 - acc: 0.0000e+00 - val_loss: 6.0257e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.6577e-05 - acc: 0.0000e+00 - val_loss: 6.1517e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13707/13707 [==============================] - 2s - loss: 8.3109e-05 - acc: 0.0000e+00 - val_loss: 2.0343e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.2431e-05 - acc: 0.0000e+00 - val_loss: 1.9113e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.1796e-05 - acc: 0.0000e+00 - val_loss: 4.9820e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.7776e-05 - acc: 0.0000e+00 - val_loss: 8.7579e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0819e-04 - acc: 0.0000e+00 - val_loss: 2.2275e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.0869e-05 - acc: 0.0000e+00 - val_loss: 2.5468e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.7399e-05 - acc: 0.0000e+00 - val_loss: 3.6695e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.4413e-05 - acc: 0.0000e+00 - val_loss: 4.7752e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.3482e-05 - acc: 0.0000e+00 - val_loss: 1.9224e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.3268e-05 - acc: 0.0000e+00 - val_loss: 1.8249e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.9930e-05 - acc: 0.0000e+00 - val_loss: 1.7710e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.3396e-04 - acc: 0.0000e+00 - val_loss: 8.7447e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0981e-04 - acc: 0.0000e+00 - val_loss: 2.0225e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.0163e-05 - acc: 0.0000e+00 - val_loss: 2.2337e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.9133e-05 - acc: 0.0000e+00 - val_loss: 1.8427e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.4249e-05 - acc: 0.0000e+00 - val_loss: 2.0690e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.9830e-05 - acc: 0.0000e+00 - val_loss: 1.8465e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.6182e-05 - acc: 0.0000e+00 - val_loss: 1.5271e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.1117e-05 - acc: 0.0000e+00 - val_loss: 3.1092e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.3630e-05 - acc: 0.0000e+00 - val_loss: 1.8699e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.4434e-05 - acc: 0.0000e+00 - val_loss: 1.8895e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.1581e-05 - acc: 0.0000e+00 - val_loss: 2.9110e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.6274e-05 - acc: 0.0000e+00 - val_loss: 1.5566e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.4637e-05 - acc: 0.0000e+00 - val_loss: 6.4768e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.1862e-05 - acc: 0.0000e+00 - val_loss: 2.9254e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.9357e-05 - acc: 0.0000e+00 - val_loss: 1.6584e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.8475e-05 - acc: 0.0000e+00 - val_loss: 5.3655e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.2943e-05 - acc: 0.0000e+00 - val_loss: 1.7021e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.9721e-05 - acc: 0.0000e+00 - val_loss: 1.3614e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.0734e-05 - acc: 0.0000e+00 - val_loss: 1.5711e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.1704e-05 - acc: 0.0000e+00 - val_loss: 1.3463e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7186e-05 - acc: 0.0000e+00 - val_loss: 1.3573e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.9047e-05 - acc: 0.0000e+00 - val_loss: 1.8992e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.2696e-05 - acc: 0.0000e+00 - val_loss: 1.7688e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.7160e-05 - acc: 0.0000e+00 - val_loss: 3.1347e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.0094e-05 - acc: 0.0000e+00 - val_loss: 2.2745e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.6800e-05 - acc: 0.0000e+00 - val_loss: 1.4116e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.9765e-05 - acc: 0.0000e+00 - val_loss: 4.1499e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.9224e-05 - acc: 0.0000e+00 - val_loss: 1.2130e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.2976e-05 - acc: 0.0000e+00 - val_loss: 1.2258e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.2055e-05 - acc: 0.0000e+00 - val_loss: 1.5383e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.8283e-05 - acc: 0.0000e+00 - val_loss: 4.2818e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.1359e-05 - acc: 0.0000e+00 - val_loss: 1.4343e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.6590e-05 - acc: 0.0000e+00 - val_loss: 1.6401e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.4550e-05 - acc: 0.0000e+00 - val_loss: 1.1309e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.6076e-05 - acc: 0.0000e+00 - val_loss: 1.6766e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.1783e-05 - acc: 0.0000e+00 - val_loss: 1.5469e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.6211e-05 - acc: 0.0000e+00 - val_loss: 1.0848e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7415e-05 - acc: 0.0000e+00 - val_loss: 1.0903e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.6551e-05 - acc: 0.0000e+00 - val_loss: 1.5485e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.1377e-05 - acc: 0.0000e+00 - val_loss: 2.2573e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.5689e-05 - acc: 0.0000e+00 - val_loss: 4.5697e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7639e-05 - acc: 0.0000e+00 - val_loss: 1.1830e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.0664e-05 - acc: 0.0000e+00 - val_loss: 1.0969e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.9571e-05 - acc: 0.0000e+00 - val_loss: 2.2084e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.6089e-05 - acc: 0.0000e+00 - val_loss: 1.0555e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13707/13707 [==============================] - 2s - loss: 5.3151e-05 - acc: 0.0000e+00 - val_loss: 1.5398e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.4668e-05 - acc: 0.0000e+00 - val_loss: 1.0647e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.4110e-05 - acc: 0.0000e+00 - val_loss: 1.7840e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.2869e-05 - acc: 0.0000e+00 - val_loss: 1.6193e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7827e-05 - acc: 0.0000e+00 - val_loss: 1.2444e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.0090e-05 - acc: 0.0000e+00 - val_loss: 1.1830e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.6312e-05 - acc: 0.0000e+00 - val_loss: 1.0655e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.9841e-05 - acc: 0.0000e+00 - val_loss: 9.7127e-05 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.0071e-05 - acc: 0.0000e+00 - val_loss: 1.8104e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.9592e-05 - acc: 0.0000e+00 - val_loss: 1.2402e-04 - val_acc: 0.0000e+0000e+\n",
      "Epoch 87/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.5382e-05 - acc: 0.0000e+00 - val_loss: 2.4054e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.4348e-05 - acc: 0.0000e+00 - val_loss: 9.7188e-05 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.1847e-05 - acc: 0.0000e+00 - val_loss: 1.0149e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.8408e-05 - acc: 0.0000e+00 - val_loss: 9.3328e-05 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00002 MSE (0.00 RMSE)\n",
      "Test Score: 0.00057 MSE (0.02 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_31 (LSTM)               (None, 60, 256)           267264    \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 60, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_32 (LSTM)               (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 800,833\n",
      "Trainable params: 800,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13676 samples, validate on 1520 samples\n",
      "Epoch 1/90\n",
      "13676/13676 [==============================] - 8s - loss: 0.0084 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "13676/13676 [==============================] - 6s - loss: 2.7248e-04 - acc: 0.0000e+00 - val_loss: 3.5689e-04 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "13676/13676 [==============================] - 6s - loss: 1.0422e-04 - acc: 0.0000e+00 - val_loss: 2.9121e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "13676/13676 [==============================] - 6s - loss: 1.0481e-04 - acc: 0.0000e+00 - val_loss: 2.7056e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "13676/13676 [==============================] - 6s - loss: 1.0170e-04 - acc: 0.0000e+00 - val_loss: 3.5500e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "13676/13676 [==============================] - 6s - loss: 9.6988e-05 - acc: 0.0000e+00 - val_loss: 2.3426e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "13676/13676 [==============================] - 6s - loss: 9.8640e-05 - acc: 0.0000e+00 - val_loss: 2.4875e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "13676/13676 [==============================] - 6s - loss: 8.4036e-05 - acc: 0.0000e+00 - val_loss: 2.4680e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "13676/13676 [==============================] - 6s - loss: 8.3746e-05 - acc: 0.0000e+00 - val_loss: 2.7350e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "13676/13676 [==============================] - 6s - loss: 8.8756e-05 - acc: 0.0000e+00 - val_loss: 2.7643e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "13676/13676 [==============================] - 6s - loss: 1.0011e-04 - acc: 0.0000e+00 - val_loss: 2.1519e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "13676/13676 [==============================] - 6s - loss: 8.2156e-05 - acc: 0.0000e+00 - val_loss: 1.9427e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "13676/13676 [==============================] - 6s - loss: 8.3908e-05 - acc: 0.0000e+00 - val_loss: 2.9803e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "13676/13676 [==============================] - 6s - loss: 8.0122e-05 - acc: 0.0000e+00 - val_loss: 1.8400e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "13676/13676 [==============================] - 6s - loss: 7.8017e-05 - acc: 0.0000e+00 - val_loss: 1.7691e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "13676/13676 [==============================] - 6s - loss: 8.3288e-05 - acc: 0.0000e+00 - val_loss: 1.8869e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "13676/13676 [==============================] - 6s - loss: 9.6624e-05 - acc: 0.0000e+00 - val_loss: 5.7811e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "13676/13676 [==============================] - 6s - loss: 1.1805e-04 - acc: 0.0000e+00 - val_loss: 6.7952e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "13676/13676 [==============================] - 6s - loss: 9.5846e-05 - acc: 0.0000e+00 - val_loss: 3.6331e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "13676/13676 [==============================] - 6s - loss: 7.7151e-05 - acc: 0.0000e+00 - val_loss: 2.5769e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "13676/13676 [==============================] - 6s - loss: 7.6016e-05 - acc: 0.0000e+00 - val_loss: 1.6514e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "13676/13676 [==============================] - 6s - loss: 6.5420e-05 - acc: 0.0000e+00 - val_loss: 2.4318e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "13676/13676 [==============================] - 6s - loss: 6.6187e-05 - acc: 0.0000e+00 - val_loss: 1.7297e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "13676/13676 [==============================] - 6s - loss: 6.5685e-05 - acc: 0.0000e+00 - val_loss: 1.5182e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "13676/13676 [==============================] - 6s - loss: 7.0885e-05 - acc: 0.0000e+00 - val_loss: 1.6147e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "13676/13676 [==============================] - 6s - loss: 6.9420e-05 - acc: 0.0000e+00 - val_loss: 1.4672e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "13676/13676 [==============================] - 6s - loss: 7.4088e-05 - acc: 0.0000e+00 - val_loss: 1.8074e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "13676/13676 [==============================] - 6s - loss: 6.2291e-05 - acc: 0.0000e+00 - val_loss: 2.3920e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "13676/13676 [==============================] - 6s - loss: 7.1535e-05 - acc: 0.0000e+00 - val_loss: 4.3298e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "13676/13676 [==============================] - 6s - loss: 7.0425e-05 - acc: 0.0000e+00 - val_loss: 3.4583e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "13676/13676 [==============================] - 6s - loss: 7.6407e-05 - acc: 0.0000e+00 - val_loss: 1.7762e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "13676/13676 [==============================] - 6s - loss: 6.4939e-05 - acc: 0.0000e+00 - val_loss: 2.7031e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "13676/13676 [==============================] - 6s - loss: 6.6270e-05 - acc: 0.0000e+00 - val_loss: 2.3552e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "13676/13676 [==============================] - 6s - loss: 7.1337e-05 - acc: 0.0000e+00 - val_loss: 1.3107e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13676/13676 [==============================] - 6s - loss: 7.1398e-05 - acc: 0.0000e+00 - val_loss: 1.2726e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "13676/13676 [==============================] - 6s - loss: 6.5292e-05 - acc: 0.0000e+00 - val_loss: 1.7028e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "13676/13676 [==============================] - 6s - loss: 6.3492e-05 - acc: 0.0000e+00 - val_loss: 1.3615e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "13676/13676 [==============================] - 6s - loss: 6.0024e-05 - acc: 0.0000e+00 - val_loss: 1.9519e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "13676/13676 [==============================] - 6s - loss: 6.5094e-05 - acc: 0.0000e+00 - val_loss: 2.1089e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "13676/13676 [==============================] - 6s - loss: 6.5635e-05 - acc: 0.0000e+00 - val_loss: 3.5169e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "13676/13676 [==============================] - 6s - loss: 6.7866e-05 - acc: 0.0000e+00 - val_loss: 2.2524e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "13676/13676 [==============================] - 6s - loss: 5.9040e-05 - acc: 0.0000e+00 - val_loss: 1.4868e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "13676/13676 [==============================] - 6s - loss: 6.0647e-05 - acc: 0.0000e+00 - val_loss: 1.4703e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "13676/13676 [==============================] - 6s - loss: 6.0363e-05 - acc: 0.0000e+00 - val_loss: 1.8940e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "13676/13676 [==============================] - 6s - loss: 6.5200e-05 - acc: 0.0000e+00 - val_loss: 1.5826e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "13676/13676 [==============================] - 6s - loss: 5.5706e-05 - acc: 0.0000e+00 - val_loss: 1.1612e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "13676/13676 [==============================] - 6s - loss: 5.8658e-05 - acc: 0.0000e+00 - val_loss: 1.4448e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "13676/13676 [==============================] - 6s - loss: 5.7370e-05 - acc: 0.0000e+00 - val_loss: 1.5604e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "13676/13676 [==============================] - 6s - loss: 6.3057e-05 - acc: 0.0000e+00 - val_loss: 5.8358e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "13676/13676 [==============================] - 6s - loss: 1.1588e-04 - acc: 0.0000e+00 - val_loss: 9.4144e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "13676/13676 [==============================] - 6s - loss: 8.8303e-05 - acc: 0.0000e+00 - val_loss: 3.3450e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "13676/13676 [==============================] - 6s - loss: 6.0488e-05 - acc: 0.0000e+00 - val_loss: 1.9126e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "13676/13676 [==============================] - 6s - loss: 5.8730e-05 - acc: 0.0000e+00 - val_loss: 1.5351e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "13676/13676 [==============================] - 6s - loss: 5.5843e-05 - acc: 0.0000e+00 - val_loss: 1.4139e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "13676/13676 [==============================] - 6s - loss: 6.5757e-05 - acc: 0.0000e+00 - val_loss: 1.1203e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "13676/13676 [==============================] - 6s - loss: 6.1407e-05 - acc: 0.0000e+00 - val_loss: 1.9490e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "13676/13676 [==============================] - 6s - loss: 5.7071e-05 - acc: 0.0000e+00 - val_loss: 1.0850e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "13676/13676 [==============================] - 6s - loss: 5.4125e-05 - acc: 0.0000e+00 - val_loss: 4.3498e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "13676/13676 [==============================] - 6s - loss: 7.5769e-05 - acc: 0.0000e+00 - val_loss: 1.8514e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "13676/13676 [==============================] - 6s - loss: 5.6348e-05 - acc: 0.0000e+00 - val_loss: 1.1854e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "13676/13676 [==============================] - 6s - loss: 5.8194e-05 - acc: 0.0000e+00 - val_loss: 1.7838e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "13676/13676 [==============================] - 6s - loss: 5.7426e-05 - acc: 0.0000e+00 - val_loss: 1.1236e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "13676/13676 [==============================] - 6s - loss: 6.3834e-05 - acc: 0.0000e+00 - val_loss: 2.4864e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "13676/13676 [==============================] - 6s - loss: 5.9942e-05 - acc: 0.0000e+00 - val_loss: 1.9181e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "13676/13676 [==============================] - 6s - loss: 6.3122e-05 - acc: 0.0000e+00 - val_loss: 1.6537e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "13676/13676 [==============================] - 6s - loss: 5.9516e-05 - acc: 0.0000e+00 - val_loss: 2.3519e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "13676/13676 [==============================] - 6s - loss: 5.5016e-05 - acc: 0.0000e+00 - val_loss: 1.2309e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "13676/13676 [==============================] - 6s - loss: 5.2601e-05 - acc: 0.0000e+00 - val_loss: 9.9239e-05 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "13676/13676 [==============================] - 6s - loss: 5.6247e-05 - acc: 0.0000e+00 - val_loss: 1.0302e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "13676/13676 [==============================] - 6s - loss: 5.1336e-05 - acc: 0.0000e+00 - val_loss: 1.4021e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "13676/13676 [==============================] - 6s - loss: 5.5450e-05 - acc: 0.0000e+00 - val_loss: 1.0187e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "13676/13676 [==============================] - 6s - loss: 5.3208e-05 - acc: 0.0000e+00 - val_loss: 1.0006e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "13676/13676 [==============================] - 6s - loss: 5.3208e-05 - acc: 0.0000e+00 - val_loss: 1.0181e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "13676/13676 [==============================] - 6s - loss: 5.9665e-05 - acc: 0.0000e+00 - val_loss: 1.3104e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "13676/13676 [==============================] - 6s - loss: 6.7943e-05 - acc: 0.0000e+00 - val_loss: 1.0154e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "13676/13676 [==============================] - 6s - loss: 4.9551e-05 - acc: 0.0000e+00 - val_loss: 9.4271e-05 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "13676/13676 [==============================] - 6s - loss: 4.8806e-05 - acc: 0.0000e+00 - val_loss: 1.2064e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "13676/13676 [==============================] - 6s - loss: 5.6354e-05 - acc: 0.0000e+00 - val_loss: 3.3932e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "13676/13676 [==============================] - 6s - loss: 5.2090e-05 - acc: 0.0000e+00 - val_loss: 1.2067e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "13676/13676 [==============================] - 6s - loss: 5.4690e-05 - acc: 0.0000e+00 - val_loss: 1.0812e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "13676/13676 [==============================] - 6s - loss: 5.4870e-05 - acc: 0.0000e+00 - val_loss: 9.2201e-05 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "13676/13676 [==============================] - 6s - loss: 4.6908e-05 - acc: 0.0000e+00 - val_loss: 1.3780e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "13676/13676 [==============================] - 6s - loss: 4.9418e-05 - acc: 0.0000e+00 - val_loss: 1.9574e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "13676/13676 [==============================] - 6s - loss: 5.8731e-05 - acc: 0.0000e+00 - val_loss: 1.2955e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "13676/13676 [==============================] - 6s - loss: 5.4250e-05 - acc: 0.0000e+00 - val_loss: 9.2180e-05 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "13676/13676 [==============================] - 6s - loss: 5.1110e-05 - acc: 0.0000e+00 - val_loss: 2.2284e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "13676/13676 [==============================] - 6s - loss: 5.0823e-05 - acc: 0.0000e+00 - val_loss: 9.1376e-05 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "13676/13676 [==============================] - 6s - loss: 4.4377e-05 - acc: 0.0000e+00 - val_loss: 8.6608e-05 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "13676/13676 [==============================] - 6s - loss: 4.9532e-05 - acc: 0.0000e+00 - val_loss: 9.8229e-05 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "13676/13676 [==============================] - 6s - loss: 5.8112e-05 - acc: 0.0000e+00 - val_loss: 1.5642e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00004 MSE (0.01 RMSE)\n",
      "Test Score: 0.00110 MSE (0.03 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_33 (LSTM)               (None, 120, 256)          267264    \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 120, 256)          0         \n",
      "_________________________________________________________________\n",
      "lstm_34 (LSTM)               (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 800,833\n",
      "Trainable params: 800,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13627 samples, validate on 1515 samples\n",
      "Epoch 1/90\n",
      "13627/13627 [==============================] - 14s - loss: 0.0132 - acc: 0.0000e+00 - val_loss: 0.0160 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "13627/13627 [==============================] - 12s - loss: 5.4418e-04 - acc: 0.0000e+00 - val_loss: 8.1841e-04 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "13627/13627 [==============================] - 12s - loss: 1.4252e-04 - acc: 0.0000e+00 - val_loss: 3.9795e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "13627/13627 [==============================] - 12s - loss: 1.1436e-04 - acc: 0.0000e+00 - val_loss: 2.6819e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "13627/13627 [==============================] - 12s - loss: 9.3901e-05 - acc: 0.0000e+00 - val_loss: 2.2107e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "13627/13627 [==============================] - 12s - loss: 9.3137e-05 - acc: 0.0000e+00 - val_loss: 2.1678e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "13627/13627 [==============================] - 12s - loss: 9.0018e-05 - acc: 0.0000e+00 - val_loss: 2.3579e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "13627/13627 [==============================] - 12s - loss: 8.9298e-05 - acc: 0.0000e+00 - val_loss: 2.0263e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "13627/13627 [==============================] - 12s - loss: 8.5730e-05 - acc: 0.0000e+00 - val_loss: 1.9890e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "13627/13627 [==============================] - 12s - loss: 8.6167e-05 - acc: 0.0000e+00 - val_loss: 2.1627e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "13627/13627 [==============================] - 12s - loss: 8.3232e-05 - acc: 0.0000e+00 - val_loss: 1.9127e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "13627/13627 [==============================] - 12s - loss: 8.0928e-05 - acc: 0.0000e+00 - val_loss: 1.8539e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "13627/13627 [==============================] - 12s - loss: 8.1467e-05 - acc: 0.0000e+00 - val_loss: 2.3295e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "13627/13627 [==============================] - 12s - loss: 7.8706e-05 - acc: 0.0000e+00 - val_loss: 1.8251e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "13627/13627 [==============================] - 12s - loss: 7.6470e-05 - acc: 0.0000e+00 - val_loss: 1.8233e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "13627/13627 [==============================] - 12s - loss: 7.6411e-05 - acc: 0.0000e+00 - val_loss: 3.1473e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "13627/13627 [==============================] - 12s - loss: 8.2909e-05 - acc: 0.0000e+00 - val_loss: 1.9584e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "13627/13627 [==============================] - 12s - loss: 7.6005e-05 - acc: 0.0000e+00 - val_loss: 2.2303e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "13627/13627 [==============================] - 12s - loss: 7.4048e-05 - acc: 0.0000e+00 - val_loss: 2.0199e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "13627/13627 [==============================] - 12s - loss: 7.5477e-05 - acc: 0.0000e+00 - val_loss: 2.0248e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "13627/13627 [==============================] - 12s - loss: 8.3522e-05 - acc: 0.0000e+00 - val_loss: 3.0674e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "13627/13627 [==============================] - 12s - loss: 7.7555e-05 - acc: 0.0000e+00 - val_loss: 1.6220e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "13627/13627 [==============================] - 12s - loss: 7.2584e-05 - acc: 0.0000e+00 - val_loss: 1.6752e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "13627/13627 [==============================] - 12s - loss: 6.9536e-05 - acc: 0.0000e+00 - val_loss: 1.6174e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "13627/13627 [==============================] - 12s - loss: 7.0980e-05 - acc: 0.0000e+00 - val_loss: 1.8548e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "13627/13627 [==============================] - 12s - loss: 8.1950e-05 - acc: 0.0000e+00 - val_loss: 1.5593e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "13627/13627 [==============================] - 12s - loss: 6.7273e-05 - acc: 0.0000e+00 - val_loss: 1.5258e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "13627/13627 [==============================] - 12s - loss: 6.6588e-05 - acc: 0.0000e+00 - val_loss: 1.9357e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "13627/13627 [==============================] - 12s - loss: 6.9566e-05 - acc: 0.0000e+00 - val_loss: 2.2359e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "13627/13627 [==============================] - 12s - loss: 6.7375e-05 - acc: 0.0000e+00 - val_loss: 1.5025e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "13627/13627 [==============================] - 12s - loss: 7.4412e-05 - acc: 0.0000e+00 - val_loss: 1.7582e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "13627/13627 [==============================] - 12s - loss: 6.4413e-05 - acc: 0.0000e+00 - val_loss: 1.4535e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "13627/13627 [==============================] - 12s - loss: 6.4737e-05 - acc: 0.0000e+00 - val_loss: 1.8866e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "13627/13627 [==============================] - 12s - loss: 6.8793e-05 - acc: 0.0000e+00 - val_loss: 1.9636e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "13627/13627 [==============================] - 12s - loss: 6.5486e-05 - acc: 0.0000e+00 - val_loss: 1.3802e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "13627/13627 [==============================] - 12s - loss: 7.3256e-05 - acc: 0.0000e+00 - val_loss: 3.2344e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "13627/13627 [==============================] - 12s - loss: 6.5952e-05 - acc: 0.0000e+00 - val_loss: 1.4416e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "13627/13627 [==============================] - 12s - loss: 6.1343e-05 - acc: 0.0000e+00 - val_loss: 1.6331e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "13627/13627 [==============================] - 12s - loss: 6.2842e-05 - acc: 0.0000e+00 - val_loss: 1.3876e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "13627/13627 [==============================] - 12s - loss: 5.8793e-05 - acc: 0.0000e+00 - val_loss: 1.7601e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "13627/13627 [==============================] - 12s - loss: 6.5935e-05 - acc: 0.0000e+00 - val_loss: 2.1223e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "13627/13627 [==============================] - 12s - loss: 6.7935e-05 - acc: 0.0000e+00 - val_loss: 3.1681e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "13627/13627 [==============================] - 12s - loss: 6.8726e-05 - acc: 0.0000e+00 - val_loss: 1.3403e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "13627/13627 [==============================] - 12s - loss: 6.1849e-05 - acc: 0.0000e+00 - val_loss: 1.5426e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "13627/13627 [==============================] - 12s - loss: 5.8084e-05 - acc: 0.0000e+00 - val_loss: 1.6089e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "13627/13627 [==============================] - 12s - loss: 6.4271e-05 - acc: 0.0000e+00 - val_loss: 1.2902e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "13627/13627 [==============================] - 12s - loss: 5.9284e-05 - acc: 0.0000e+00 - val_loss: 1.3569e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "13627/13627 [==============================] - 12s - loss: 6.5214e-05 - acc: 0.0000e+00 - val_loss: 1.2466e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "13627/13627 [==============================] - 12s - loss: 6.2108e-05 - acc: 0.0000e+00 - val_loss: 1.2906e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "13627/13627 [==============================] - 12s - loss: 6.0872e-05 - acc: 0.0000e+00 - val_loss: 1.4563e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "13627/13627 [==============================] - 12s - loss: 7.9486e-05 - acc: 0.0000e+00 - val_loss: 1.3953e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "13627/13627 [==============================] - 12s - loss: 7.2581e-05 - acc: 0.0000e+00 - val_loss: 2.1274e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "13627/13627 [==============================] - 12s - loss: 6.3389e-05 - acc: 0.0000e+00 - val_loss: 1.5034e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "13627/13627 [==============================] - 12s - loss: 5.9793e-05 - acc: 0.0000e+00 - val_loss: 1.2347e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "13627/13627 [==============================] - 12s - loss: 6.4523e-05 - acc: 0.0000e+00 - val_loss: 1.4254e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "13627/13627 [==============================] - 12s - loss: 6.0791e-05 - acc: 0.0000e+00 - val_loss: 1.8967e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13627/13627 [==============================] - 12s - loss: 6.0908e-05 - acc: 0.0000e+00 - val_loss: 4.2675e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "13627/13627 [==============================] - 12s - loss: 5.9758e-05 - acc: 0.0000e+00 - val_loss: 1.4290e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "13627/13627 [==============================] - 12s - loss: 6.0854e-05 - acc: 0.0000e+00 - val_loss: 1.4859e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "13627/13627 [==============================] - 12s - loss: 5.5491e-05 - acc: 0.0000e+00 - val_loss: 1.5465e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "13627/13627 [==============================] - 12s - loss: 5.7282e-05 - acc: 0.0000e+00 - val_loss: 2.1252e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "13627/13627 [==============================] - 12s - loss: 5.6169e-05 - acc: 0.0000e+00 - val_loss: 1.5959e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "13627/13627 [==============================] - 12s - loss: 5.3933e-05 - acc: 0.0000e+00 - val_loss: 1.1506e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "13627/13627 [==============================] - 12s - loss: 5.9949e-05 - acc: 0.0000e+00 - val_loss: 1.1616e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "13627/13627 [==============================] - 12s - loss: 6.4285e-05 - acc: 0.0000e+00 - val_loss: 1.1336e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "13627/13627 [==============================] - 12s - loss: 5.8237e-05 - acc: 0.0000e+00 - val_loss: 1.3427e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "13627/13627 [==============================] - 12s - loss: 5.5533e-05 - acc: 0.0000e+00 - val_loss: 1.4075e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "13627/13627 [==============================] - 12s - loss: 5.9929e-05 - acc: 0.0000e+00 - val_loss: 1.1589e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "13627/13627 [==============================] - 12s - loss: 5.8676e-05 - acc: 0.0000e+00 - val_loss: 2.1256e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "13627/13627 [==============================] - 12s - loss: 6.0606e-05 - acc: 0.0000e+00 - val_loss: 1.0983e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "13627/13627 [==============================] - 12s - loss: 4.9798e-05 - acc: 0.0000e+00 - val_loss: 1.1622e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "13627/13627 [==============================] - 12s - loss: 5.9031e-05 - acc: 0.0000e+00 - val_loss: 3.3399e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "13627/13627 [==============================] - 12s - loss: 6.8193e-05 - acc: 0.0000e+00 - val_loss: 1.2528e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "13627/13627 [==============================] - 12s - loss: 6.0124e-05 - acc: 0.0000e+00 - val_loss: 2.4766e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "13627/13627 [==============================] - 12s - loss: 5.3276e-05 - acc: 0.0000e+00 - val_loss: 1.1728e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "13627/13627 [==============================] - 12s - loss: 5.8850e-05 - acc: 0.0000e+00 - val_loss: 2.9997e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "13627/13627 [==============================] - 12s - loss: 5.1704e-05 - acc: 0.0000e+00 - val_loss: 1.2458e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "13627/13627 [==============================] - 12s - loss: 5.1348e-05 - acc: 0.0000e+00 - val_loss: 1.5266e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "13627/13627 [==============================] - 12s - loss: 6.0807e-05 - acc: 0.0000e+00 - val_loss: 3.2861e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "13627/13627 [==============================] - 12s - loss: 5.3762e-05 - acc: 0.0000e+00 - val_loss: 1.2479e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "13627/13627 [==============================] - 12s - loss: 6.0570e-05 - acc: 0.0000e+00 - val_loss: 1.4242e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "13627/13627 [==============================] - 12s - loss: 5.8000e-05 - acc: 0.0000e+00 - val_loss: 1.4785e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "13627/13627 [==============================] - 12s - loss: 5.7535e-05 - acc: 0.0000e+00 - val_loss: 1.9425e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "13627/13627 [==============================] - 12s - loss: 5.8419e-05 - acc: 0.0000e+00 - val_loss: 1.3510e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "13627/13627 [==============================] - 12s - loss: 5.4971e-05 - acc: 0.0000e+00 - val_loss: 1.0202e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "13627/13627 [==============================] - 12s - loss: 5.7241e-05 - acc: 0.0000e+00 - val_loss: 1.1356e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "13627/13627 [==============================] - 12s - loss: 5.2266e-05 - acc: 0.0000e+00 - val_loss: 1.4945e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "13627/13627 [==============================] - 12s - loss: 5.0067e-05 - acc: 0.0000e+00 - val_loss: 1.0618e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "13627/13627 [==============================] - 12s - loss: 5.8646e-05 - acc: 0.0000e+00 - val_loss: 1.2745e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "13627/13627 [==============================] - 12s - loss: 5.2802e-05 - acc: 0.0000e+00 - val_loss: 2.2678e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00005 MSE (0.01 RMSE)\n",
      "Test Score: 0.00134 MSE (0.04 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_35 (LSTM)               (None, 180, 256)          267264    \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 180, 256)          0         \n",
      "_________________________________________________________________\n",
      "lstm_36 (LSTM)               (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 800,833\n",
      "Trainable params: 800,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13579 samples, validate on 1509 samples\n",
      "Epoch 1/90\n",
      "13579/13579 [==============================] - 26s - loss: 0.0094 - acc: 0.0000e+00 - val_loss: 0.0044 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "13579/13579 [==============================] - 24s - loss: 4.3997e-04 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "13579/13579 [==============================] - 24s - loss: 1.6346e-04 - acc: 0.0000e+00 - val_loss: 4.3121e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "13579/13579 [==============================] - 24s - loss: 1.2442e-04 - acc: 0.0000e+00 - val_loss: 3.0564e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "13579/13579 [==============================] - 24s - loss: 1.1094e-04 - acc: 0.0000e+00 - val_loss: 2.5845e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "13579/13579 [==============================] - 24s - loss: 1.0471e-04 - acc: 0.0000e+00 - val_loss: 2.3817e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "13579/13579 [==============================] - 24s - loss: 9.5702e-05 - acc: 0.0000e+00 - val_loss: 2.1527e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "13579/13579 [==============================] - 24s - loss: 9.8694e-05 - acc: 0.0000e+00 - val_loss: 3.0860e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "13579/13579 [==============================] - 24s - loss: 9.7905e-05 - acc: 0.0000e+00 - val_loss: 2.0036e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "13579/13579 [==============================] - 24s - loss: 8.5286e-05 - acc: 0.0000e+00 - val_loss: 2.1586e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "13579/13579 [==============================] - 24s - loss: 8.5159e-05 - acc: 0.0000e+00 - val_loss: 2.6195e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "13579/13579 [==============================] - 24s - loss: 8.5071e-05 - acc: 0.0000e+00 - val_loss: 2.4182e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "13579/13579 [==============================] - 24s - loss: 8.4028e-05 - acc: 0.0000e+00 - val_loss: 1.8857e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "13579/13579 [==============================] - 24s - loss: 8.2075e-05 - acc: 0.0000e+00 - val_loss: 2.0642e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13579/13579 [==============================] - 24s - loss: 8.1145e-05 - acc: 0.0000e+00 - val_loss: 1.8364e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "13579/13579 [==============================] - 24s - loss: 7.4481e-05 - acc: 0.0000e+00 - val_loss: 1.8538e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "13579/13579 [==============================] - 24s - loss: 7.8155e-05 - acc: 0.0000e+00 - val_loss: 1.9232e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "13579/13579 [==============================] - 24s - loss: 7.0134e-05 - acc: 0.0000e+00 - val_loss: 1.7495e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "13579/13579 [==============================] - 24s - loss: 7.5644e-05 - acc: 0.0000e+00 - val_loss: 1.8265e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "13579/13579 [==============================] - 24s - loss: 7.6612e-05 - acc: 0.0000e+00 - val_loss: 1.6688e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "13579/13579 [==============================] - 24s - loss: 7.2388e-05 - acc: 0.0000e+00 - val_loss: 1.8866e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "13579/13579 [==============================] - 24s - loss: 7.1746e-05 - acc: 0.0000e+00 - val_loss: 2.3058e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "13579/13579 [==============================] - 24s - loss: 8.1533e-05 - acc: 0.0000e+00 - val_loss: 1.9465e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "13579/13579 [==============================] - 24s - loss: 7.1388e-05 - acc: 0.0000e+00 - val_loss: 1.7868e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "13579/13579 [==============================] - 24s - loss: 8.1184e-05 - acc: 0.0000e+00 - val_loss: 4.7591e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "13579/13579 [==============================] - 24s - loss: 7.7567e-05 - acc: 0.0000e+00 - val_loss: 1.7215e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "13579/13579 [==============================] - 24s - loss: 7.8118e-05 - acc: 0.0000e+00 - val_loss: 1.8059e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "13579/13579 [==============================] - 24s - loss: 7.2468e-05 - acc: 0.0000e+00 - val_loss: 1.6878e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "13579/13579 [==============================] - 24s - loss: 6.9796e-05 - acc: 0.0000e+00 - val_loss: 1.7216e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "13579/13579 [==============================] - 24s - loss: 7.0409e-05 - acc: 0.0000e+00 - val_loss: 1.7320e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "13579/13579 [==============================] - 24s - loss: 6.0891e-05 - acc: 0.0000e+00 - val_loss: 1.4863e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "13579/13579 [==============================] - 24s - loss: 6.8187e-05 - acc: 0.0000e+00 - val_loss: 1.4364e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "13579/13579 [==============================] - 24s - loss: 6.4221e-05 - acc: 0.0000e+00 - val_loss: 1.4580e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "13579/13579 [==============================] - 24s - loss: 6.3173e-05 - acc: 0.0000e+00 - val_loss: 1.5641e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "13579/13579 [==============================] - 24s - loss: 6.8616e-05 - acc: 0.0000e+00 - val_loss: 1.5443e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "13579/13579 [==============================] - 24s - loss: 6.8935e-05 - acc: 0.0000e+00 - val_loss: 1.5192e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "13579/13579 [==============================] - 24s - loss: 6.6026e-05 - acc: 0.0000e+00 - val_loss: 1.3792e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "13579/13579 [==============================] - 24s - loss: 7.1146e-05 - acc: 0.0000e+00 - val_loss: 1.6814e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "13579/13579 [==============================] - 24s - loss: 5.8572e-05 - acc: 0.0000e+00 - val_loss: 3.4053e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "13579/13579 [==============================] - 24s - loss: 7.6802e-05 - acc: 0.0000e+00 - val_loss: 1.3642e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "13579/13579 [==============================] - 24s - loss: 6.2122e-05 - acc: 0.0000e+00 - val_loss: 3.8727e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "13579/13579 [==============================] - 24s - loss: 7.4233e-05 - acc: 0.0000e+00 - val_loss: 3.3770e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "13579/13579 [==============================] - 24s - loss: 6.5784e-05 - acc: 0.0000e+00 - val_loss: 1.7905e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "13579/13579 [==============================] - 24s - loss: 6.8010e-05 - acc: 0.0000e+00 - val_loss: 1.6349e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "13579/13579 [==============================] - 24s - loss: 6.5276e-05 - acc: 0.0000e+00 - val_loss: 1.7740e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "13579/13579 [==============================] - 24s - loss: 7.1226e-05 - acc: 0.0000e+00 - val_loss: 2.9247e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "13579/13579 [==============================] - 24s - loss: 7.0382e-05 - acc: 0.0000e+00 - val_loss: 1.6621e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "13579/13579 [==============================] - 24s - loss: 6.2019e-05 - acc: 0.0000e+00 - val_loss: 1.5399e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "13579/13579 [==============================] - 24s - loss: 5.9234e-05 - acc: 0.0000e+00 - val_loss: 1.2525e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "13579/13579 [==============================] - 24s - loss: 6.3384e-05 - acc: 0.0000e+00 - val_loss: 1.3656e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "13579/13579 [==============================] - 24s - loss: 6.9252e-05 - acc: 0.0000e+00 - val_loss: 1.5823e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "13579/13579 [==============================] - 24s - loss: 6.1382e-05 - acc: 0.0000e+00 - val_loss: 2.0558e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "13579/13579 [==============================] - 24s - loss: 6.3378e-05 - acc: 0.0000e+00 - val_loss: 1.4254e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "13579/13579 [==============================] - 24s - loss: 6.2511e-05 - acc: 0.0000e+00 - val_loss: 4.7572e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "13579/13579 [==============================] - 24s - loss: 6.8484e-05 - acc: 0.0000e+00 - val_loss: 2.8783e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "13579/13579 [==============================] - 24s - loss: 7.3151e-05 - acc: 0.0000e+00 - val_loss: 3.9962e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "13579/13579 [==============================] - 24s - loss: 6.3128e-05 - acc: 0.0000e+00 - val_loss: 1.3920e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "13579/13579 [==============================] - 24s - loss: 5.3454e-05 - acc: 0.0000e+00 - val_loss: 1.1483e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "13579/13579 [==============================] - 24s - loss: 5.7217e-05 - acc: 0.0000e+00 - val_loss: 1.2380e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "13579/13579 [==============================] - 25s - loss: 5.4969e-05 - acc: 0.0000e+00 - val_loss: 1.9747e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "13579/13579 [==============================] - 24s - loss: 5.3246e-05 - acc: 0.0000e+00 - val_loss: 1.3352e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "13579/13579 [==============================] - 25s - loss: 6.1323e-05 - acc: 0.0000e+00 - val_loss: 1.2786e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "13579/13579 [==============================] - 24s - loss: 5.2563e-05 - acc: 0.0000e+00 - val_loss: 1.5135e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "13579/13579 [==============================] - 24s - loss: 6.1483e-05 - acc: 0.0000e+00 - val_loss: 1.6452e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "13579/13579 [==============================] - 24s - loss: 6.0864e-05 - acc: 0.0000e+00 - val_loss: 1.3067e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "13579/13579 [==============================] - 25s - loss: 5.5991e-05 - acc: 0.0000e+00 - val_loss: 1.2651e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "13579/13579 [==============================] - 24s - loss: 7.2140e-05 - acc: 0.0000e+00 - val_loss: 1.5778e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "13579/13579 [==============================] - 25s - loss: 5.4745e-05 - acc: 0.0000e+00 - val_loss: 1.0885e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "13579/13579 [==============================] - 24s - loss: 5.6990e-05 - acc: 0.0000e+00 - val_loss: 3.2890e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "13579/13579 [==============================] - 24s - loss: 7.2326e-05 - acc: 0.0000e+00 - val_loss: 3.1394e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13579/13579 [==============================] - 24s - loss: 5.7491e-05 - acc: 0.0000e+00 - val_loss: 1.3206e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "13579/13579 [==============================] - 24s - loss: 5.3565e-05 - acc: 0.0000e+00 - val_loss: 2.3588e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "13579/13579 [==============================] - 24s - loss: 5.4092e-05 - acc: 0.0000e+00 - val_loss: 1.2113e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "13579/13579 [==============================] - 24s - loss: 5.2915e-05 - acc: 0.0000e+00 - val_loss: 1.2127e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "13579/13579 [==============================] - 24s - loss: 5.9604e-05 - acc: 0.0000e+00 - val_loss: 2.0901e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "13579/13579 [==============================] - 24s - loss: 5.4687e-05 - acc: 0.0000e+00 - val_loss: 1.1650e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "13579/13579 [==============================] - 24s - loss: 5.0619e-05 - acc: 0.0000e+00 - val_loss: 2.4677e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "13579/13579 [==============================] - 24s - loss: 5.2500e-05 - acc: 0.0000e+00 - val_loss: 1.3239e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "13579/13579 [==============================] - 24s - loss: 5.1306e-05 - acc: 0.0000e+00 - val_loss: 1.3669e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "13579/13579 [==============================] - 24s - loss: 5.0534e-05 - acc: 0.0000e+00 - val_loss: 1.1819e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "13579/13579 [==============================] - 24s - loss: 5.1145e-05 - acc: 0.0000e+00 - val_loss: 1.1354e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "13579/13579 [==============================] - 24s - loss: 5.5164e-05 - acc: 0.0000e+00 - val_loss: 1.5562e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "13579/13579 [==============================] - 24s - loss: 5.5740e-05 - acc: 0.0000e+00 - val_loss: 1.1222e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "13579/13579 [==============================] - 25s - loss: 5.4487e-05 - acc: 0.0000e+00 - val_loss: 1.4835e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "13579/13579 [==============================] - 24s - loss: 5.3292e-05 - acc: 0.0000e+00 - val_loss: 1.1943e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "13579/13579 [==============================] - 24s - loss: 4.7758e-05 - acc: 0.0000e+00 - val_loss: 4.9412e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "13579/13579 [==============================] - 24s - loss: 5.3333e-05 - acc: 0.0000e+00 - val_loss: 1.2307e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "13579/13579 [==============================] - 24s - loss: 4.8729e-05 - acc: 0.0000e+00 - val_loss: 1.5663e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "13579/13579 [==============================] - 24s - loss: 5.3640e-05 - acc: 0.0000e+00 - val_loss: 1.5906e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "13579/13579 [==============================] - 24s - loss: 5.4915e-05 - acc: 0.0000e+00 - val_loss: 9.5203e-05 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00002 MSE (0.00 RMSE)\n",
      "Test Score: 0.00059 MSE (0.02 RMSE)\n"
     ]
    }
   ],
   "source": [
    "seq_len_list = [5, 10, 22, 60, 120, 180]\n",
    "\n",
    "seq_len_result = {}\n",
    "\n",
    "for seq_len in seq_len_list:\n",
    "    shape = [4, seq_len, 1]\n",
    "    \n",
    "    trainScore, testScore = quick_measure(stock_name, seq_len, d, shape, neurons, epochs, decay)\n",
    "    seq_len_result[seq_len] = testScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEWCAYAAABbgYH9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24cb1ce4ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lists = sorted(seq_len_result.items())\n",
    "x,y = zip(*lists)\n",
    "plt.plot(x,y)\n",
    "plt.title('Finding the best hyperparameter')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Mean Square Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
