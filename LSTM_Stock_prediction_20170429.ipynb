{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock value prediction from Open, High, Low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt2\n",
    "import pandas as pd\n",
    "from pandas import datetime\n",
    "import math, time\n",
    "import itertools\n",
    "from sklearn import preprocessing\n",
    "import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import load_model\n",
    "import keras\n",
    "import pandas_datareader.data as web\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stock_name = '^GSPC'\n",
    "seq_len = 22\n",
    "d = 0.2\n",
    "shape = [4, seq_len, 1] # feature, window, output\n",
    "neurons = [128, 128, 32, 1]\n",
    "epochs = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1. Download data and normalize it\n",
    "Data since 1950 to today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stock_data(stock_name, normalize=True):\n",
    "    start = datetime.datetime(1950, 1, 1)\n",
    "    end = datetime.date.today()\n",
    "    df = web.DataReader(stock_name, \"yahoo\", start, end)\n",
    "    df.drop(['Volume', 'Close'], 1, inplace=True)\n",
    "    \n",
    "    if normalize:        \n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        df['Open'] = min_max_scaler.fit_transform(df.Open.values.reshape(-1,1))\n",
    "        df['High'] = min_max_scaler.fit_transform(df.High.values.reshape(-1,1))\n",
    "        df['Low'] = min_max_scaler.fit_transform(df.Low.values.reshape(-1,1))\n",
    "        df['Adj Close'] = min_max_scaler.fit_transform(df['Adj Close'].values.reshape(-1,1))\n",
    "    return df\n",
    "\n",
    "df = get_stock_data(stock_name, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Plot out the Normalized Adjusted close price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Open      High       Low  Adj Close\n",
      "Date                                               \n",
      "1950-01-03  0.000000  0.000000  0.000000   0.000000\n",
      "1950-01-04  0.000080  0.000080  0.000080   0.000080\n",
      "1950-01-05  0.000114  0.000113  0.000114   0.000113\n",
      "1950-01-06  0.000135  0.000134  0.000135   0.000134\n",
      "1950-01-09  0.000177  0.000176  0.000177   0.000177\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20f873644e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_stock(stock_name):\n",
    "    df = get_stock_data(stock_name, normalize=True)\n",
    "    print(df.head())\n",
    "    plt.plot(df['Adj Close'], color='red', label='Adj Close')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "plot_stock(stock_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Set last day Adjusted Close as y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(stock, seq_len):\n",
    "    amount_of_features = len(stock.columns)\n",
    "    data = stock.as_matrix() \n",
    "    sequence_length = seq_len + 1 # index starting from 0\n",
    "    result = []\n",
    "    \n",
    "    for index in range(len(data) - sequence_length): # maxmimum date = lastest date - sequence length\n",
    "        result.append(data[index: index + sequence_length]) # index : index + 22days\n",
    "    \n",
    "    result = np.array(result)\n",
    "    row = round(0.9 * result.shape[0]) # 90% split\n",
    "    train = result[:int(row), :] # 90% date, all features # (3893, 23, 4)\n",
    "    X_train = train[:, :-1] # x = all feature except adj close # (3893, 22, 4)\n",
    "    y_train = train[:, -1][:,-1] # y = last feature, last day (3893)\n",
    "    X_test = result[int(row):, :-1] #(432, 22, 4)\n",
    "    y_test = result[int(row):, -1][:,-1] #(432)\n",
    "\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], amount_of_features))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], amount_of_features))  \n",
    "\n",
    "    return [X_train, y_train, X_test, y_test]\n",
    "\n",
    "X_train, y_train, X_test, y_test = load_data(df, seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 4. Buidling neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model2(layers, neurons, d):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(neurons[0], input_shape=(layers[1], layers[0]), return_sequences=True))\n",
    "    model.add(Dropout(d))\n",
    "        \n",
    "    model.add(LSTM(neurons[1], input_shape=(layers[1], layers[0]), return_sequences=False))\n",
    "    model.add(Dropout(d))\n",
    "        \n",
    "    model.add(Dense(neurons[2],kernel_initializer=\"uniform\",activation='relu'))        \n",
    "    model.add(Dense(neurons[3],kernel_initializer=\"uniform\",activation='linear'))\n",
    "    # model = load_model('my_LSTM_stock_model1000.h5')\n",
    "    # adam = keras.optimizers.Adam(decay=0.2)\n",
    "    model.compile(loss='mse',optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Model Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_21 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_22 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model2(shape, neurons, d)\n",
    "# layers = [4, 22, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13702 samples, validate on 1523 samples\n",
      "Epoch 1/300\n",
      "13702/13702 [==============================] - 3s - loss: 0.0123 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7706e-04 - acc: 0.0000e+00 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.7348e-04 - acc: 0.0000e+00 - val_loss: 6.3644e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7076e-04 - acc: 0.0000e+00 - val_loss: 3.7487e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4376e-04 - acc: 0.0000e+00 - val_loss: 3.0687e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4102e-04 - acc: 0.0000e+00 - val_loss: 2.5381e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2676e-04 - acc: 0.0000e+00 - val_loss: 3.0596e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4229e-04 - acc: 0.0000e+00 - val_loss: 3.5200e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2557e-04 - acc: 0.0000e+00 - val_loss: 2.3675e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2848e-04 - acc: 0.0000e+00 - val_loss: 2.3618e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2542e-04 - acc: 0.0000e+00 - val_loss: 2.2216e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1654e-04 - acc: 0.0000e+00 - val_loss: 2.2119e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1313e-04 - acc: 0.0000e+00 - val_loss: 2.1987e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1508e-04 - acc: 0.0000e+00 - val_loss: 2.2412e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2046e-04 - acc: 0.0000e+00 - val_loss: 2.5556e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1317e-04 - acc: 0.0000e+00 - val_loss: 2.7565e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1329e-04 - acc: 0.0000e+00 - val_loss: 2.0942e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0609e-04 - acc: 0.0000e+00 - val_loss: 2.0404e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0416e-04 - acc: 0.0000e+00 - val_loss: 2.0609e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1025e-04 - acc: 0.0000e+00 - val_loss: 2.0147e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0329e-04 - acc: 0.0000e+00 - val_loss: 2.1304e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0502e-04 - acc: 0.0000e+00 - val_loss: 4.4296e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2341e-04 - acc: 0.0000e+00 - val_loss: 3.0053e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1191e-04 - acc: 0.0000e+00 - val_loss: 1.9894e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.9425e-05 - acc: 0.0000e+00 - val_loss: 1.9181e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0329e-04 - acc: 0.0000e+00 - val_loss: 1.9201e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.8957e-05 - acc: 0.0000e+00 - val_loss: 1.9422e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1076e-04 - acc: 0.0000e+00 - val_loss: 2.2914e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1027e-04 - acc: 0.0000e+00 - val_loss: 3.1081e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3972e-04 - acc: 0.0000e+00 - val_loss: 1.8602e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0109e-04 - acc: 0.0000e+00 - val_loss: 1.8418e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0033e-04 - acc: 0.0000e+00 - val_loss: 2.0477e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0661e-04 - acc: 0.0000e+00 - val_loss: 2.8022e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0409e-04 - acc: 0.0000e+00 - val_loss: 1.7537e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1060e-04 - acc: 0.0000e+00 - val_loss: 1.9356e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.1767e-05 - acc: 0.0000e+00 - val_loss: 1.6985e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.5615e-05 - acc: 0.0000e+00 - val_loss: 3.2072e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2411e-04 - acc: 0.0000e+00 - val_loss: 2.4731e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1019e-04 - acc: 0.0000e+00 - val_loss: 3.1403e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0001e-04 - acc: 0.0000e+00 - val_loss: 7.2244e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2644e-04 - acc: 0.0000e+00 - val_loss: 5.4840e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1782e-04 - acc: 0.0000e+00 - val_loss: 1.6586e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.9390e-05 - acc: 0.0000e+00 - val_loss: 1.5933e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.0748e-05 - acc: 0.0000e+00 - val_loss: 1.8214e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.6787e-05 - acc: 0.0000e+00 - val_loss: 1.7667e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.2171e-05 - acc: 0.0000e+00 - val_loss: 1.8973e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3445e-05 - acc: 0.0000e+00 - val_loss: 2.3302e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.9240e-05 - acc: 0.0000e+00 - val_loss: 1.7163e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.7152e-05 - acc: 0.0000e+00 - val_loss: 2.3586e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.5454e-05 - acc: 0.0000e+00 - val_loss: 4.5665e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0607e-04 - acc: 0.0000e+00 - val_loss: 1.6087e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.8494e-05 - acc: 0.0000e+00 - val_loss: 1.4612e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.8229e-05 - acc: 0.0000e+00 - val_loss: 4.2381e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.7905e-05 - acc: 0.0000e+00 - val_loss: 3.9963e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.8208e-05 - acc: 0.0000e+00 - val_loss: 1.7313e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.4173e-05 - acc: 0.0000e+00 - val_loss: 1.4673e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13702/13702 [==============================] - 1s - loss: 7.9500e-05 - acc: 0.0000e+00 - val_loss: 1.6054e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0208e-05 - acc: 0.0000e+00 - val_loss: 1.3967e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3925e-05 - acc: 0.0000e+00 - val_loss: 1.3662e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8319e-05 - acc: 0.0000e+00 - val_loss: 2.6067e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.9368e-05 - acc: 0.0000e+00 - val_loss: 2.0857e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1368e-05 - acc: 0.0000e+00 - val_loss: 2.0302e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8229e-05 - acc: 0.0000e+00 - val_loss: 1.3445e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.5972e-05 - acc: 0.0000e+00 - val_loss: 1.3713e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8909e-05 - acc: 0.0000e+00 - val_loss: 1.4842e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.1493e-05 - acc: 0.0000e+00 - val_loss: 1.4490e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.5526e-05 - acc: 0.0000e+00 - val_loss: 1.3507e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8281e-05 - acc: 0.0000e+00 - val_loss: 1.3416e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.6869e-05 - acc: 0.0000e+00 - val_loss: 2.0041e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0865e-05 - acc: 0.0000e+00 - val_loss: 3.1738e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.9296e-05 - acc: 0.0000e+00 - val_loss: 1.5231e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.4233e-05 - acc: 0.0000e+00 - val_loss: 1.7630e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.4673e-05 - acc: 0.0000e+00 - val_loss: 1.3543e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9034e-05 - acc: 0.0000e+00 - val_loss: 3.2235e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.6830e-05 - acc: 0.0000e+00 - val_loss: 1.4935e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.7443e-05 - acc: 0.0000e+00 - val_loss: 1.2535e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2180e-05 - acc: 0.0000e+00 - val_loss: 1.3408e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1295e-05 - acc: 0.0000e+00 - val_loss: 1.7976e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.9850e-05 - acc: 0.0000e+00 - val_loss: 1.8060e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.7815e-05 - acc: 0.0000e+00 - val_loss: 1.8341e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8415e-05 - acc: 0.0000e+00 - val_loss: 1.6679e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.3784e-05 - acc: 0.0000e+00 - val_loss: 1.2610e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0751e-05 - acc: 0.0000e+00 - val_loss: 1.2137e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.8761e-05 - acc: 0.0000e+00 - val_loss: 1.1823e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2821e-05 - acc: 0.0000e+00 - val_loss: 2.2421e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0554e-05 - acc: 0.0000e+00 - val_loss: 1.1665e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2842e-05 - acc: 0.0000e+00 - val_loss: 1.2040e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.8401e-05 - acc: 0.0000e+00 - val_loss: 2.4603e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.9020e-05 - acc: 0.0000e+00 - val_loss: 1.1376e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.9894e-05 - acc: 0.0000e+00 - val_loss: 2.4395e-04 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.5640e-05 - acc: 0.0000e+00 - val_loss: 1.1077e-04 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0418e-05 - acc: 0.0000e+00 - val_loss: 4.6172e-04 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.5064e-05 - acc: 0.0000e+00 - val_loss: 1.8231e-04 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.5842e-05 - acc: 0.0000e+00 - val_loss: 3.1469e-04 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2830e-05 - acc: 0.0000e+00 - val_loss: 1.3454e-04 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1487e-05 - acc: 0.0000e+00 - val_loss: 2.4040e-04 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.3143e-05 - acc: 0.0000e+00 - val_loss: 1.8573e-04 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0119e-05 - acc: 0.0000e+00 - val_loss: 2.1340e-04 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.6002e-05 - acc: 0.0000e+00 - val_loss: 1.5392e-04 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.9317e-05 - acc: 0.0000e+00 - val_loss: 1.3915e-04 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.8044e-05 - acc: 0.0000e+00 - val_loss: 1.3163e-04 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7316e-05 - acc: 0.0000e+00 - val_loss: 1.7381e-04 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.1939e-05 - acc: 0.0000e+00 - val_loss: 1.1190e-04 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7330e-05 - acc: 0.0000e+00 - val_loss: 1.6076e-04 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7444e-05 - acc: 0.0000e+00 - val_loss: 1.2467e-04 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.5899e-05 - acc: 0.0000e+00 - val_loss: 1.1416e-04 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8770e-05 - acc: 0.0000e+00 - val_loss: 1.0544e-04 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9479e-05 - acc: 0.0000e+00 - val_loss: 1.1763e-04 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.5183e-05 - acc: 0.0000e+00 - val_loss: 1.5183e-04 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4421e-05 - acc: 0.0000e+00 - val_loss: 1.2440e-04 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3403e-05 - acc: 0.0000e+00 - val_loss: 1.1256e-04 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9171e-05 - acc: 0.0000e+00 - val_loss: 1.4859e-04 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13702/13702 [==============================] - 1s - loss: 5.9237e-05 - acc: 0.0000e+00 - val_loss: 1.1493e-04 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.1312e-05 - acc: 0.0000e+00 - val_loss: 1.0902e-04 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9865e-05 - acc: 0.0000e+00 - val_loss: 1.2336e-04 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.6883e-05 - acc: 0.0000e+00 - val_loss: 1.0724e-04 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8860e-05 - acc: 0.0000e+00 - val_loss: 1.2652e-04 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.0152e-05 - acc: 0.0000e+00 - val_loss: 1.1456e-04 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8167e-05 - acc: 0.0000e+00 - val_loss: 1.1338e-04 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.7379e-05 - acc: 0.0000e+00 - val_loss: 1.0322e-04 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9693e-05 - acc: 0.0000e+00 - val_loss: 1.0684e-04 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.7962e-05 - acc: 0.0000e+00 - val_loss: 1.0337e-04 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.5111e-05 - acc: 0.0000e+00 - val_loss: 9.4783e-05 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3970e-05 - acc: 0.0000e+00 - val_loss: 3.1590e-04 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.6488e-05 - acc: 0.0000e+00 - val_loss: 2.9444e-04 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.6438e-05 - acc: 0.0000e+00 - val_loss: 1.3189e-04 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3083e-05 - acc: 0.0000e+00 - val_loss: 9.6318e-05 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.4903e-05 - acc: 0.0000e+00 - val_loss: 3.0656e-04 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2356e-05 - acc: 0.0000e+00 - val_loss: 1.1758e-04 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7419e-05 - acc: 0.0000e+00 - val_loss: 1.1406e-04 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.6866e-05 - acc: 0.0000e+00 - val_loss: 1.1857e-04 - val_acc: 0.0000e+00\n",
      "Epoch 132/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.1137e-05 - acc: 0.0000e+00 - val_loss: 9.4767e-05 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.2809e-05 - acc: 0.0000e+00 - val_loss: 2.4594e-04 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.0962e-05 - acc: 0.0000e+00 - val_loss: 1.3873e-04 - val_acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.2801e-05 - acc: 0.0000e+00 - val_loss: 9.2898e-05 - val_acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9330e-05 - acc: 0.0000e+00 - val_loss: 1.0166e-04 - val_acc: 0.0000e+00\n",
      "Epoch 137/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3148e-05 - acc: 0.0000e+00 - val_loss: 1.1240e-04 - val_acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3527e-05 - acc: 0.0000e+00 - val_loss: 1.1020e-04 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.8455e-05 - acc: 0.0000e+00 - val_loss: 1.3436e-04 - val_acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3005e-05 - acc: 0.0000e+00 - val_loss: 1.2232e-04 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9603e-05 - acc: 0.0000e+00 - val_loss: 8.8681e-05 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.8775e-05 - acc: 0.0000e+00 - val_loss: 8.7542e-05 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.1587e-05 - acc: 0.0000e+00 - val_loss: 9.9316e-05 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.1275e-05 - acc: 0.0000e+00 - val_loss: 3.1562e-04 - val_acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.2467e-05 - acc: 0.0000e+00 - val_loss: 1.4082e-04 - val_acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.0519e-05 - acc: 0.0000e+00 - val_loss: 1.1434e-04 - val_acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.5920e-05 - acc: 0.0000e+00 - val_loss: 2.0629e-04 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9102e-05 - acc: 0.0000e+00 - val_loss: 1.1399e-04 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9762e-05 - acc: 0.0000e+00 - val_loss: 9.6454e-05 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9873e-05 - acc: 0.0000e+00 - val_loss: 8.5265e-05 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.2710e-05 - acc: 0.0000e+00 - val_loss: 2.0064e-04 - val_acc: 0.0000e+00\n",
      "Epoch 152/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.4388e-05 - acc: 0.0000e+00 - val_loss: 1.0244e-04 - val_acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6869e-05 - acc: 0.0000e+00 - val_loss: 1.5631e-04 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.8999e-05 - acc: 0.0000e+00 - val_loss: 8.7716e-05 - val_acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9596e-05 - acc: 0.0000e+00 - val_loss: 1.0105e-04 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.7567e-05 - acc: 0.0000e+00 - val_loss: 1.3648e-04 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6353e-05 - acc: 0.0000e+00 - val_loss: 1.3246e-04 - val_acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.0821e-05 - acc: 0.0000e+00 - val_loss: 1.3097e-04 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.0301e-05 - acc: 0.0000e+00 - val_loss: 8.0380e-05 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6794e-05 - acc: 0.0000e+00 - val_loss: 1.0062e-04 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6044e-05 - acc: 0.0000e+00 - val_loss: 9.4748e-05 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3725e-05 - acc: 0.0000e+00 - val_loss: 1.9617e-04 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.8787e-05 - acc: 0.0000e+00 - val_loss: 9.8656e-05 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.7064e-05 - acc: 0.0000e+00 - val_loss: 8.0240e-05 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6602e-05 - acc: 0.0000e+00 - val_loss: 1.0009e-04 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.7917e-05 - acc: 0.0000e+00 - val_loss: 2.4788e-04 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9515e-05 - acc: 0.0000e+00 - val_loss: 1.3668e-04 - val_acc: 0.0000e+00\n",
      "Epoch 168/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.4331e-05 - acc: 0.0000e+00 - val_loss: 8.6485e-05 - val_acc: 0.0000e+00\n",
      "Epoch 169/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13702/13702 [==============================] - 1s - loss: 4.3286e-05 - acc: 0.0000e+00 - val_loss: 8.2068e-05 - val_acc: 0.0000e+00\n",
      "Epoch 170/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.8856e-05 - acc: 0.0000e+00 - val_loss: 8.1019e-05 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.4046e-05 - acc: 0.0000e+00 - val_loss: 7.9796e-05 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.4647e-05 - acc: 0.0000e+00 - val_loss: 3.4785e-04 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.3621e-05 - acc: 0.0000e+00 - val_loss: 7.7378e-05 - val_acc: 0.0000e+00\n",
      "Epoch 174/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.3630e-05 - acc: 0.0000e+00 - val_loss: 1.4229e-04 - val_acc: 0.0000e+00\n",
      "Epoch 175/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5626e-05 - acc: 0.0000e+00 - val_loss: 8.6298e-05 - val_acc: 0.0000e+00\n",
      "Epoch 176/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5509e-05 - acc: 0.0000e+00 - val_loss: 7.7310e-05 - val_acc: 0.0000e+00\n",
      "Epoch 177/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.3379e-05 - acc: 0.0000e+00 - val_loss: 8.0368e-05 - val_acc: 0.0000e+00\n",
      "Epoch 178/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9485e-05 - acc: 0.0000e+00 - val_loss: 8.2315e-05 - val_acc: 0.0000e+00\n",
      "Epoch 179/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5289e-05 - acc: 0.0000e+00 - val_loss: 7.9582e-05 - val_acc: 0.0000e+00\n",
      "Epoch 180/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.4012e-05 - acc: 0.0000e+00 - val_loss: 1.0335e-04 - val_acc: 0.0000e+00\n",
      "Epoch 181/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.4789e-05 - acc: 0.0000e+00 - val_loss: 1.1798e-04 - val_acc: 0.0000e+00\n",
      "Epoch 182/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.7491e-05 - acc: 0.0000e+00 - val_loss: 1.0820e-04 - val_acc: 0.0000e+00\n",
      "Epoch 183/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0914e-05 - acc: 0.0000e+00 - val_loss: 8.0923e-05 - val_acc: 0.0000e+00\n",
      "Epoch 184/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0846e-05 - acc: 0.0000e+00 - val_loss: 8.1908e-05 - val_acc: 0.0000e+00\n",
      "Epoch 185/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.3368e-05 - acc: 0.0000e+00 - val_loss: 8.4445e-05 - val_acc: 0.0000e+00\n",
      "Epoch 186/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.1003e-05 - acc: 0.0000e+00 - val_loss: 1.8884e-04 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1101e-05 - acc: 0.0000e+00 - val_loss: 7.4257e-05 - val_acc: 0.0000e+00\n",
      "Epoch 188/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2709e-05 - acc: 0.0000e+00 - val_loss: 8.5550e-05 - val_acc: 0.0000e+00\n",
      "Epoch 189/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1223e-05 - acc: 0.0000e+00 - val_loss: 7.0636e-05 - val_acc: 0.0000e+00\n",
      "Epoch 190/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2044e-05 - acc: 0.0000e+00 - val_loss: 7.1331e-05 - val_acc: 0.0000e+00\n",
      "Epoch 191/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8226e-05 - acc: 0.0000e+00 - val_loss: 7.0614e-05 - val_acc: 0.0000e+00\n",
      "Epoch 192/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1523e-05 - acc: 0.0000e+00 - val_loss: 1.6285e-04 - val_acc: 0.0000e+00\n",
      "Epoch 193/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2150e-05 - acc: 0.0000e+00 - val_loss: 1.0862e-04 - val_acc: 0.0000e+00\n",
      "Epoch 194/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.3093e-05 - acc: 0.0000e+00 - val_loss: 8.2521e-05 - val_acc: 0.0000e+00\n",
      "Epoch 195/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2789e-05 - acc: 0.0000e+00 - val_loss: 7.7972e-05 - val_acc: 0.0000e+00\n",
      "Epoch 196/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2348e-05 - acc: 0.0000e+00 - val_loss: 7.1500e-05 - val_acc: 0.0000e+00\n",
      "Epoch 197/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7617e-05 - acc: 0.0000e+00 - val_loss: 7.2346e-05 - val_acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0044e-05 - acc: 0.0000e+00 - val_loss: 1.1966e-04 - val_acc: 0.0000e+00\n",
      "Epoch 199/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0658e-05 - acc: 0.0000e+00 - val_loss: 7.9133e-05 - val_acc: 0.0000e+00\n",
      "Epoch 200/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5553e-05 - acc: 0.0000e+00 - val_loss: 8.5315e-05 - val_acc: 0.0000e+00\n",
      "Epoch 201/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2808e-05 - acc: 0.0000e+00 - val_loss: 8.0536e-05 - val_acc: 0.0000e+00\n",
      "Epoch 202/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6987e-05 - acc: 0.0000e+00 - val_loss: 9.8398e-05 - val_acc: 0.0000e+00\n",
      "Epoch 203/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7802e-05 - acc: 0.0000e+00 - val_loss: 9.2561e-05 - val_acc: 0.0000e+00\n",
      "Epoch 204/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0227e-05 - acc: 0.0000e+00 - val_loss: 1.2509e-04 - val_acc: 0.0000e+00\n",
      "Epoch 205/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8934e-05 - acc: 0.0000e+00 - val_loss: 1.1282e-04 - val_acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7450e-05 - acc: 0.0000e+00 - val_loss: 1.1969e-04 - val_acc: 0.0000e+00\n",
      "Epoch 207/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.8156e-05 - acc: 0.0000e+00 - val_loss: 7.3591e-05 - val_acc: 0.0000e+00\n",
      "Epoch 208/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5327e-05 - acc: 0.0000e+00 - val_loss: 2.8344e-04 - val_acc: 0.0000e+00\n",
      "Epoch 209/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1806e-05 - acc: 0.0000e+00 - val_loss: 1.5859e-04 - val_acc: 0.0000e+00\n",
      "Epoch 210/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.9205e-05 - acc: 0.0000e+00 - val_loss: 7.0207e-05 - val_acc: 0.0000e+00\n",
      "Epoch 211/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0453e-05 - acc: 0.0000e+00 - val_loss: 6.7260e-05 - val_acc: 0.0000e+00\n",
      "Epoch 212/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7592e-05 - acc: 0.0000e+00 - val_loss: 9.8865e-05 - val_acc: 0.0000e+00\n",
      "Epoch 213/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5711e-05 - acc: 0.0000e+00 - val_loss: 6.8217e-05 - val_acc: 0.0000e+00\n",
      "Epoch 214/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7225e-05 - acc: 0.0000e+00 - val_loss: 8.5594e-05 - val_acc: 0.0000e+00\n",
      "Epoch 215/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.9400e-05 - acc: 0.0000e+00 - val_loss: 6.5842e-05 - val_acc: 0.0000e+00\n",
      "Epoch 216/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6866e-05 - acc: 0.0000e+00 - val_loss: 1.1780e-04 - val_acc: 0.0000e+00\n",
      "Epoch 217/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.9935e-05 - acc: 0.0000e+00 - val_loss: 8.3443e-05 - val_acc: 0.0000e+00\n",
      "Epoch 218/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0523e-05 - acc: 0.0000e+00 - val_loss: 6.5758e-05 - val_acc: 0.0000e+00\n",
      "Epoch 219/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7439e-05 - acc: 0.0000e+00 - val_loss: 1.1879e-04 - val_acc: 0.0000e+00\n",
      "Epoch 220/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0186e-05 - acc: 0.0000e+00 - val_loss: 6.7562e-05 - val_acc: 0.0000e+00\n",
      "Epoch 221/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6142e-05 - acc: 0.0000e+00 - val_loss: 6.6271e-05 - val_acc: 0.0000e+00\n",
      "Epoch 222/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5955e-05 - acc: 0.0000e+00 - val_loss: 6.4476e-05 - val_acc: 0.0000e+00\n",
      "Epoch 223/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6291e-05 - acc: 0.0000e+00 - val_loss: 7.6671e-05 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.9985e-05 - acc: 0.0000e+00 - val_loss: 2.5067e-04 - val_acc: 0.0000e+00\n",
      "Epoch 225/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13702/13702 [==============================] - 1s - loss: 4.2122e-05 - acc: 0.0000e+00 - val_loss: 8.8204e-05 - val_acc: 0.0000e+00\n",
      "Epoch 226/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0988e-05 - acc: 0.0000e+00 - val_loss: 9.4153e-05 - val_acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5446e-05 - acc: 0.0000e+00 - val_loss: 8.0506e-05 - val_acc: 0.0000e+00\n",
      "Epoch 228/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7963e-05 - acc: 0.0000e+00 - val_loss: 1.0311e-04 - val_acc: 0.0000e+00\n",
      "Epoch 229/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0119e-05 - acc: 0.0000e+00 - val_loss: 6.7661e-05 - val_acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.7685e-05 - acc: 0.0000e+00 - val_loss: 6.3728e-05 - val_acc: 0.0000e+00\n",
      "Epoch 231/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.9021e-05 - acc: 0.0000e+00 - val_loss: 6.4773e-05 - val_acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6028e-05 - acc: 0.0000e+00 - val_loss: 7.2746e-05 - val_acc: 0.0000e+00\n",
      "Epoch 233/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7445e-05 - acc: 0.0000e+00 - val_loss: 6.8802e-05 - val_acc: 0.0000e+00\n",
      "Epoch 234/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6022e-05 - acc: 0.0000e+00 - val_loss: 1.1188e-04 - val_acc: 0.0000e+00\n",
      "Epoch 235/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7940e-05 - acc: 0.0000e+00 - val_loss: 6.3546e-05 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8099e-05 - acc: 0.0000e+00 - val_loss: 6.4229e-05 - val_acc: 0.0000e+00\n",
      "Epoch 237/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4901e-05 - acc: 0.0000e+00 - val_loss: 6.4413e-05 - val_acc: 0.0000e+00\n",
      "Epoch 238/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7071e-05 - acc: 0.0000e+00 - val_loss: 7.5773e-05 - val_acc: 0.0000e+00\n",
      "Epoch 239/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7732e-05 - acc: 0.0000e+00 - val_loss: 8.0782e-05 - val_acc: 0.0000e+00\n",
      "Epoch 240/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3699e-05 - acc: 0.0000e+00 - val_loss: 6.1495e-05 - val_acc: 0.0000e+00\n",
      "Epoch 241/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7764e-05 - acc: 0.0000e+00 - val_loss: 6.4131e-05 - val_acc: 0.0000e+00\n",
      "Epoch 242/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5304e-05 - acc: 0.0000e+00 - val_loss: 6.5291e-05 - val_acc: 0.0000e+00\n",
      "Epoch 243/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6321e-05 - acc: 0.0000e+00 - val_loss: 6.7608e-05 - val_acc: 0.0000e+00\n",
      "Epoch 244/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6597e-05 - acc: 0.0000e+00 - val_loss: 9.4927e-05 - val_acc: 0.0000e+00\n",
      "Epoch 245/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0937e-05 - acc: 0.0000e+00 - val_loss: 6.1051e-05 - val_acc: 0.0000e+00\n",
      "Epoch 246/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2427e-05 - acc: 0.0000e+00 - val_loss: 6.6117e-05 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0185e-05 - acc: 0.0000e+00 - val_loss: 6.3301e-05 - val_acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6776e-05 - acc: 0.0000e+00 - val_loss: 7.5333e-05 - val_acc: 0.0000e+00\n",
      "Epoch 249/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5267e-05 - acc: 0.0000e+00 - val_loss: 1.0073e-04 - val_acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8285e-05 - acc: 0.0000e+00 - val_loss: 6.2572e-05 - val_acc: 0.0000e+00\n",
      "Epoch 251/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7131e-05 - acc: 0.0000e+00 - val_loss: 1.7364e-04 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6691e-05 - acc: 0.0000e+00 - val_loss: 6.7703e-05 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3738e-05 - acc: 0.0000e+00 - val_loss: 6.5763e-05 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5767e-05 - acc: 0.0000e+00 - val_loss: 6.4723e-05 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4830e-05 - acc: 0.0000e+00 - val_loss: 7.1629e-05 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6271e-05 - acc: 0.0000e+00 - val_loss: 6.1238e-05 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4799e-05 - acc: 0.0000e+00 - val_loss: 8.5129e-05 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6095e-05 - acc: 0.0000e+00 - val_loss: 6.5438e-05 - val_acc: 0.0000e+00\n",
      "Epoch 259/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.2788e-05 - acc: 0.0000e+00 - val_loss: 1.1204e-04 - val_acc: 0.0000e+00\n",
      "Epoch 260/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7510e-05 - acc: 0.0000e+00 - val_loss: 6.5620e-05 - val_acc: 0.0000e+00\n",
      "Epoch 261/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3250e-05 - acc: 0.0000e+00 - val_loss: 7.5485e-05 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.2431e-05 - acc: 0.0000e+00 - val_loss: 6.7315e-05 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.1903e-05 - acc: 0.0000e+00 - val_loss: 6.2988e-05 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3992e-05 - acc: 0.0000e+00 - val_loss: 8.6322e-05 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3767e-05 - acc: 0.0000e+00 - val_loss: 6.3221e-05 - val_acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.1139e-05 - acc: 0.0000e+00 - val_loss: 6.3224e-05 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4206e-05 - acc: 0.0000e+00 - val_loss: 6.1757e-05 - val_acc: 0.0000e+00\n",
      "Epoch 268/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.1289e-05 - acc: 0.0000e+00 - val_loss: 1.1206e-04 - val_acc: 0.0000e+00\n",
      "Epoch 269/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.0756e-05 - acc: 0.0000e+00 - val_loss: 6.0048e-05 - val_acc: 0.0000e+00\n",
      "Epoch 270/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4448e-05 - acc: 0.0000e+00 - val_loss: 2.3299e-04 - val_acc: 0.0000e+00\n",
      "Epoch 271/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0538e-05 - acc: 0.0000e+00 - val_loss: 8.6511e-05 - val_acc: 0.0000e+00\n",
      "Epoch 272/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4137e-05 - acc: 0.0000e+00 - val_loss: 8.2772e-05 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.2439e-05 - acc: 0.0000e+00 - val_loss: 1.2354e-04 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4925e-05 - acc: 0.0000e+00 - val_loss: 7.1628e-05 - val_acc: 0.0000e+00\n",
      "Epoch 275/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3042e-05 - acc: 0.0000e+00 - val_loss: 5.7916e-05 - val_acc: 0.0000e+00\n",
      "Epoch 276/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.1768e-05 - acc: 0.0000e+00 - val_loss: 8.0502e-05 - val_acc: 0.0000e+00\n",
      "Epoch 277/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3913e-05 - acc: 0.0000e+00 - val_loss: 6.1111e-05 - val_acc: 0.0000e+00\n",
      "Epoch 278/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6178e-05 - acc: 0.0000e+00 - val_loss: 9.6754e-05 - val_acc: 0.0000e+00\n",
      "Epoch 279/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3646e-05 - acc: 0.0000e+00 - val_loss: 8.7504e-05 - val_acc: 0.0000e+00\n",
      "Epoch 280/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.2112e-05 - acc: 0.0000e+00 - val_loss: 1.0438e-04 - val_acc: 0.0000e+00\n",
      "Epoch 281/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13702/13702 [==============================] - 1s - loss: 3.3599e-05 - acc: 0.0000e+00 - val_loss: 6.4390e-05 - val_acc: 0.0000e+00\n",
      "Epoch 282/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8564e-05 - acc: 0.0000e+00 - val_loss: 7.8942e-05 - val_acc: 0.0000e+00\n",
      "Epoch 283/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5432e-05 - acc: 0.0000e+00 - val_loss: 6.9701e-05 - val_acc: 0.0000e+00\n",
      "Epoch 284/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6280e-05 - acc: 0.0000e+00 - val_loss: 7.1961e-05 - val_acc: 0.0000e+00\n",
      "Epoch 285/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.4807e-05 - acc: 0.0000e+00 - val_loss: 1.9348e-04 - val_acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5989e-05 - acc: 0.0000e+00 - val_loss: 6.2614e-05 - val_acc: 0.0000e+00\n",
      "Epoch 287/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3820e-05 - acc: 0.0000e+00 - val_loss: 9.6478e-05 - val_acc: 0.0000e+00\n",
      "Epoch 288/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.2979e-05 - acc: 0.0000e+00 - val_loss: 1.0354e-04 - val_acc: 0.0000e+00\n",
      "Epoch 289/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3160e-05 - acc: 0.0000e+00 - val_loss: 1.0529e-04 - val_acc: 0.0000e+00\n",
      "Epoch 290/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5468e-05 - acc: 0.0000e+00 - val_loss: 6.8319e-05 - val_acc: 0.0000e+00\n",
      "Epoch 291/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5597e-05 - acc: 0.0000e+00 - val_loss: 1.4740e-04 - val_acc: 0.0000e+00\n",
      "Epoch 292/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.1912e-05 - acc: 0.0000e+00 - val_loss: 5.7989e-05 - val_acc: 0.0000e+00\n",
      "Epoch 293/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3086e-05 - acc: 0.0000e+00 - val_loss: 6.8591e-05 - val_acc: 0.0000e+00\n",
      "Epoch 294/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3070e-05 - acc: 0.0000e+00 - val_loss: 7.1520e-05 - val_acc: 0.0000e+00\n",
      "Epoch 295/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.0114e-05 - acc: 0.0000e+00 - val_loss: 5.4224e-05 - val_acc: 0.0000e+00\n",
      "Epoch 296/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.1893e-05 - acc: 0.0000e+00 - val_loss: 8.7936e-05 - val_acc: 0.0000e+00\n",
      "Epoch 297/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.0466e-05 - acc: 0.0000e+00 - val_loss: 5.5904e-05 - val_acc: 0.0000e+00\n",
      "Epoch 298/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.9420e-05 - acc: 0.0000e+00 - val_loss: 6.4212e-05 - val_acc: 0.0000e+00\n",
      "Epoch 299/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.0613e-05 - acc: 0.0000e+00 - val_loss: 6.6401e-05 - val_acc: 0.0000e+00\n",
      "Epoch 300/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.9649e-05 - acc: 0.0000e+00 - val_loss: 5.5303e-05 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20f9c11ae10>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=512,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.1,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Result on training set and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.00002 MSE (0.00 RMSE)\n",
      "Test Score: 0.00012 MSE (0.01 RMSE)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.3023599784263853e-05, 0.00012482673341001607)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model_score(model, X_train, y_train, X_test, y_test):\n",
    "    trainScore = model.evaluate(X_train, y_train, verbose=0)\n",
    "    print('Train Score: %.5f MSE (%.2f RMSE)' % (trainScore[0], math.sqrt(trainScore[0])))\n",
    "\n",
    "    testScore = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test Score: %.5f MSE (%.2f RMSE)' % (testScore[0], math.sqrt(testScore[0])))\n",
    "    return trainScore[0], testScore[0]\n",
    "    \n",
    "model_score(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Prediction vs Real results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def percentage_difference(model, X_test, y_test):\n",
    "    percentage_diff=[]\n",
    "\n",
    "    p = model.predict(X_test)\n",
    "    for u in range(len(y_test)): # for each data index in test data\n",
    "        pr = p[u][0] # pr = prediction on day u\n",
    "\n",
    "        percentage_diff.append((pr-y_test[u]/pr)*100)\n",
    "    return p\n",
    "\n",
    "p = percentage_difference(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Plot out prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def denormalize(stock_name, normalized_value):\n",
    "    start = datetime.datetime(2000, 1, 1)\n",
    "    end = datetime.date.today()\n",
    "    df = web.DataReader(stock_name, \"yahoo\", start, end)\n",
    "    \n",
    "    df = df['Adj Close'][-round(0.9 * len(df)):].values.reshape(-1,1)\n",
    "    normalized_value = normalized_value.reshape(-1,1)\n",
    "    \n",
    "    #return df.shape, p.shape\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    a = min_max_scaler.fit_transform(df)\n",
    "    new = min_max_scaler.inverse_transform(normalized_value)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD8CAYAAACYebj1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20f8cddae80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_result(stock_name, normalized_value_p, normalized_value_y_test):\n",
    "    newp = denormalize(stock_name, normalized_value_p)\n",
    "    newy_test = denormalize(stock_name, normalized_value_y_test)\n",
    "    plt2.plot(newp, color='red', label='Prediction')\n",
    "    plt2.plot(newy_test,color='blue', label='Actual')\n",
    "    plt2.legend(loc='best')\n",
    "    plt2.show()\n",
    "\n",
    "plot_result(stock_name, p, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Save for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('LSTM_Stock_prediction-20170429.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. Fine tune model\n",
    "# 11. Function to load data, train model and see score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stock_name = '^GSPC'\n",
    "seq_len = 22\n",
    "shape = [4, seq_len, 1] # feature, window, output\n",
    "neurons = [128, 128, 32, 1]\n",
    "epochs = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def quick_measure(stock_name, seq_len, d, shape, neurons, epochs):\n",
    "    df = get_stock_data(stock_name)\n",
    "    X_train, y_train, X_test, y_test = load_data(df, seq_len)\n",
    "    model = build_model2(shape, neurons, d)\n",
    "    model.fit(X_train, y_train, batch_size=512, epochs=epochs, validation_split=0.1, verbose=1)\n",
    "    trainScore, testScore = model_score(model, X_train, y_train, X_test, y_test)\n",
    "    return trainScore, testScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Fine tune hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.1 Optimial Dropout value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_23 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_24 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13702 samples, validate on 1523 samples\n",
      "Epoch 1/300\n",
      "13702/13702 [==============================] - 3s - loss: 0.0123 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.1290e-04 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.5709e-04 - acc: 0.0000e+00 - val_loss: 5.8588e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6717e-04 - acc: 0.0000e+00 - val_loss: 3.3226e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4297e-04 - acc: 0.0000e+00 - val_loss: 3.2287e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4404e-04 - acc: 0.0000e+00 - val_loss: 2.4426e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3121e-04 - acc: 0.0000e+00 - val_loss: 2.3651e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3057e-04 - acc: 0.0000e+00 - val_loss: 2.3421e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1669e-04 - acc: 0.0000e+00 - val_loss: 2.1885e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1981e-04 - acc: 0.0000e+00 - val_loss: 2.1407e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1986e-04 - acc: 0.0000e+00 - val_loss: 2.2460e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2441e-04 - acc: 0.0000e+00 - val_loss: 2.2776e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2866e-04 - acc: 0.0000e+00 - val_loss: 2.2096e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0664e-04 - acc: 0.0000e+00 - val_loss: 3.0566e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1256e-04 - acc: 0.0000e+00 - val_loss: 2.1723e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0788e-04 - acc: 0.0000e+00 - val_loss: 3.1061e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2603e-04 - acc: 0.0000e+00 - val_loss: 3.1244e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0386e-04 - acc: 0.0000e+00 - val_loss: 2.0555e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0253e-04 - acc: 0.0000e+00 - val_loss: 2.4896e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0693e-04 - acc: 0.0000e+00 - val_loss: 1.9817e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0477e-04 - acc: 0.0000e+00 - val_loss: 1.9123e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.9920e-05 - acc: 0.0000e+00 - val_loss: 1.9331e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0211e-04 - acc: 0.0000e+00 - val_loss: 3.9175e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0288e-04 - acc: 0.0000e+00 - val_loss: 1.8979e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.5724e-05 - acc: 0.0000e+00 - val_loss: 5.1282e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2098e-04 - acc: 0.0000e+00 - val_loss: 5.4900e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1463e-04 - acc: 0.0000e+00 - val_loss: 1.8485e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.6437e-05 - acc: 0.0000e+00 - val_loss: 1.8040e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.8043e-05 - acc: 0.0000e+00 - val_loss: 1.8142e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0275e-04 - acc: 0.0000e+00 - val_loss: 7.6693e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0822e-04 - acc: 0.0000e+00 - val_loss: 2.7135e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.6028e-05 - acc: 0.0000e+00 - val_loss: 2.4015e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.9982e-05 - acc: 0.0000e+00 - val_loss: 4.2595e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1808e-04 - acc: 0.0000e+00 - val_loss: 4.9746e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.1130e-05 - acc: 0.0000e+00 - val_loss: 1.6837e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3145e-05 - acc: 0.0000e+00 - val_loss: 3.7832e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0072e-04 - acc: 0.0000e+00 - val_loss: 1.9095e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.6040e-05 - acc: 0.0000e+00 - val_loss: 2.3212e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3378e-05 - acc: 0.0000e+00 - val_loss: 2.1129e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0736e-04 - acc: 0.0000e+00 - val_loss: 2.3474e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.0708e-05 - acc: 0.0000e+00 - val_loss: 2.0846e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.4410e-05 - acc: 0.0000e+00 - val_loss: 4.0471e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.5829e-05 - acc: 0.0000e+00 - val_loss: 1.7980e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.7148e-05 - acc: 0.0000e+00 - val_loss: 2.2672e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.6467e-05 - acc: 0.0000e+00 - val_loss: 1.6527e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.8956e-05 - acc: 0.0000e+00 - val_loss: 1.5316e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3517e-05 - acc: 0.0000e+00 - val_loss: 2.4350e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0047e-04 - acc: 0.0000e+00 - val_loss: 2.2527e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13702/13702 [==============================] - 1s - loss: 9.4744e-05 - acc: 0.0000e+00 - val_loss: 2.4658e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.4697e-05 - acc: 0.0000e+00 - val_loss: 7.1417e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.9894e-05 - acc: 0.0000e+00 - val_loss: 1.7327e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.6464e-05 - acc: 0.0000e+00 - val_loss: 1.9872e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.4104e-05 - acc: 0.0000e+00 - val_loss: 1.4537e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9031e-05 - acc: 0.0000e+00 - val_loss: 1.5018e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0498e-05 - acc: 0.0000e+00 - val_loss: 1.9391e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.8731e-05 - acc: 0.0000e+00 - val_loss: 4.2608e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.4652e-05 - acc: 0.0000e+00 - val_loss: 1.4286e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0342e-05 - acc: 0.0000e+00 - val_loss: 1.4503e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8373e-05 - acc: 0.0000e+00 - val_loss: 3.5593e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3971e-05 - acc: 0.0000e+00 - val_loss: 1.3961e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4806e-05 - acc: 0.0000e+00 - val_loss: 1.3406e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.8763e-05 - acc: 0.0000e+00 - val_loss: 3.3798e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3006e-05 - acc: 0.0000e+00 - val_loss: 4.0789e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.2073e-05 - acc: 0.0000e+00 - val_loss: 2.4725e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.6317e-05 - acc: 0.0000e+00 - val_loss: 1.5536e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1087e-05 - acc: 0.0000e+00 - val_loss: 1.2853e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.7961e-05 - acc: 0.0000e+00 - val_loss: 1.2647e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7853e-05 - acc: 0.0000e+00 - val_loss: 1.3903e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1144e-04 - acc: 0.0000e+00 - val_loss: 8.3362e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0544e-04 - acc: 0.0000e+00 - val_loss: 1.3260e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1093e-05 - acc: 0.0000e+00 - val_loss: 1.2645e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1560e-05 - acc: 0.0000e+00 - val_loss: 1.3493e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0969e-05 - acc: 0.0000e+00 - val_loss: 1.8404e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1100e-05 - acc: 0.0000e+00 - val_loss: 1.1951e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.9350e-05 - acc: 0.0000e+00 - val_loss: 1.2378e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0891e-05 - acc: 0.0000e+00 - val_loss: 1.8719e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.6089e-05 - acc: 0.0000e+00 - val_loss: 1.1840e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2160e-05 - acc: 0.0000e+00 - val_loss: 1.1477e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.5178e-05 - acc: 0.0000e+00 - val_loss: 1.1543e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8477e-05 - acc: 0.0000e+00 - val_loss: 3.4239e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.9410e-05 - acc: 0.0000e+00 - val_loss: 4.6259e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.6896e-05 - acc: 0.0000e+00 - val_loss: 1.1210e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7344e-05 - acc: 0.0000e+00 - val_loss: 1.2616e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7979e-05 - acc: 0.0000e+00 - val_loss: 1.7375e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2977e-05 - acc: 0.0000e+00 - val_loss: 1.2358e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0999e-05 - acc: 0.0000e+00 - val_loss: 1.0986e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.5990e-05 - acc: 0.0000e+00 - val_loss: 1.0956e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4864e-05 - acc: 0.0000e+00 - val_loss: 1.4691e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0564e-05 - acc: 0.0000e+00 - val_loss: 1.1077e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.1718e-05 - acc: 0.0000e+00 - val_loss: 1.4056e-04 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4649e-05 - acc: 0.0000e+00 - val_loss: 1.5310e-04 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.9371e-05 - acc: 0.0000e+00 - val_loss: 2.1123e-04 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.5651e-05 - acc: 0.0000e+00 - val_loss: 1.3451e-04 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2044e-05 - acc: 0.0000e+00 - val_loss: 1.0733e-04 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7127e-05 - acc: 0.0000e+00 - val_loss: 1.0775e-04 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.1679e-05 - acc: 0.0000e+00 - val_loss: 1.1235e-04 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2835e-05 - acc: 0.0000e+00 - val_loss: 1.1231e-04 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.8254e-05 - acc: 0.0000e+00 - val_loss: 1.0388e-04 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.5250e-05 - acc: 0.0000e+00 - val_loss: 2.1472e-04 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3003e-05 - acc: 0.0000e+00 - val_loss: 1.0253e-04 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8087e-05 - acc: 0.0000e+00 - val_loss: 1.0509e-04 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3079e-05 - acc: 0.0000e+00 - val_loss: 1.3390e-04 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.1614e-05 - acc: 0.0000e+00 - val_loss: 1.0420e-04 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8111e-05 - acc: 0.0000e+00 - val_loss: 1.0093e-04 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13702/13702 [==============================] - 1s - loss: 6.0134e-05 - acc: 0.0000e+00 - val_loss: 1.1251e-04 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2084e-05 - acc: 0.0000e+00 - val_loss: 9.9580e-05 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0559e-05 - acc: 0.0000e+00 - val_loss: 1.0106e-04 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6692e-05 - acc: 0.0000e+00 - val_loss: 3.9671e-04 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4779e-05 - acc: 0.0000e+00 - val_loss: 2.5309e-04 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.9265e-05 - acc: 0.0000e+00 - val_loss: 1.9515e-04 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4985e-05 - acc: 0.0000e+00 - val_loss: 9.7191e-05 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.0570e-05 - acc: 0.0000e+00 - val_loss: 9.6109e-05 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.1057e-05 - acc: 0.0000e+00 - val_loss: 1.0714e-04 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.7057e-05 - acc: 0.0000e+00 - val_loss: 1.6175e-04 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.6837e-05 - acc: 0.0000e+00 - val_loss: 1.2669e-04 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9870e-05 - acc: 0.0000e+00 - val_loss: 2.8617e-04 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1762e-05 - acc: 0.0000e+00 - val_loss: 9.6694e-05 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.4347e-05 - acc: 0.0000e+00 - val_loss: 9.4449e-05 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.4911e-05 - acc: 0.0000e+00 - val_loss: 2.2940e-04 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7833e-05 - acc: 0.0000e+00 - val_loss: 1.0037e-04 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.5155e-05 - acc: 0.0000e+00 - val_loss: 9.5358e-05 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.0857e-05 - acc: 0.0000e+00 - val_loss: 1.2387e-04 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9933e-05 - acc: 0.0000e+00 - val_loss: 1.7985e-04 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8989e-05 - acc: 0.0000e+00 - val_loss: 2.1588e-04 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.1304e-05 - acc: 0.0000e+00 - val_loss: 1.5945e-04 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.7798e-05 - acc: 0.0000e+00 - val_loss: 1.0715e-04 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.1221e-05 - acc: 0.0000e+00 - val_loss: 1.2188e-04 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4743e-05 - acc: 0.0000e+00 - val_loss: 4.0982e-04 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6189e-05 - acc: 0.0000e+00 - val_loss: 1.1139e-04 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.7591e-05 - acc: 0.0000e+00 - val_loss: 8.8826e-05 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.4324e-05 - acc: 0.0000e+00 - val_loss: 1.6814e-04 - val_acc: 0.0000e+00\n",
      "Epoch 132/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.0033e-05 - acc: 0.0000e+00 - val_loss: 2.4726e-04 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.1173e-05 - acc: 0.0000e+00 - val_loss: 2.0419e-04 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.6220e-05 - acc: 0.0000e+00 - val_loss: 8.8416e-05 - val_acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.0618e-05 - acc: 0.0000e+00 - val_loss: 1.2417e-04 - val_acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.1297e-05 - acc: 0.0000e+00 - val_loss: 8.9584e-05 - val_acc: 0.0000e+00\n",
      "Epoch 137/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.8641e-05 - acc: 0.0000e+00 - val_loss: 9.1096e-05 - val_acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.0895e-05 - acc: 0.0000e+00 - val_loss: 2.1268e-04 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.0538e-05 - acc: 0.0000e+00 - val_loss: 9.0727e-05 - val_acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.0730e-05 - acc: 0.0000e+00 - val_loss: 9.0720e-05 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5832e-05 - acc: 0.0000e+00 - val_loss: 9.0971e-05 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6666e-05 - acc: 0.0000e+00 - val_loss: 1.7177e-04 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3076e-05 - acc: 0.0000e+00 - val_loss: 1.5484e-04 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.6469e-05 - acc: 0.0000e+00 - val_loss: 1.4650e-04 - val_acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3577e-05 - acc: 0.0000e+00 - val_loss: 8.5639e-05 - val_acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.8548e-05 - acc: 0.0000e+00 - val_loss: 9.2792e-05 - val_acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.8269e-05 - acc: 0.0000e+00 - val_loss: 1.1983e-04 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5031e-05 - acc: 0.0000e+00 - val_loss: 1.1144e-04 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.7550e-05 - acc: 0.0000e+00 - val_loss: 8.5693e-05 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5140e-05 - acc: 0.0000e+00 - val_loss: 1.0523e-04 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6394e-05 - acc: 0.0000e+00 - val_loss: 8.6729e-05 - val_acc: 0.0000e+00\n",
      "Epoch 152/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5853e-05 - acc: 0.0000e+00 - val_loss: 1.3613e-04 - val_acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.3148e-05 - acc: 0.0000e+00 - val_loss: 1.0589e-04 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6485e-05 - acc: 0.0000e+00 - val_loss: 8.8370e-05 - val_acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2606e-05 - acc: 0.0000e+00 - val_loss: 1.5000e-04 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.4574e-05 - acc: 0.0000e+00 - val_loss: 8.3302e-05 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.8345e-05 - acc: 0.0000e+00 - val_loss: 8.1770e-05 - val_acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.8819e-05 - acc: 0.0000e+00 - val_loss: 1.2108e-04 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6766e-05 - acc: 0.0000e+00 - val_loss: 2.1463e-04 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.0432e-05 - acc: 0.0000e+00 - val_loss: 1.0140e-04 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13702/13702 [==============================] - 1s - loss: 4.9750e-05 - acc: 0.0000e+00 - val_loss: 1.5147e-04 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2750e-05 - acc: 0.0000e+00 - val_loss: 8.4485e-05 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1993e-05 - acc: 0.0000e+00 - val_loss: 8.8429e-05 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.8208e-05 - acc: 0.0000e+00 - val_loss: 1.3213e-04 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.8998e-05 - acc: 0.0000e+00 - val_loss: 2.2894e-04 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6933e-05 - acc: 0.0000e+00 - val_loss: 8.4207e-05 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2394e-05 - acc: 0.0000e+00 - val_loss: 7.7307e-05 - val_acc: 0.0000e+00\n",
      "Epoch 168/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0930e-05 - acc: 0.0000e+00 - val_loss: 7.8462e-05 - val_acc: 0.0000e+00\n",
      "Epoch 169/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2324e-05 - acc: 0.0000e+00 - val_loss: 1.2096e-04 - val_acc: 0.0000e+00\n",
      "Epoch 170/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1394e-05 - acc: 0.0000e+00 - val_loss: 7.6758e-05 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.3034e-05 - acc: 0.0000e+00 - val_loss: 7.7058e-05 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5723e-05 - acc: 0.0000e+00 - val_loss: 1.0510e-04 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.4027e-05 - acc: 0.0000e+00 - val_loss: 7.5915e-05 - val_acc: 0.0000e+00\n",
      "Epoch 174/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2158e-05 - acc: 0.0000e+00 - val_loss: 1.2165e-04 - val_acc: 0.0000e+00\n",
      "Epoch 175/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0756e-05 - acc: 0.0000e+00 - val_loss: 7.4398e-05 - val_acc: 0.0000e+00\n",
      "Epoch 176/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.3938e-05 - acc: 0.0000e+00 - val_loss: 1.3867e-04 - val_acc: 0.0000e+00\n",
      "Epoch 177/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1760e-05 - acc: 0.0000e+00 - val_loss: 1.0736e-04 - val_acc: 0.0000e+00\n",
      "Epoch 178/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0882e-05 - acc: 0.0000e+00 - val_loss: 7.8257e-05 - val_acc: 0.0000e+00\n",
      "Epoch 179/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1662e-05 - acc: 0.0000e+00 - val_loss: 7.2582e-05 - val_acc: 0.0000e+00\n",
      "Epoch 180/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.3589e-05 - acc: 0.0000e+00 - val_loss: 1.0486e-04 - val_acc: 0.0000e+00\n",
      "Epoch 181/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8277e-05 - acc: 0.0000e+00 - val_loss: 8.6050e-05 - val_acc: 0.0000e+00\n",
      "Epoch 182/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2094e-05 - acc: 0.0000e+00 - val_loss: 7.2336e-05 - val_acc: 0.0000e+00\n",
      "Epoch 183/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.9017e-05 - acc: 0.0000e+00 - val_loss: 8.8631e-05 - val_acc: 0.0000e+00\n",
      "Epoch 184/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1919e-05 - acc: 0.0000e+00 - val_loss: 8.6352e-05 - val_acc: 0.0000e+00\n",
      "Epoch 185/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.4205e-05 - acc: 0.0000e+00 - val_loss: 8.4087e-05 - val_acc: 0.0000e+00\n",
      "Epoch 186/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0621e-05 - acc: 0.0000e+00 - val_loss: 2.2651e-04 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.9446e-05 - acc: 0.0000e+00 - val_loss: 2.0249e-04 - val_acc: 0.0000e+00\n",
      "Epoch 188/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1982e-05 - acc: 0.0000e+00 - val_loss: 7.5963e-05 - val_acc: 0.0000e+00\n",
      "Epoch 189/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6836e-05 - acc: 0.0000e+00 - val_loss: 6.8568e-05 - val_acc: 0.0000e+00\n",
      "Epoch 190/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.9830e-05 - acc: 0.0000e+00 - val_loss: 1.0648e-04 - val_acc: 0.0000e+00\n",
      "Epoch 191/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.9375e-05 - acc: 0.0000e+00 - val_loss: 1.8235e-04 - val_acc: 0.0000e+00\n",
      "Epoch 192/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5231e-05 - acc: 0.0000e+00 - val_loss: 8.9897e-05 - val_acc: 0.0000e+00\n",
      "Epoch 193/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6301e-05 - acc: 0.0000e+00 - val_loss: 7.7314e-05 - val_acc: 0.0000e+00\n",
      "Epoch 194/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2690e-05 - acc: 0.0000e+00 - val_loss: 1.4797e-04 - val_acc: 0.0000e+00\n",
      "Epoch 195/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1040e-05 - acc: 0.0000e+00 - val_loss: 7.0861e-05 - val_acc: 0.0000e+00\n",
      "Epoch 196/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6772e-05 - acc: 0.0000e+00 - val_loss: 8.9291e-05 - val_acc: 0.0000e+00\n",
      "Epoch 197/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.3169e-05 - acc: 0.0000e+00 - val_loss: 9.5369e-05 - val_acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3642e-05 - acc: 0.0000e+00 - val_loss: 7.0723e-05 - val_acc: 0.0000e+00\n",
      "Epoch 199/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7814e-05 - acc: 0.0000e+00 - val_loss: 1.0433e-04 - val_acc: 0.0000e+00\n",
      "Epoch 200/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0268e-05 - acc: 0.0000e+00 - val_loss: 1.2548e-04 - val_acc: 0.0000e+00\n",
      "Epoch 201/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8579e-05 - acc: 0.0000e+00 - val_loss: 9.5098e-05 - val_acc: 0.0000e+00\n",
      "Epoch 202/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0300e-05 - acc: 0.0000e+00 - val_loss: 6.7650e-05 - val_acc: 0.0000e+00\n",
      "Epoch 203/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8469e-05 - acc: 0.0000e+00 - val_loss: 1.2109e-04 - val_acc: 0.0000e+00\n",
      "Epoch 204/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5271e-05 - acc: 0.0000e+00 - val_loss: 1.5652e-04 - val_acc: 0.0000e+00\n",
      "Epoch 205/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5847e-05 - acc: 0.0000e+00 - val_loss: 7.3234e-05 - val_acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5527e-05 - acc: 0.0000e+00 - val_loss: 1.0322e-04 - val_acc: 0.0000e+00\n",
      "Epoch 207/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5613e-05 - acc: 0.0000e+00 - val_loss: 7.0166e-05 - val_acc: 0.0000e+00\n",
      "Epoch 208/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3357e-05 - acc: 0.0000e+00 - val_loss: 6.4967e-05 - val_acc: 0.0000e+00\n",
      "Epoch 209/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3591e-05 - acc: 0.0000e+00 - val_loss: 9.0044e-05 - val_acc: 0.0000e+00\n",
      "Epoch 210/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.3924e-05 - acc: 0.0000e+00 - val_loss: 1.1533e-04 - val_acc: 0.0000e+00\n",
      "Epoch 211/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3258e-05 - acc: 0.0000e+00 - val_loss: 6.8120e-05 - val_acc: 0.0000e+00\n",
      "Epoch 212/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6803e-05 - acc: 0.0000e+00 - val_loss: 1.3296e-04 - val_acc: 0.0000e+00\n",
      "Epoch 213/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6044e-05 - acc: 0.0000e+00 - val_loss: 7.7379e-05 - val_acc: 0.0000e+00\n",
      "Epoch 214/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0587e-05 - acc: 0.0000e+00 - val_loss: 7.1456e-05 - val_acc: 0.0000e+00\n",
      "Epoch 215/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7728e-05 - acc: 0.0000e+00 - val_loss: 6.9028e-05 - val_acc: 0.0000e+00\n",
      "Epoch 216/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3368e-05 - acc: 0.0000e+00 - val_loss: 7.4349e-05 - val_acc: 0.0000e+00\n",
      "Epoch 217/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13702/13702 [==============================] - 1s - loss: 3.5140e-05 - acc: 0.0000e+00 - val_loss: 6.3795e-05 - val_acc: 0.0000e+00\n",
      "Epoch 218/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3937e-05 - acc: 0.0000e+00 - val_loss: 7.4056e-05 - val_acc: 0.0000e+00\n",
      "Epoch 219/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5262e-05 - acc: 0.0000e+00 - val_loss: 8.0809e-05 - val_acc: 0.0000e+00\n",
      "Epoch 220/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5615e-05 - acc: 0.0000e+00 - val_loss: 6.4038e-05 - val_acc: 0.0000e+00\n",
      "Epoch 221/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6467e-05 - acc: 0.0000e+00 - val_loss: 7.0325e-05 - val_acc: 0.0000e+00\n",
      "Epoch 222/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4067e-05 - acc: 0.0000e+00 - val_loss: 7.2915e-05 - val_acc: 0.0000e+00\n",
      "Epoch 223/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3146e-05 - acc: 0.0000e+00 - val_loss: 1.0270e-04 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6044e-05 - acc: 0.0000e+00 - val_loss: 6.3987e-05 - val_acc: 0.0000e+00\n",
      "Epoch 225/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2313e-05 - acc: 0.0000e+00 - val_loss: 8.4092e-05 - val_acc: 0.0000e+00\n",
      "Epoch 226/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7954e-05 - acc: 0.0000e+00 - val_loss: 6.3554e-05 - val_acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3668e-05 - acc: 0.0000e+00 - val_loss: 6.1982e-05 - val_acc: 0.0000e+00\n",
      "Epoch 228/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3725e-05 - acc: 0.0000e+00 - val_loss: 1.1369e-04 - val_acc: 0.0000e+00\n",
      "Epoch 229/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6952e-05 - acc: 0.0000e+00 - val_loss: 6.2471e-05 - val_acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.0417e-05 - acc: 0.0000e+00 - val_loss: 6.4579e-05 - val_acc: 0.0000e+00\n",
      "Epoch 231/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.2915e-05 - acc: 0.0000e+00 - val_loss: 6.8240e-05 - val_acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4998e-05 - acc: 0.0000e+00 - val_loss: 9.2426e-05 - val_acc: 0.0000e+00\n",
      "Epoch 233/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4591e-05 - acc: 0.0000e+00 - val_loss: 8.3948e-05 - val_acc: 0.0000e+00\n",
      "Epoch 234/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.2824e-05 - acc: 0.0000e+00 - val_loss: 6.6575e-05 - val_acc: 0.0000e+00\n",
      "Epoch 235/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.1968e-05 - acc: 0.0000e+00 - val_loss: 8.2998e-05 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5812e-05 - acc: 0.0000e+00 - val_loss: 6.1605e-05 - val_acc: 0.0000e+00\n",
      "Epoch 237/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4121e-05 - acc: 0.0000e+00 - val_loss: 8.1502e-05 - val_acc: 0.0000e+00\n",
      "Epoch 238/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3013e-05 - acc: 0.0000e+00 - val_loss: 7.8300e-05 - val_acc: 0.0000e+00\n",
      "Epoch 239/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4417e-05 - acc: 0.0000e+00 - val_loss: 9.4455e-05 - val_acc: 0.0000e+00\n",
      "Epoch 240/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3349e-05 - acc: 0.0000e+00 - val_loss: 6.2539e-05 - val_acc: 0.0000e+00\n",
      "Epoch 241/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6656e-05 - acc: 0.0000e+00 - val_loss: 7.9588e-05 - val_acc: 0.0000e+00\n",
      "Epoch 242/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.2592e-05 - acc: 0.0000e+00 - val_loss: 1.9923e-04 - val_acc: 0.0000e+00\n",
      "Epoch 243/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8112e-05 - acc: 0.0000e+00 - val_loss: 7.5395e-05 - val_acc: 0.0000e+00\n",
      "Epoch 244/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.1506e-05 - acc: 0.0000e+00 - val_loss: 1.4405e-04 - val_acc: 0.0000e+00\n",
      "Epoch 245/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.1629e-05 - acc: 0.0000e+00 - val_loss: 6.0321e-05 - val_acc: 0.0000e+00\n",
      "Epoch 246/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.1584e-05 - acc: 0.0000e+00 - val_loss: 9.2755e-05 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.2621e-05 - acc: 0.0000e+00 - val_loss: 8.6067e-05 - val_acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.0651e-05 - acc: 0.0000e+00 - val_loss: 6.8675e-05 - val_acc: 0.0000e+00\n",
      "Epoch 249/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3300e-05 - acc: 0.0000e+00 - val_loss: 6.7962e-05 - val_acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.0626e-05 - acc: 0.0000e+00 - val_loss: 9.2718e-05 - val_acc: 0.0000e+00\n",
      "Epoch 251/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6529e-05 - acc: 0.0000e+00 - val_loss: 9.6351e-05 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.2529e-05 - acc: 0.0000e+00 - val_loss: 6.0959e-05 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.1707e-05 - acc: 0.0000e+00 - val_loss: 2.7722e-04 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.9078e-05 - acc: 0.0000e+00 - val_loss: 8.0732e-05 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4221e-05 - acc: 0.0000e+00 - val_loss: 9.8765e-05 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4633e-05 - acc: 0.0000e+00 - val_loss: 7.4381e-05 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.2392e-05 - acc: 0.0000e+00 - val_loss: 8.2301e-05 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.2074e-05 - acc: 0.0000e+00 - val_loss: 9.4928e-05 - val_acc: 0.0000e+00\n",
      "Epoch 259/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.0872e-05 - acc: 0.0000e+00 - val_loss: 7.0313e-05 - val_acc: 0.0000e+00\n",
      "Epoch 260/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6510e-05 - acc: 0.0000e+00 - val_loss: 1.5784e-04 - val_acc: 0.0000e+00\n",
      "Epoch 261/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8005e-05 - acc: 0.0000e+00 - val_loss: 1.0360e-04 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.1381e-05 - acc: 0.0000e+00 - val_loss: 1.0178e-04 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.9799e-05 - acc: 0.0000e+00 - val_loss: 8.7387e-05 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.2490e-05 - acc: 0.0000e+00 - val_loss: 6.5063e-05 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.2580e-05 - acc: 0.0000e+00 - val_loss: 6.0007e-05 - val_acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.1648e-05 - acc: 0.0000e+00 - val_loss: 6.2496e-05 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.1595e-05 - acc: 0.0000e+00 - val_loss: 7.8071e-05 - val_acc: 0.0000e+00\n",
      "Epoch 268/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.1240e-05 - acc: 0.0000e+00 - val_loss: 9.1970e-05 - val_acc: 0.0000e+00\n",
      "Epoch 269/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.9704e-05 - acc: 0.0000e+00 - val_loss: 7.3336e-05 - val_acc: 0.0000e+00\n",
      "Epoch 270/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.0119e-05 - acc: 0.0000e+00 - val_loss: 7.8346e-05 - val_acc: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "dlist = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "neurons_LSTM = [32, 64, 128, 256, 512, 1024, 2048]\n",
    "\n",
    "for d in dlist:\n",
    "    dropout_result = {}\n",
    "    trainScore, testScore = quick_measure(stock_name, seq_len, d, shape, neurons, epochs)\n",
    "    dropout_result[d] = testScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val = min(dropout_result.values())\n",
    "min_val_key = [k for k, v in dropout_result.items() if v == min_val]\n",
    "print (min_val_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.2 Optimial epochs value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.3 Optimal number of neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
